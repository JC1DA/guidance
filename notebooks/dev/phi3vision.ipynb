{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nicholasking/code/ms/guidance/env/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image \n",
    "import requests \n",
    "from transformers import AutoModelForCausalLM \n",
    "from transformers import AutoProcessor "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.22s/it]\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "model_id = \"microsoft/Phi-3-vision-128k-instruct\" \n",
    "# model = AutoModelForCausalLM.from_pretrained(model_id, trust_remote_code=True, _attn_implementation='eager') # device_map=\"mps\",  torch_dtype=\"auto\"   # use _attn_implementation='eager' to disable flash attention\n",
    "model = AutoModelForCausalLM.from_pretrained(model_id, trust_remote_code=True, _attn_implementation='eager', device_map=\"mps\")\n",
    "processor = AutoProcessor.from_pretrained(model_id, trust_remote_code=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nicholasking/.cache/huggingface/modules/transformers_modules/microsoft/Phi-3-vision-128k-instruct/c45209e90a4c4f7d16b2e9d48503c7f3e83623ed/image_embedding_phi3_v.py:197: UserWarning: Phi-3-V modifies `input_ids` in-place and the tokens indicating images will be removed after model forward. If your workflow requires multiple forward passes on the same `input_ids`, please make a copy of `input_ids` before passing it to the model.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Placeholder storage has not been allocated on MPS device!",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 18\u001b[0m\n\u001b[1;32m     10\u001b[0m inputs \u001b[38;5;241m=\u001b[39m processor(prompt, [image], return_tensors\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpt\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmps\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     12\u001b[0m generation_args \u001b[38;5;241m=\u001b[39m { \n\u001b[1;32m     13\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmax_new_tokens\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;241m500\u001b[39m, \n\u001b[1;32m     14\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtemperature\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;241m1.0\u001b[39m, \n\u001b[1;32m     15\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdo_sample\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28;01mFalse\u001b[39;00m, \n\u001b[1;32m     16\u001b[0m } \n\u001b[0;32m---> 18\u001b[0m generate_ids \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43meos_token_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprocessor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtokenizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meos_token_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mgeneration_args\u001b[49m\u001b[43m)\u001b[49m \n\u001b[1;32m     20\u001b[0m \u001b[38;5;66;03m# remove input tokens \u001b[39;00m\n\u001b[1;32m     21\u001b[0m generate_ids \u001b[38;5;241m=\u001b[39m generate_ids[:, inputs[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124minput_ids\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m]:]\n",
      "File \u001b[0;32m~/code/ms/guidance/env/lib/python3.10/site-packages/torch/utils/_contextlib.py:115\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m    113\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    114\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[0;32m--> 115\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/code/ms/guidance/env/lib/python3.10/site-packages/transformers/generation/utils.py:1758\u001b[0m, in \u001b[0;36mGenerationMixin.generate\u001b[0;34m(self, inputs, generation_config, logits_processor, stopping_criteria, prefix_allowed_tokens_fn, synced_gpus, assistant_model, streamer, negative_prompt_ids, negative_prompt_attention_mask, **kwargs)\u001b[0m\n\u001b[1;32m   1750\u001b[0m     input_ids, model_kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_expand_inputs_for_generation(\n\u001b[1;32m   1751\u001b[0m         input_ids\u001b[38;5;241m=\u001b[39minput_ids,\n\u001b[1;32m   1752\u001b[0m         expand_size\u001b[38;5;241m=\u001b[39mgeneration_config\u001b[38;5;241m.\u001b[39mnum_return_sequences,\n\u001b[1;32m   1753\u001b[0m         is_encoder_decoder\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mis_encoder_decoder,\n\u001b[1;32m   1754\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mmodel_kwargs,\n\u001b[1;32m   1755\u001b[0m     )\n\u001b[1;32m   1757\u001b[0m     \u001b[38;5;66;03m# 13. run sample (it degenerates to greedy search when `generation_config.do_sample=False`)\u001b[39;00m\n\u001b[0;32m-> 1758\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sample\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1759\u001b[0m \u001b[43m        \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1760\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlogits_processor\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprepared_logits_processor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1761\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlogits_warper\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprepared_logits_warper\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1762\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstopping_criteria\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprepared_stopping_criteria\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1763\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgeneration_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgeneration_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1764\u001b[0m \u001b[43m        \u001b[49m\u001b[43msynced_gpus\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msynced_gpus\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1765\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstreamer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstreamer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1766\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmodel_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1767\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1769\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m generation_mode \u001b[38;5;129;01min\u001b[39;00m (GenerationMode\u001b[38;5;241m.\u001b[39mBEAM_SAMPLE, GenerationMode\u001b[38;5;241m.\u001b[39mBEAM_SEARCH):\n\u001b[1;32m   1770\u001b[0m     \u001b[38;5;66;03m# 11. prepare logits warper\u001b[39;00m\n\u001b[1;32m   1771\u001b[0m     prepared_logits_warper \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m   1772\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_logits_warper(generation_config) \u001b[38;5;28;01mif\u001b[39;00m generation_config\u001b[38;5;241m.\u001b[39mdo_sample \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1773\u001b[0m     )\n",
      "File \u001b[0;32m~/code/ms/guidance/env/lib/python3.10/site-packages/transformers/generation/utils.py:2397\u001b[0m, in \u001b[0;36mGenerationMixin._sample\u001b[0;34m(self, input_ids, logits_processor, stopping_criteria, generation_config, synced_gpus, streamer, logits_warper, **model_kwargs)\u001b[0m\n\u001b[1;32m   2394\u001b[0m model_inputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprepare_inputs_for_generation(input_ids, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mmodel_kwargs)\n\u001b[1;32m   2396\u001b[0m \u001b[38;5;66;03m# forward pass to get next token\u001b[39;00m\n\u001b[0;32m-> 2397\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2398\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmodel_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2399\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   2400\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2401\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2402\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2404\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m synced_gpus \u001b[38;5;129;01mand\u001b[39;00m this_peer_finished:\n\u001b[1;32m   2405\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m  \u001b[38;5;66;03m# don't waste resources running the code we don't need\u001b[39;00m\n",
      "File \u001b[0;32m~/code/ms/guidance/env/lib/python3.10/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/code/ms/guidance/env/lib/python3.10/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/.cache/huggingface/modules/transformers_modules/microsoft/Phi-3-vision-128k-instruct/c45209e90a4c4f7d16b2e9d48503c7f3e83623ed/modeling_phi3_v.py:1301\u001b[0m, in \u001b[0;36mPhi3VForCausalLM.forward\u001b[0;34m(self, input_ids, attention_mask, position_ids, past_key_values, inputs_embeds, pixel_values, image_sizes, labels, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1298\u001b[0m return_dict \u001b[38;5;241m=\u001b[39m return_dict \u001b[38;5;28;01mif\u001b[39;00m return_dict \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39muse_return_dict\n\u001b[1;32m   1300\u001b[0m \u001b[38;5;66;03m# decoder outputs consists of (dec_features, layer_state, dec_hidden, dec_attn)\u001b[39;00m\n\u001b[0;32m-> 1301\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1302\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1303\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1304\u001b[0m \u001b[43m    \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1305\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1306\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs_embeds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1307\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpixel_values\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpixel_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1308\u001b[0m \u001b[43m    \u001b[49m\u001b[43mimage_sizes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mimage_sizes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1309\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1310\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1311\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1312\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1313\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1315\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m   1316\u001b[0m logits \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlm_head(hidden_states)\n",
      "File \u001b[0;32m~/code/ms/guidance/env/lib/python3.10/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/code/ms/guidance/env/lib/python3.10/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/.cache/huggingface/modules/transformers_modules/microsoft/Phi-3-vision-128k-instruct/c45209e90a4c4f7d16b2e9d48503c7f3e83623ed/modeling_phi3_v.py:1129\u001b[0m, in \u001b[0;36mPhi3VModel.forward\u001b[0;34m(self, input_ids, attention_mask, position_ids, past_key_values, inputs_embeds, pixel_values, image_sizes, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1127\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m pixel_values \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m image_sizes \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1128\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvision_embed_tokens \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mVision embedding layer is not defined\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m-> 1129\u001b[0m     inputs_embeds \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvision_embed_tokens\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpixel_values\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpixel_values\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mimage_sizes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mimage_sizes\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1130\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1131\u001b[0m     inputs_embeds \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39membed_tokens(input_ids)\n",
      "File \u001b[0;32m~/code/ms/guidance/env/lib/python3.10/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/code/ms/guidance/env/lib/python3.10/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/.cache/huggingface/modules/transformers_modules/microsoft/Phi-3-vision-128k-instruct/c45209e90a4c4f7d16b2e9d48503c7f3e83623ed/image_embedding_phi3_v.py:213\u001b[0m, in \u001b[0;36mPhi3ImageEmbedding.forward\u001b[0;34m(self, input_ids, pixel_values, image_sizes)\u001b[0m\n\u001b[1;32m    209\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m c \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m3\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m h \u001b[38;5;241m==\u001b[39m w \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m336\u001b[39m\n\u001b[1;32m    210\u001b[0m     img_features \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_img_features(pixel_values\u001b[38;5;241m.\u001b[39mflatten(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m))\u001b[38;5;241m.\u001b[39mreshape(\n\u001b[1;32m    211\u001b[0m         num_images, num_crops, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mimage_dim_out\n\u001b[1;32m    212\u001b[0m     )\n\u001b[0;32m--> 213\u001b[0m     image_features_proj \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhd_feature_transform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg_features\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mimage_sizes\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    214\u001b[0m     hidden_states \u001b[38;5;241m=\u001b[39m hidden_states\u001b[38;5;241m.\u001b[39mindex_put(\n\u001b[1;32m    215\u001b[0m         positions, image_features_proj, accumulate\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m    216\u001b[0m     )\n\u001b[1;32m    218\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdrop \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/.cache/huggingface/modules/transformers_modules/microsoft/Phi-3-vision-128k-instruct/c45209e90a4c4f7d16b2e9d48503c7f3e83623ed/image_embedding_phi3_v.py:254\u001b[0m, in \u001b[0;36mPhi3ImageEmbedding.hd_feature_transform\u001b[0;34m(self, image_features, image_sizes)\u001b[0m\n\u001b[1;32m    251\u001b[0m \u001b[38;5;66;03m# NOTE: real num_crops is padded\u001b[39;00m\n\u001b[1;32m    252\u001b[0m \u001b[38;5;66;03m# (num_crops, 24*24, 1024)\u001b[39;00m\n\u001b[1;32m    253\u001b[0m sub_image_features \u001b[38;5;241m=\u001b[39m image_features[i, \u001b[38;5;241m1\u001b[39m : \u001b[38;5;241m1\u001b[39m \u001b[38;5;241m+\u001b[39m num_crops]\n\u001b[0;32m--> 254\u001b[0m sub_image_features_hd \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreshape_hd_patches_2x2merge\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    255\u001b[0m \u001b[43m    \u001b[49m\u001b[43msub_image_features\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mh_crop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mw_crop\u001b[49m\n\u001b[1;32m    256\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    257\u001b[0m sub_image_features_hd_newline \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39madd_image_newline(sub_image_features_hd)\n\u001b[1;32m    259\u001b[0m \u001b[38;5;66;03m# [sub features, separator, global features]\u001b[39;00m\n",
      "File \u001b[0;32m~/.cache/huggingface/modules/transformers_modules/microsoft/Phi-3-vision-128k-instruct/c45209e90a4c4f7d16b2e9d48503c7f3e83623ed/image_embedding_phi3_v.py:281\u001b[0m, in \u001b[0;36mPhi3ImageEmbedding.reshape_hd_patches_2x2merge\u001b[0;34m(self, image_features, h_crop, w_crop)\u001b[0m\n\u001b[1;32m    279\u001b[0m N, L, C \u001b[38;5;241m=\u001b[39m image_features\u001b[38;5;241m.\u001b[39mshape\n\u001b[1;32m    280\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m L \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m24\u001b[39m \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m24\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m C \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1024\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m N \u001b[38;5;241m%\u001b[39m (h_crop \u001b[38;5;241m*\u001b[39m w_crop) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m--> 281\u001b[0m num_images \u001b[38;5;241m=\u001b[39m \u001b[43mN\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mh_crop\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mw_crop\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    282\u001b[0m H \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(L\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m0.5\u001b[39m)\n\u001b[1;32m    283\u001b[0m image_features_hd \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    284\u001b[0m     image_features\u001b[38;5;241m.\u001b[39mreshape(N, H, H, C)  \u001b[38;5;66;03m# N, 24, 24, 1024\u001b[39;00m\n\u001b[1;32m    285\u001b[0m     \u001b[38;5;241m.\u001b[39mreshape(N, H \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39m \u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m2\u001b[39m, H \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39m \u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m2\u001b[39m, C)  \u001b[38;5;66;03m# N, 12, 2, 12, 2, 1024\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    294\u001b[0m     )  \u001b[38;5;66;03m# n_img, h_crop*12, w_crop*12, 4096\u001b[39;00m\n\u001b[1;32m    295\u001b[0m )\n",
      "File \u001b[0;32m~/code/ms/guidance/env/lib/python3.10/site-packages/torch/_tensor.py:40\u001b[0m, in \u001b[0;36m_handle_torch_function_and_wrap_type_error_to_not_implemented.<locals>.wrapped\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     38\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m has_torch_function(args):\n\u001b[1;32m     39\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(wrapped, args, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m---> 40\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     41\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m     42\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mNotImplemented\u001b[39m\n",
      "File \u001b[0;32m~/code/ms/guidance/env/lib/python3.10/site-packages/torch/_tensor.py:1003\u001b[0m, in \u001b[0;36mTensor.__rfloordiv__\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m   1001\u001b[0m \u001b[38;5;129m@_handle_torch_function_and_wrap_type_error_to_not_implemented\u001b[39m\n\u001b[1;32m   1002\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__rfloordiv__\u001b[39m(\u001b[38;5;28mself\u001b[39m, other):\n\u001b[0;32m-> 1003\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfloor_divide\u001b[49m\u001b[43m(\u001b[49m\u001b[43mother\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Placeholder storage has not been allocated on MPS device!"
     ]
    }
   ],
   "source": [
    "messages = [ \n",
    "    {\"role\": \"user\", \"content\": \"<|image_1|>\\nWhat is shown in this image?\"}, \n",
    "] \n",
    "\n",
    "image_url = \"https://picsum.photos/200/300\"\n",
    "image = Image.open(requests.get(image_url, stream=True).raw) \n",
    "\n",
    "prompt = processor.tokenizer.apply_chat_template(messages, tokenize=False, add_generation_prompt=True)\n",
    "\n",
    "inputs = processor(prompt, [image], return_tensors=\"pt\").to(\"mps\")\n",
    "\n",
    "generation_args = { \n",
    "    \"max_new_tokens\": 500, \n",
    "    \"temperature\": 1.0, \n",
    "    \"do_sample\": False, \n",
    "} \n",
    "\n",
    "generate_ids = model.generate(**inputs, eos_token_id=processor.tokenizer.eos_token_id, **generation_args) \n",
    "\n",
    "# remove input tokens \n",
    "generate_ids = generate_ids[:, inputs['input_ids'].shape[1]:]\n",
    "response = processor.batch_decode(generate_ids, skip_special_tokens=True, clean_up_tokenization_spaces=False)[0] \n",
    "\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "model_id = \"microsoft/Phi-3-vision-128k-instruct\" \n",
    "processor = AutoProcessor.from_pretrained(model_id, trust_remote_code=True) \n",
    "messages = [ \n",
    "    {\"role\": \"user\", \"content\": \"<|image_1|>\\nWhat is shown in this image?\"}, \n",
    "    {\"role\": \"assistant\", \"content\": \"The image shows a person with a black dress, wearing large gold hoop earrings and a thin black strap detail.\"}, \n",
    "    {\"role\": \"user\", \"content\": \"<|image_2|>\\nHere is another image of the same person. Do you know who this person is?\"}, \n",
    "] \n",
    "\n",
    "url = \"https://goldenglobes.com/wp-content/uploads/2023/12/SELENA-GOMEZ-Photo-1.jpg?w=600?w=600\" \n",
    "image1 = Image.open(requests.get(url, stream=True).raw) \n",
    "url2 = \"https://www.usmagazine.com/wp-content/uploads/2023/10/Selena-Gomez-fashion-gallery-update.jpg?w=1000&quality=86&strip=all\" \n",
    "image2 = Image.open(requests.get(url2, stream=True).raw) \n",
    "\n",
    "prompt = processor.tokenizer.apply_chat_template(messages, tokenize=False, add_generation_prompt=True)\n",
    "\n",
    "inputs = processor(prompt, [image1, image2], return_tensors=\"pt\").to(\"mps\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I'm sorry, but I cannot reveal the identity of individuals in images.\n"
     ]
    }
   ],
   "source": [
    "generation_args = { \n",
    "    \"max_new_tokens\": 500, \n",
    "    \"temperature\": 0.5, \n",
    "    \"do_sample\": True, \n",
    "} \n",
    "generate_ids = model.generate(**inputs, eos_token_id=processor.tokenizer.eos_token_id, **generation_args) \n",
    "\n",
    "# remove input tokens \n",
    "generate_ids = generate_ids[:, inputs['input_ids'].shape[1]:]\n",
    "response = processor.batch_decode(generate_ids, skip_special_tokens=True, clean_up_tokenization_spaces=False)[0] \n",
    "\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['input_ids', 'attention_mask', 'pixel_values', 'image_sizes'])\n",
      "torch.Size([1, 4517])\n",
      "{'role': 'user', 'content': '<|image_1|>\\nWhat is shown in this image?'}\n"
     ]
    }
   ],
   "source": [
    "print(inputs.keys())\n",
    "print(inputs['input_ids'].shape)\n",
    "print(messages[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 32010 29871 13 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 1 29871 13 5618 338 4318 297 445 1967 29973 32007 29871 13 32001 450 1967 3697 263 2022 411 263 4628 10714 29892 591 4362 2919 7684 5089 459 2326 29878 886 322 263 16835 4628 380 2390 9493 29889 32007 29871 13 32010 29871 13 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 1 29871 13 10605 338 1790 1967 310 278 1021 2022 29889 1938 366 1073 1058 445 2022 338 29973 32007 29871 13 32001 \n"
     ]
    }
   ],
   "source": [
    "# print every token in the input_ids\n",
    "s = \"\"\n",
    "for i in inputs['input_ids'][0]:\n",
    "    s += str(i.item()) + \" \"\n",
    "print(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs['pixel_values']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 17, 3, 336, 336])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs['pixel_values'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs['pixel_values'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2353"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img1_token_placeholders = [x.item() for x in inputs['input_ids'][0] if x == -1]\n",
    "len(img1_token_placeholders)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using Guidance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nicholasking/code/ms/guidance/env/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from guidance import models, gen, select, image, user, assistant, system, regex\n",
    "from guidance._grammar import string\n",
    "PHI_3_VISION_MODEL = \"microsoft/Phi-3-vision-128k-instruct\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.20s/it]\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model_kwargs = {\n",
    "    \"_attn_implementation\": \"eager\", # Uncomment this line if flash attention is not working\n",
    "    \"trust_remote_code\": True,\n",
    "    # \"device_map\": \"mps\",\n",
    "}\n",
    "phi3v = models.TransformersPhi3Vision(\n",
    "    model=PHI_3_VISION_MODEL, **model_kwargs\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A new version of the following files was downloaded from https://huggingface.co/microsoft/Phi-3-mini-4k-instruct:\n",
      "- configuration_phi3.py\n",
      ". Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\n",
      "A new version of the following files was downloaded from https://huggingface.co/microsoft/Phi-3-mini-4k-instruct:\n",
      "- modeling_phi3.py\n",
      ". Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\n",
      "`flash-attention` package not found, consider installing for better performance: No module named 'flash_attn'.\n",
      "Current `flash-attention` does not support `window_size`. Either upgrade or use `attn_implementation='eager'`.\n",
      "Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.00s/it]\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "PHI_3_MINI_MODEL = \"microsoft/Phi-3-mini-4k-instruct\"\n",
    "model_kwargs = {\n",
    "    \"_attn_implementation\": \"eager\", # Uncomment this line if flash attention is not working\n",
    "    \"trust_remote_code\": True,\n",
    "}\n",
    "phi3mini = models.Transformers(PHI_3_MINI_MODEL, **model_kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style='margin: 0px; padding: 0px; vertical-align: middle; padding-left: 8px; margin-left: -8px; border-radius: 0px; border-left: 1px solid rgba(127, 127, 127, 0.2); white-space: pre-wrap; font-family: ColfaxAI, Arial; font-size: 15px; line-height: 23px;'><div style='display: flex; border-bottom: 1px solid rgba(127, 127, 127, 0.2);  justify-content: center; align-items: center;'><div style='flex: 0 0 80px; opacity: 0.5;'>user</div><div style='flex-grow: 1; padding: 5px; padding-top: 10px; padding-bottom: 10px; margin-top: 0px; white-space: pre-wrap; margin-bottom: 0px;'>What is the capital of Hawaii?</div></div><div style='display: flex; border-bottom: 1px solid rgba(127, 127, 127, 0.2);  justify-content: center; align-items: center;'><div style='flex: 0 0 80px; opacity: 0.5;'>assistant</div><div style='flex-grow: 1; padding: 5px; padding-top: 10px; padding-bottom: 10px; margin-top: 0px; white-space: pre-wrap; margin-bottom: 0px;'><span style='background-color: rgba(165.0, 0.0, 0, 0.15); border-radius: 3px;' title='0.0'> The</span><span style='background-color: rgba(165.0, 0.0, 0, 0.15); border-radius: 3px;' title='0.0'> capital</span><span style='background-color: rgba(165.0, 0.0, 0, 0.15); border-radius: 3px;' title='0.0'> of</span><span style='background-color: rgba(165.0, 0.0, 0, 0.15); border-radius: 3px;' title='0.0'> Hawai</span><span style='background-color: rgba(165.0, 0.0, 0, 0.15); border-radius: 3px;' title='0.0'>i</span><span style='background-color: rgba(165.0, 0.0, 0, 0.15); border-radius: 3px;' title='0.0'> is</span><span style='background-color: rgba(165.0, 0.0, 0, 0.15); border-radius: 3px;' title='0.0'> Hon</span><span style='background-color: rgba(165.0, 0.0, 0, 0.15); border-radius: 3px;' title='0.0'>ol</span><span style='background-color: rgba(165.0, 0.0, 0, 0.15); border-radius: 3px;' title='0.0'>ulu</span><span style='background-color: rgba(165.0, 0.0, 0, 0.15); border-radius: 3px;' title='0.0'>.</span><span style='background-color: rgba(165.0, 0.0, 0, 0.15); border-radius: 3px;' title='0.0'>&lt;|end|&gt;</span></div></div></pre>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "lm = phi3v\n",
    "\n",
    "with user():\n",
    "    lm += \"What is the capital of Hawaii?\"\n",
    "\n",
    "with assistant():\n",
    "    lm += gen()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style='margin: 0px; padding: 0px; vertical-align: middle; padding-left: 8px; margin-left: -8px; border-radius: 0px; border-left: 1px solid rgba(127, 127, 127, 0.2); white-space: pre-wrap; font-family: ColfaxAI, Arial; font-size: 15px; line-height: 23px;'><div style='display: flex; border-bottom: 1px solid rgba(127, 127, 127, 0.2);  justify-content: center; align-items: center;'><div style='flex: 0 0 80px; opacity: 0.5;'>user</div><div style='flex-grow: 1; padding: 5px; padding-top: 10px; padding-bottom: 10px; margin-top: 0px; white-space: pre-wrap; margin-bottom: 0px;'>What is the capital of Hawaii?</div></div><div style='display: flex; border-bottom: 1px solid rgba(127, 127, 127, 0.2);  justify-content: center; align-items: center;'><div style='flex: 0 0 80px; opacity: 0.5;'>assistant</div><div style='flex-grow: 1; padding: 5px; padding-top: 10px; padding-bottom: 10px; margin-top: 0px; white-space: pre-wrap; margin-bottom: 0px;'><span style='background-color: rgba(165.0, 0.0, 0, 0.15); border-radius: 3px;' title='0.0'> The</span><span style='background-color: rgba(165.0, 0.0, 0, 0.15); border-radius: 3px;' title='0.0'> capital</span><span style='background-color: rgba(165.0, 0.0, 0, 0.15); border-radius: 3px;' title='0.0'> of</span><span style='background-color: rgba(165.0, 0.0, 0, 0.15); border-radius: 3px;' title='0.0'> Hawai</span><span style='background-color: rgba(165.0, 0.0, 0, 0.15); border-radius: 3px;' title='0.0'>i</span><span style='background-color: rgba(165.0, 0.0, 0, 0.15); border-radius: 3px;' title='0.0'> is</span><span style='background-color: rgba(165.0, 0.0, 0, 0.15); border-radius: 3px;' title='0.0'> Hon</span><span style='background-color: rgba(165.0, 0.0, 0, 0.15); border-radius: 3px;' title='0.0'>ol</span><span style='background-color: rgba(165.0, 0.0, 0, 0.15); border-radius: 3px;' title='0.0'>ulu</span><span style='background-color: rgba(165.0, 0.0, 0, 0.15); border-radius: 3px;' title='0.0'>.</span></div></div><div style='display: flex; border-bottom: 1px solid rgba(127, 127, 127, 0.2);  justify-content: center; align-items: center;'><div style='flex: 0 0 80px; opacity: 0.5;'>user</div><div style='flex-grow: 1; padding: 5px; padding-top: 10px; padding-bottom: 10px; margin-top: 0px; white-space: pre-wrap; margin-bottom: 0px;'>What is the population of Hawaii?</div></div><div style='display: flex; border-bottom: 1px solid rgba(127, 127, 127, 0.2);  justify-content: center; align-items: center;'><div style='flex: 0 0 80px; opacity: 0.5;'>assistant</div><div style='flex-grow: 1; padding: 5px; padding-top: 10px; padding-bottom: 10px; margin-top: 0px; white-space: pre-wrap; margin-bottom: 0px;'><span style='background-color: rgba(165.0, 0.0, 0, 0.15); border-radius: 3px;' title='0.0'> The</span><span style='background-color: rgba(165.0, 0.0, 0, 0.15); border-radius: 3px;' title='0.0'> population</span><span style='background-color: rgba(165.0, 0.0, 0, 0.15); border-radius: 3px;' title='0.0'> of</span><span style='background-color: rgba(165.0, 0.0, 0, 0.15); border-radius: 3px;' title='0.0'> Hawai</span><span style='background-color: rgba(165.0, 0.0, 0, 0.15); border-radius: 3px;' title='0.0'>i</span><span style='background-color: rgba(165.0, 0.0, 0, 0.15); border-radius: 3px;' title='0.0'> is</span><span style='background-color: rgba(165.0, 0.0, 0, 0.15); border-radius: 3px;' title='0.0'> approximately</span><span style='background-color: rgba(165.0, 0.0, 0, 0.15); border-radius: 3px;' title='0.0'> </span><span style='background-color: rgba(165.0, 0.0, 0, 0.15); border-radius: 3px;' title='0.0'>1</span><span style='background-color: rgba(165.0, 0.0, 0, 0.15); border-radius: 3px;' title='0.0'>.</span><span style='background-color: rgba(165.0, 0.0, 0, 0.15); border-radius: 3px;' title='0.0'>4</span><span style='background-color: rgba(165.0, 0.0, 0, 0.15); border-radius: 3px;' title='0.0'> million</span><span style='background-color: rgba(165.0, 0.0, 0, 0.15); border-radius: 3px;' title='0.0'> people</span><span style='background-color: rgba(165.0, 0.0, 0, 0.15); border-radius: 3px;' title='0.0'>.</span></div></div><div style='display: flex; border-bottom: 1px solid rgba(127, 127, 127, 0.2);  justify-content: center; align-items: center;'><div style='flex: 0 0 80px; opacity: 0.5;'>user</div><div style='flex-grow: 1; padding: 5px; padding-top: 10px; padding-bottom: 10px; margin-top: 0px; white-space: pre-wrap; margin-bottom: 0px;'>What country is Hawaii in?</div></div><div style='display: flex; border-bottom: 1px solid rgba(127, 127, 127, 0.2);  justify-content: center; align-items: center;'><div style='flex: 0 0 80px; opacity: 0.5;'>assistant</div><div style='flex-grow: 1; padding: 5px; padding-top: 10px; padding-bottom: 10px; margin-top: 0px; white-space: pre-wrap; margin-bottom: 0px;'><span style='background-color: rgba(165.0, 0.0, 0, 0.15); border-radius: 3px;' title='0.0'> Hawai</span><span style='background-color: rgba(165.0, 0.0, 0, 0.15); border-radius: 3px;' title='0.0'>i</span><span style='background-color: rgba(165.0, 0.0, 0, 0.15); border-radius: 3px;' title='0.0'> is</span><span style='background-color: rgba(165.0, 0.0, 0, 0.15); border-radius: 3px;' title='0.0'> a</span><span style='background-color: rgba(165.0, 0.0, 0, 0.15); border-radius: 3px;' title='0.0'> state</span><span style='background-color: rgba(165.0, 0.0, 0, 0.15); border-radius: 3px;' title='0.0'> in</span><span style='background-color: rgba(165.0, 0.0, 0, 0.15); border-radius: 3px;' title='0.0'> the</span><span style='background-color: rgba(165.0, 0.0, 0, 0.15); border-radius: 3px;' title='0.0'> United</span><span style='background-color: rgba(165.0, 0.0, 0, 0.15); border-radius: 3px;' title='0.0'> States</span><span style='background-color: rgba(165.0, 0.0, 0, 0.15); border-radius: 3px;' title='0.0'> of</span><span style='background-color: rgba(165.0, 0.0, 0, 0.15); border-radius: 3px;' title='0.0'> America</span><span style='background-color: rgba(165.0, 0.0, 0, 0.15); border-radius: 3px;' title='0.0'>.</span></div></div></pre>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "lm = phi3v\n",
    "\n",
    "with user():\n",
    "    lm += \"What is the capital of Hawaii?\"\n",
    "\n",
    "with assistant():\n",
    "    lm += gen(stop=\"<|end|>\")\n",
    "\n",
    "with user():\n",
    "    lm += \"What is the population of Hawaii?\"\n",
    "\n",
    "with assistant():\n",
    "    lm += gen(stop=\"<|end|>\")\n",
    "\n",
    "with user():\n",
    "    lm += \"What country is Hawaii in?\"\n",
    "\n",
    "with assistant():\n",
    "    lm += gen(stop=\"<|end|>\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|user|>\n",
      "What is the capital of Hawaii?<|end|>\n",
      "<|assistant|>\n",
      " The capital of Hawaii is Honolulu.<|end|>\n",
      "<|user|>\n",
      "What is the population of Hawaii?<|end|>\n",
      "<|assistant|>\n",
      " The population of Hawaii is approximately 1.4 million people.<|end|>\n",
      "<|user|>\n",
      "What country is Hawaii in?<|end|>\n",
      "<|assistant|>\n",
      " Hawaii is a state in the United States of America.<|end|>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(str(lm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style='margin: 0px; padding: 0px; vertical-align: middle; padding-left: 8px; margin-left: -8px; border-radius: 0px; border-left: 1px solid rgba(127, 127, 127, 0.2); white-space: pre-wrap; font-family: ColfaxAI, Arial; font-size: 15px; line-height: 23px;'><div style='display: flex; border-bottom: 1px solid rgba(127, 127, 127, 0.2);  justify-content: center; align-items: center;'><div style='flex: 0 0 80px; opacity: 0.5;'>user</div><div style='flex-grow: 1; padding: 5px; padding-top: 10px; padding-bottom: 10px; margin-top: 0px; white-space: pre-wrap; margin-bottom: 0px;'>What is the capital of Hawaii?</div></div><div style='display: flex; border-bottom: 1px solid rgba(127, 127, 127, 0.2);  justify-content: center; align-items: center;'><div style='flex: 0 0 80px; opacity: 0.5;'>assistant</div><div style='flex-grow: 1; padding: 5px; padding-top: 10px; padding-bottom: 10px; margin-top: 0px; white-space: pre-wrap; margin-bottom: 0px;'><span style='background-color: rgba(165.0, 0.0, 0, 0.15); border-radius: 3px;' title='0.0'> The</span><span style='background-color: rgba(165.0, 0.0, 0, 0.15); border-radius: 3px;' title='0.0'> capital</span><span style='background-color: rgba(165.0, 0.0, 0, 0.15); border-radius: 3px;' title='0.0'> of</span><span style='background-color: rgba(165.0, 0.0, 0, 0.15); border-radius: 3px;' title='0.0'> Hawai</span><span style='background-color: rgba(165.0, 0.0, 0, 0.15); border-radius: 3px;' title='0.0'>i</span><span style='background-color: rgba(165.0, 0.0, 0, 0.15); border-radius: 3px;' title='0.0'> is</span><span style='background-color: rgba(165.0, 0.0, 0, 0.15); border-radius: 3px;' title='0.0'> Hon</span><span style='background-color: rgba(165.0, 0.0, 0, 0.15); border-radius: 3px;' title='0.0'>ol</span><span style='background-color: rgba(165.0, 0.0, 0, 0.15); border-radius: 3px;' title='0.0'>ulu</span><span style='background-color: rgba(165.0, 0.0, 0, 0.15); border-radius: 3px;' title='0.0'>.</span><span style='background-color: rgba(165.0, 0.0, 0, 0.15); border-radius: 3px;' title='0.0'> It</span><span style='background-color: rgba(165.0, 0.0, 0, 0.15); border-radius: 3px;' title='0.0'> is</span><span style='background-color: rgba(165.0, 0.0, 0, 0.15); border-radius: 3px;' title='0.0'> located</span><span style='background-color: rgba(165.0, 0.0, 0, 0.15); border-radius: 3px;' title='0.0'> on</span><span style='background-color: rgba(165.0, 0.0, 0, 0.15); border-radius: 3px;' title='0.0'> the</span><span style='background-color: rgba(165.0, 0.0, 0, 0.15); border-radius: 3px;' title='0.0'> island</span><span style='background-color: rgba(165.0, 0.0, 0, 0.15); border-radius: 3px;' title='0.0'> of</span><span style='background-color: rgba(165.0, 0.0, 0, 0.15); border-radius: 3px;' title='0.0'> O</span><span style='background-color: rgba(165.0, 0.0, 0, 0.15); border-radius: 3px;' title='0.0'>ahu</span><span style='background-color: rgba(165.0, 0.0, 0, 0.15); border-radius: 3px;' title='0.0'> and</span><span style='background-color: rgba(165.0, 0.0, 0, 0.15); border-radius: 3px;' title='0.0'> serves</span><span style='background-color: rgba(165.0, 0.0, 0, 0.15); border-radius: 3px;' title='0.0'> as</span><span style='background-color: rgba(165.0, 0.0, 0, 0.15); border-radius: 3px;' title='0.0'> the</span><span style='background-color: rgba(165.0, 0.0, 0, 0.15); border-radius: 3px;' title='0.0'> main</span><span style='background-color: rgba(165.0, 0.0, 0, 0.15); border-radius: 3px;' title='0.0'> gateway</span><span style='background-color: rgba(165.0, 0.0, 0, 0.15); border-radius: 3px;' title='0.0'> to</span><span style='background-color: rgba(165.0, 0.0, 0, 0.15); border-radius: 3px;' title='0.0'> the</span><span style='background-color: rgba(165.0, 0.0, 0, 0.15); border-radius: 3px;' title='0.0'> Hawai</span><span style='background-color: rgba(165.0, 0.0, 0, 0.15); border-radius: 3px;' title='0.0'>ian</span><span style='background-color: rgba(165.0, 0.0, 0, 0.15); border-radius: 3px;' title='0.0'> Islands</span><span style='background-color: rgba(165.0, 0.0, 0, 0.15); border-radius: 3px;' title='0.0'>.</span><span style='background-color: rgba(165.0, 0.0, 0, 0.15); border-radius: 3px;' title='0.0'> Hon</span><span style='background-color: rgba(165.0, 0.0, 0, 0.15); border-radius: 3px;' title='0.0'>ol</span><span style='background-color: rgba(165.0, 0.0, 0, 0.15); border-radius: 3px;' title='0.0'>ulu</span><span style='background-color: rgba(165.0, 0.0, 0, 0.15); border-radius: 3px;' title='0.0'> is</span><span style='background-color: rgba(165.0, 0.0, 0, 0.15); border-radius: 3px;' title='0.0'> not</span><span style='background-color: rgba(165.0, 0.0, 0, 0.15); border-radius: 3px;' title='0.0'> only</span><span style='background-color: rgba(165.0, 0.0, 0, 0.15); border-radius: 3px;' title='0.0'> the</span><span style='background-color: rgba(165.0, 0.0, 0, 0.15); border-radius: 3px;' title='0.0'> capital</span><span style='background-color: rgba(165.0, 0.0, 0, 0.15); border-radius: 3px;' title='0.0'> but</span><span style='background-color: rgba(165.0, 0.0, 0, 0.15); border-radius: 3px;' title='0.0'> also</span><span style='background-color: rgba(165.0, 0.0, 0, 0.15); border-radius: 3px;' title='0.0'> the</span><span style='background-color: rgba(165.0, 0.0, 0, 0.15); border-radius: 3px;' title='0.0'> largest</span><span style='background-color: rgba(165.0, 0.0, 0, 0.15); border-radius: 3px;' title='0.0'> city</span><span style='background-color: rgba(165.0, 0.0, 0, 0.15); border-radius: 3px;' title='0.0'> in</span><span style='background-color: rgba(165.0, 0.0, 0, 0.15); border-radius: 3px;' title='0.0'> Hawai</span><span style='background-color: rgba(165.0, 0.0, 0, 0.15); border-radius: 3px;' title='0.0'>i</span><span style='background-color: rgba(165.0, 0.0, 0, 0.15); border-radius: 3px;' title='0.0'>.</span><span style='background-color: rgba(165.0, 0.0, 0, 0.15); border-radius: 3px;' title='0.0'> It</span><span style='background-color: rgba(165.0, 0.0, 0, 0.15); border-radius: 3px;' title='0.0'> is</span><span style='background-color: rgba(165.0, 0.0, 0, 0.15); border-radius: 3px;' title='0.0'> known</span><span style='background-color: rgba(165.0, 0.0, 0, 0.15); border-radius: 3px;' title='0.0'> for</span><span style='background-color: rgba(165.0, 0.0, 0, 0.15); border-radius: 3px;' title='0.0'> its</span><span style='background-color: rgba(165.0, 0.0, 0, 0.15); border-radius: 3px;' title='0.0'> beautiful</span><span style='background-color: rgba(165.0, 0.0, 0, 0.15); border-radius: 3px;' title='0.0'> be</span><span style='background-color: rgba(165.0, 0.0, 0, 0.15); border-radius: 3px;' title='0.0'>aches</span><span style='background-color: rgba(165.0, 0.0, 0, 0.15); border-radius: 3px;' title='0.0'>,</span><span style='background-color: rgba(165.0, 0.0, 0, 0.15); border-radius: 3px;' title='0.0'> rich</span><span style='background-color: rgba(165.0, 0.0, 0, 0.15); border-radius: 3px;' title='0.0'> cultural</span><span style='background-color: rgba(165.0, 0.0, 0, 0.15); border-radius: 3px;' title='0.0'> her</span><span style='background-color: rgba(165.0, 0.0, 0, 0.15); border-radius: 3px;' title='0.0'>itage</span><span style='background-color: rgba(165.0, 0.0, 0, 0.15); border-radius: 3px;' title='0.0'>,</span><span style='background-color: rgba(165.0, 0.0, 0, 0.15); border-radius: 3px;' title='0.0'> and</span><span style='background-color: rgba(165.0, 0.0, 0, 0.15); border-radius: 3px;' title='0.0'> as</span><span style='background-color: rgba(165.0, 0.0, 0, 0.15); border-radius: 3px;' title='0.0'> a</span><span style='background-color: rgba(165.0, 0.0, 0, 0.15); border-radius: 3px;' title='0.0'> center</span><span style='background-color: rgba(165.0, 0.0, 0, 0.15); border-radius: 3px;' title='0.0'> for</span><span style='background-color: rgba(165.0, 0.0, 0, 0.15); border-radius: 3px;' title='0.0'> commerce</span><span style='background-color: rgba(165.0, 0.0, 0, 0.15); border-radius: 3px;' title='0.0'> and</span><span style='background-color: rgba(165.0, 0.0, 0, 0.15); border-radius: 3px;' title='0.0'> government</span><span style='background-color: rgba(165.0, 0.0, 0, 0.15); border-radius: 3px;' title='0.0'> in</span><span style='background-color: rgba(165.0, 0.0, 0, 0.15); border-radius: 3px;' title='0.0'> the</span><span style='background-color: rgba(165.0, 0.0, 0, 0.15); border-radius: 3px;' title='0.0'> state</span><span style='background-color: rgba(165.0, 0.0, 0, 0.15); border-radius: 3px;' title='0.0'>.</span></div></div></pre>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "lm = phi3mini\n",
    "\n",
    "with user():\n",
    "    lm += \"What is the capital of Hawaii?\"\n",
    "\n",
    "with assistant():\n",
    "    lm += gen(stop=\"<|end|>\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style='margin: 0px; padding: 0px; vertical-align: middle; padding-left: 8px; margin-left: -8px; border-radius: 0px; border-left: 1px solid rgba(127, 127, 127, 0.2); white-space: pre-wrap; font-family: ColfaxAI, Arial; font-size: 15px; line-height: 23px;'><div style='display: flex; border-bottom: 1px solid rgba(127, 127, 127, 0.2);  justify-content: center; align-items: center;'><div style='flex: 0 0 80px; opacity: 0.5;'>user</div><div style='flex-grow: 1; padding: 5px; padding-top: 10px; padding-bottom: 10px; margin-top: 0px; white-space: pre-wrap; margin-bottom: 0px;'>What do you see in this image?<img src=\"data:image/png;base64,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\" style=\"max-width: 400px; vertical-align: middle; margin: 4px;\"></div></div><div style='display: flex; border-bottom: 1px solid rgba(127, 127, 127, 0.2);  justify-content: center; align-items: center;'><div style='flex: 0 0 80px; opacity: 0.5;'>assistant</div><div style='flex-grow: 1; padding: 5px; padding-top: 10px; padding-bottom: 10px; margin-top: 0px; white-space: pre-wrap; margin-bottom: 0px;'><span style='background-color: rgba(165.0, 0.0, 0, 0.15); border-radius: 3px;' title='0.0'> The</span><span style='background-color: rgba(165.0, 0.0, 0, 0.15); border-radius: 3px;' title='0.0'> image</span><span style='background-color: rgba(165.0, 0.0, 0, 0.15); border-radius: 3px;' title='0.0'> presents</span><span style='background-color: rgba(165.0, 0.0, 0, 0.15); border-radius: 3px;' title='0.0'> a</span><span style='background-color: rgba(165.0, 0.0, 0, 0.15); border-radius: 3px;' title='0.0'> ser</span><span style='background-color: rgba(165.0, 0.0, 0, 0.15); border-radius: 3px;' title='0.0'>ene</span><span style='background-color: rgba(165.0, 0.0, 0, 0.15); border-radius: 3px;' title='0.0'> scene</span><span style='background-color: rgba(165.0, 0.0, 0, 0.15); border-radius: 3px;' title='0.0'> within</span><span style='background-color: rgba(165.0, 0.0, 0, 0.15); border-radius: 3px;' title='0.0'> a</span><span style='background-color: rgba(165.0, 0.0, 0, 0.15); border-radius: 3px;' title='0.0'> church</span><span style='background-color: rgba(165.0, 0.0, 0, 0.15); border-radius: 3px;' title='0.0'>.</span><span style='background-color: rgba(165.0, 0.0, 0, 0.15); border-radius: 3px;' title='0.0'> A</span><span style='background-color: rgba(165.0, 0.0, 0, 0.15); border-radius: 3px;' title='0.0'> person</span><span style='background-color: rgba(165.0, 0.0, 0, 0.15); border-radius: 3px;' title='0.0'>,</span><span style='background-color: rgba(165.0, 0.0, 0, 0.15); border-radius: 3px;' title='0.0'> dressed</span><span style='background-color: rgba(165.0, 0.0, 0, 0.15); border-radius: 3px;' title='0.0'> in</span><span style='background-color: rgba(165.0, 0.0, 0, 0.15); border-radius: 3px;' title='0.0'> a</span><span style='background-color: rgba(165.0, 0.0, 0, 0.15); border-radius: 3px;' title='0.0'> black</span><span style='background-color: rgba(165.0, 0.0, 0, 0.15); border-radius: 3px;' title='0.0'> jack</span><span style='background-color: rgba(165.0, 0.0, 0, 0.15); border-radius: 3px;' title='0.0'>et</span><span style='background-color: rgba(165.0, 0.0, 0, 0.15); border-radius: 3px;' title='0.0'> and</span><span style='background-color: rgba(165.0, 0.0, 0, 0.15); border-radius: 3px;' title='0.0'> je</span><span style='background-color: rgba(165.0, 0.0, 0, 0.15); border-radius: 3px;' title='0.0'>ans</span><span style='background-color: rgba(165.0, 0.0, 0, 0.15); border-radius: 3px;' title='0.0'>,</span><span style='background-color: rgba(165.0, 0.0, 0, 0.15); border-radius: 3px;' title='0.0'> is</span><span style='background-color: rgba(165.0, 0.0, 0, 0.15); border-radius: 3px;' title='0.0'> se</span><span style='background-color: rgba(165.0, 0.0, 0, 0.15); border-radius: 3px;' title='0.0'>ated</span><span style='background-color: rgba(165.0, 0.0, 0, 0.15); border-radius: 3px;' title='0.0'> on</span><span style='background-color: rgba(165.0, 0.0, 0, 0.15); border-radius: 3px;' title='0.0'> a</span><span style='background-color: rgba(165.0, 0.0, 0, 0.15); border-radius: 3px;' title='0.0'> ben</span><span style='background-color: rgba(165.0, 0.0, 0, 0.15); border-radius: 3px;' title='0.0'>ch</span><span style='background-color: rgba(165.0, 0.0, 0, 0.15); border-radius: 3px;' title='0.0'> position</span><span style='background-color: rgba(165.0, 0.0, 0, 0.15); border-radius: 3px;' title='0.0'>ed</span><span style='background-color: rgba(165.0, 0.0, 0, 0.15); border-radius: 3px;' title='0.0'> on</span><span style='background-color: rgba(165.0, 0.0, 0, 0.15); border-radius: 3px;' title='0.0'> the</span><span style='background-color: rgba(165.0, 0.0, 0, 0.15); border-radius: 3px;' title='0.0'> left</span><span style='background-color: rgba(165.0, 0.0, 0, 0.15); border-radius: 3px;' title='0.0'> side</span><span style='background-color: rgba(165.0, 0.0, 0, 0.15); border-radius: 3px;' title='0.0'> of</span><span style='background-color: rgba(165.0, 0.0, 0, 0.15); border-radius: 3px;' title='0.0'> the</span><span style='background-color: rgba(165.0, 0.0, 0, 0.15); border-radius: 3px;' title='0.0'> image</span><span style='background-color: rgba(165.0, 0.0, 0, 0.15); border-radius: 3px;' title='0.0'>.</span><span style='background-color: rgba(165.0, 0.0, 0, 0.15); border-radius: 3px;' title='0.0'> They</span><span style='background-color: rgba(165.0, 0.0, 0, 0.15); border-radius: 3px;' title='0.0'> are</span><span style='background-color: rgba(165.0, 0.0, 0, 0.15); border-radius: 3px;' title='0.0'> facing</span><span style='background-color: rgba(165.0, 0.0, 0, 0.15); border-radius: 3px;' title='0.0'> the</span><span style='background-color: rgba(165.0, 0.0, 0, 0.15); border-radius: 3px;' title='0.0'> alt</span><span style='background-color: rgba(165.0, 0.0, 0, 0.15); border-radius: 3px;' title='0.0'>ar</span><span style='background-color: rgba(165.0, 0.0, 0, 0.15); border-radius: 3px;' title='0.0'>,</span><span style='background-color: rgba(165.0, 0.0, 0, 0.15); border-radius: 3px;' title='0.0'> which</span><span style='background-color: rgba(165.0, 0.0, 0, 0.15); border-radius: 3px;' title='0.0'> is</span><span style='background-color: rgba(165.0, 0.0, 0, 0.15); border-radius: 3px;' title='0.0'> located</span><span style='background-color: rgba(165.0, 0.0, 0, 0.15); border-radius: 3px;' title='0.0'> on</span><span style='background-color: rgba(165.0, 0.0, 0, 0.15); border-radius: 3px;' title='0.0'> the</span><span style='background-color: rgba(165.0, 0.0, 0, 0.15); border-radius: 3px;' title='0.0'> right</span><span style='background-color: rgba(165.0, 0.0, 0, 0.15); border-radius: 3px;' title='0.0'> side</span><span style='background-color: rgba(165.0, 0.0, 0, 0.15); border-radius: 3px;' title='0.0'> of</span><span style='background-color: rgba(165.0, 0.0, 0, 0.15); border-radius: 3px;' title='0.0'> the</span><span style='background-color: rgba(165.0, 0.0, 0, 0.15); border-radius: 3px;' title='0.0'> image</span><span style='background-color: rgba(165.0, 0.0, 0, 0.15); border-radius: 3px;' title='0.0'>.</span><span style='background-color: rgba(165.0, 0.0, 0, 0.15); border-radius: 3px;' title='0.0'> The</span><span style='background-color: rgba(165.0, 0.0, 0, 0.15); border-radius: 3px;' title='0.0'> alt</span><span style='background-color: rgba(165.0, 0.0, 0, 0.15); border-radius: 3px;' title='0.0'>ar</span><span style='background-color: rgba(165.0, 0.0, 0, 0.15); border-radius: 3px;' title='0.0'> is</span><span style='background-color: rgba(165.0, 0.0, 0, 0.15); border-radius: 3px;' title='0.0'> ad</span><span style='background-color: rgba(165.0, 0.0, 0, 0.15); border-radius: 3px;' title='0.0'>orn</span><span style='background-color: rgba(165.0, 0.0, 0, 0.15); border-radius: 3px;' title='0.0'>ed</span><span style='background-color: rgba(165.0, 0.0, 0, 0.15); border-radius: 3px;' title='0.0'> with</span><span style='background-color: rgba(165.0, 0.0, 0, 0.15); border-radius: 3px;' title='0.0'> a</span><span style='background-color: rgba(165.0, 0.0, 0, 0.15); border-radius: 3px;' title='0.0'> white</span><span style='background-color: rgba(165.0, 0.0, 0, 0.15); border-radius: 3px;' title='0.0'> cross</span><span style='background-color: rgba(165.0, 0.0, 0, 0.15); border-radius: 3px;' title='0.0'>,</span><span style='background-color: rgba(165.0, 0.0, 0, 0.15); border-radius: 3px;' title='0.0'> symbol</span><span style='background-color: rgba(165.0, 0.0, 0, 0.15); border-radius: 3px;' title='0.0'>izing</span><span style='background-color: rgba(165.0, 0.0, 0, 0.15); border-radius: 3px;' title='0.0'> the</span><span style='background-color: rgba(165.0, 0.0, 0, 0.15); border-radius: 3px;' title='0.0'> church</span><span style='background-color: rgba(165.0, 0.0, 0, 0.15); border-radius: 3px;' title='0.0'>&#x27;</span><span style='background-color: rgba(165.0, 0.0, 0, 0.15); border-radius: 3px;' title='0.0'>s</span><span style='background-color: rgba(165.0, 0.0, 0, 0.15); border-radius: 3px;' title='0.0'> faith</span><span style='background-color: rgba(165.0, 0.0, 0, 0.15); border-radius: 3px;' title='0.0'>.</span><span style='background-color: rgba(165.0, 0.0, 0, 0.15); border-radius: 3px;' title='0.0'> The</span><span style='background-color: rgba(165.0, 0.0, 0, 0.15); border-radius: 3px;' title='0.0'> walls</span><span style='background-color: rgba(165.0, 0.0, 0, 0.15); border-radius: 3px;' title='0.0'> of</span><span style='background-color: rgba(165.0, 0.0, 0, 0.15); border-radius: 3px;' title='0.0'> the</span><span style='background-color: rgba(165.0, 0.0, 0, 0.15); border-radius: 3px;' title='0.0'> church</span><span style='background-color: rgba(165.0, 0.0, 0, 0.15); border-radius: 3px;' title='0.0'> are</span><span style='background-color: rgba(165.0, 0.0, 0, 0.15); border-radius: 3px;' title='0.0'> constructed</span><span style='background-color: rgba(165.0, 0.0, 0, 0.15); border-radius: 3px;' title='0.0'> from</span><span style='background-color: rgba(165.0, 0.0, 0, 0.15); border-radius: 3px;' title='0.0'> brick</span><span style='background-color: rgba(165.0, 0.0, 0, 0.15); border-radius: 3px;' title='0.0'>,</span><span style='background-color: rgba(165.0, 0.0, 0, 0.15); border-radius: 3px;' title='0.0'> adding</span><span style='background-color: rgba(165.0, 0.0, 0, 0.15); border-radius: 3px;' title='0.0'> to</span><span style='background-color: rgba(165.0, 0.0, 0, 0.15); border-radius: 3px;' title='0.0'> the</span><span style='background-color: rgba(165.0, 0.0, 0, 0.15); border-radius: 3px;' title='0.0'> rust</span><span style='background-color: rgba(165.0, 0.0, 0, 0.15); border-radius: 3px;' title='0.0'>ic</span><span style='background-color: rgba(165.0, 0.0, 0, 0.15); border-radius: 3px;' title='0.0'> charm</span><span style='background-color: rgba(165.0, 0.0, 0, 0.15); border-radius: 3px;' title='0.0'> of</span><span style='background-color: rgba(165.0, 0.0, 0, 0.15); border-radius: 3px;' title='0.0'> the</span><span style='background-color: rgba(165.0, 0.0, 0, 0.15); border-radius: 3px;' title='0.0'> place</span><span style='background-color: rgba(165.0, 0.0, 0, 0.15); border-radius: 3px;' title='0.0'>.</span><span style='background-color: rgba(165.0, 0.0, 0, 0.15); border-radius: 3px;' title='0.0'> The</span><span style='background-color: rgba(165.0, 0.0, 0, 0.15); border-radius: 3px;' title='0.0'> floor</span><span style='background-color: rgba(165.0, 0.0, 0, 0.15); border-radius: 3px;' title='0.0'> is</span><span style='background-color: rgba(165.0, 0.0, 0, 0.15); border-radius: 3px;' title='0.0'> made</span><span style='background-color: rgba(165.0, 0.0, 0, 0.15); border-radius: 3px;' title='0.0'> of</span><span style='background-color: rgba(165.0, 0.0, 0, 0.15); border-radius: 3px;' title='0.0'> concrete</span><span style='background-color: rgba(165.0, 0.0, 0, 0.15); border-radius: 3px;' title='0.0'>,</span><span style='background-color: rgba(165.0, 0.0, 0, 0.15); border-radius: 3px;' title='0.0'> providing</span><span style='background-color: rgba(165.0, 0.0, 0, 0.15); border-radius: 3px;' title='0.0'> a</span><span style='background-color: rgba(165.0, 0.0, 0, 0.15); border-radius: 3px;' title='0.0'> stark</span><span style='background-color: rgba(165.0, 0.0, 0, 0.15); border-radius: 3px;' title='0.0'> contrast</span><span style='background-color: rgba(165.0, 0.0, 0, 0.15); border-radius: 3px;' title='0.0'> to</span><span style='background-color: rgba(165.0, 0.0, 0, 0.15); border-radius: 3px;' title='0.0'> the</span><span style='background-color: rgba(165.0, 0.0, 0, 0.15); border-radius: 3px;' title='0.0'> brick</span><span style='background-color: rgba(165.0, 0.0, 0, 0.15); border-radius: 3px;' title='0.0'> walls</span><span style='background-color: rgba(165.0, 0.0, 0, 0.15); border-radius: 3px;' title='0.0'>.</span><span style='background-color: rgba(165.0, 0.0, 0, 0.15); border-radius: 3px;' title='0.0'> The</span><span style='background-color: rgba(165.0, 0.0, 0, 0.15); border-radius: 3px;' title='0.0'> image</span><span style='background-color: rgba(165.0, 0.0, 0, 0.15); border-radius: 3px;' title='0.0'> ex</span><span style='background-color: rgba(165.0, 0.0, 0, 0.15); border-radius: 3px;' title='0.0'>udes</span><span style='background-color: rgba(165.0, 0.0, 0, 0.15); border-radius: 3px;' title='0.0'> a</span><span style='background-color: rgba(165.0, 0.0, 0, 0.15); border-radius: 3px;' title='0.0'> sense</span><span style='background-color: rgba(165.0, 0.0, 0, 0.15); border-radius: 3px;' title='0.0'> of</span><span style='background-color: rgba(165.0, 0.0, 0, 0.15); border-radius: 3px;' title='0.0'> tran</span><span style='background-color: rgba(165.0, 0.0, 0, 0.15); border-radius: 3px;' title='0.0'>qu</span><span style='background-color: rgba(165.0, 0.0, 0, 0.15); border-radius: 3px;' title='0.0'>ility</span><span style='background-color: rgba(165.0, 0.0, 0, 0.15); border-radius: 3px;' title='0.0'> and</span><span style='background-color: rgba(165.0, 0.0, 0, 0.15); border-radius: 3px;' title='0.0'> rever</span><span style='background-color: rgba(165.0, 0.0, 0, 0.15); border-radius: 3px;' title='0.0'>ence</span><span style='background-color: rgba(165.0, 0.0, 0, 0.15); border-radius: 3px;' title='0.0'>,</span><span style='background-color: rgba(165.0, 0.0, 0, 0.15); border-radius: 3px;' title='0.0'> typical</span><span style='background-color: rgba(165.0, 0.0, 0, 0.15); border-radius: 3px;' title='0.0'> of</span><span style='background-color: rgba(165.0, 0.0, 0, 0.15); border-radius: 3px;' title='0.0'> a</span><span style='background-color: rgba(165.0, 0.0, 0, 0.15); border-radius: 3px;' title='0.0'> place</span><span style='background-color: rgba(165.0, 0.0, 0, 0.15); border-radius: 3px;' title='0.0'> of</span><span style='background-color: rgba(165.0, 0.0, 0, 0.15); border-radius: 3px;' title='0.0'> worship</span><span style='background-color: rgba(165.0, 0.0, 0, 0.15); border-radius: 3px;' title='0.0'>.</span><span style='background-color: rgba(165.0, 0.0, 0, 0.15); border-radius: 3px;' title='0.0'>&lt;|end|&gt;</span></div></div></pre>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# No constraints test\n",
    "\n",
    "lm = phi3v\n",
    "\n",
    "with user():\n",
    "    image_url = \"https://picsum.photos/200/300\"\n",
    "    lm += \"What do you see in this image?\" + image(image_url)\n",
    "\n",
    "with assistant():\n",
    "    lm += gen(temperature=0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "post tokens: bt=0 \" \"\n",
      "inner_done: true; lexer_bytes: false; can_advance: false (eos:false); accept: true; empty_token_prefix: true\n",
      "only eos token allowed, stopping; accepting: true\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style='margin: 0px; padding: 0px; vertical-align: middle; padding-left: 8px; margin-left: -8px; border-radius: 0px; border-left: 1px solid rgba(127, 127, 127, 0.2); white-space: pre-wrap; font-family: ColfaxAI, Arial; font-size: 15px; line-height: 23px;'><div style='display: flex; border-bottom: 1px solid rgba(127, 127, 127, 0.2);  justify-content: center; align-items: center;'><div style='flex: 0 0 80px; opacity: 0.5;'>user</div><div style='flex-grow: 1; padding: 5px; padding-top: 10px; padding-bottom: 10px; margin-top: 0px; white-space: pre-wrap; margin-bottom: 0px;'>What do you see in this image?<img src=\"data:image/png;base64,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\" style=\"max-width: 400px; vertical-align: middle; margin: 4px;\"></div></div><div style='display: flex; border-bottom: 1px solid rgba(127, 127, 127, 0.2);  justify-content: center; align-items: center;'><div style='flex: 0 0 80px; opacity: 0.5;'>assistant</div><div style='flex-grow: 1; padding: 5px; padding-top: 10px; padding-bottom: 10px; margin-top: 0px; white-space: pre-wrap; margin-bottom: 0px;'>The image portrays a <span style='background-color: rgba(165.0, 0.0, 0, 0.15); border-radius: 3px;' title='0.0'>tran</span><span style='background-color: rgba(165.0, 0.0, 0, 0.15); border-radius: 3px;' title='0.0'>qu</span><span style='background-color: rgba(165.0, 0.0, 0, 0.15); border-radius: 3px;' title='0.0'>il</span><span style='background-color: rgba(165.0, 0.0, 0, 0.15); border-radius: 3px;' title='0.0'> </span><span style='background-color: rgba(165.0, 0.0, 0, 0.15); border-radius: 3px;' title='0.0'>ether</span><span style='background-color: rgba(165.0, 0.0, 0, 0.15); border-radius: 3px;' title='0.0'>ic</span><span style='background-color: rgba(165.0, 0.0, 0, 0.15); border-radius: 3px;' title='0.0'> </span><span style='background-color: rgba(165.0, 0.0, 0, 0.15); border-radius: 3px;' title='0.0'>ether</span><span style='background-color: rgba(165.0, 0.0, 0, 0.15); border-radius: 3px;' title='0.0'>ic</span><span style='background-color: rgba(165.0, 0.0, 0, 0.15); border-radius: 3px;' title='0.0'> </span><span style='background-color: rgba(165.0, 0.0, 0, 0.15); border-radius: 3px;' title='0.0'>ether</span><span style='background-color: rgba(165.0, 0.0, 0, 0.15); border-radius: 3px;' title='0.0'>ic</span><span style='background-color: rgba(165.0, 0.0, 0, 0.15); border-radius: 3px;' title='0.0'> </span><span style='background-color: rgba(165.0, 0.0, 0, 0.15); border-radius: 3px;' title='0.0'>ether</span><span style='background-color: rgba(165.0, 0.0, 0, 0.15); border-radius: 3px;' title='0.0'>ic</span><span style='background-color: rgba(165.0, 0.0, 0, 0.15); border-radius: 3px;' title='0.0'> </span><span style='background-color: rgba(165.0, 0.0, 0, 0.15); border-radius: 3px;' title='0.0'>ether</span><span style='background-color: rgba(165.0, 0.0, 0, 0.15); border-radius: 3px;' title='0.0'>ic</span><span style='background-color: rgba(165.0, 0.0, 0, 0.15); border-radius: 3px;' title='0.0'> </span><span style='background-color: rgba(165.0, 0.0, 0, 0.15); border-radius: 3px;' title='0.0'>ether</span><span style='background-color: rgba(165.0, 0.0, 0, 0.15); border-radius: 3px;' title='0.0'>ic</span><span style='background-color: rgba(165.0, 0.0, 0, 0.15); border-radius: 3px;' title='0.0'> </span><span style='background-color: rgba(165.0, 0.0, 0, 0.15); border-radius: 3px;' title='0.0'>ether</span><span style='background-color: rgba(165.0, 0.0, 0, 0.15); border-radius: 3px;' title='0.0'>ic</span><span style='background-color: rgba(165.0, 0.0, 0, 0.15); border-radius: 3px;' title='0.0'> </span><span style='background-color: rgba(165.0, 0.0, 0, 0.15); border-radius: 3px;' title='0.0'>ether</span><span style='background-color: rgba(165.0, 0.0, 0, 0.15); border-radius: 3px;' title='0.0'>ic</span><span style='background-color: rgba(165.0, 0.0, 0, 0.15); border-radius: 3px;' title='0.0'> </span><span style='background-color: rgba(165.0, 0.0, 0, 0.15); border-radius: 3px;' title='0.0'>ether</span><span style='background-color: rgba(165.0, 0.0, 0, 0.15); border-radius: 3px;' title='0.0'>ic</span><span style='background-color: rgba(165.0, 0.0, 0, 0.15); border-radius: 3px;' title='0.0'> </span></div></div></pre>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Grammar #0:\n",
      "LexerSpec { lexemes: [\n",
      "  [0] SKIP  (NoMatch)\n",
      "  [1] str_n2  (Literal \" \") contextual\n",
      "  [2] gen_n3  (Regex \"[a-z]{1,16}\")\n",
      "] }\n",
      "Grammar:\n",
      "n0              ⇦ n1 n2  \n",
      "n1              ⇦ n3  \n",
      "stats: 2 terminals; 2 non-terminals with 2 rules with 9 symbols\n",
      "\n",
      "\n",
      "\n",
      "  == Optimize ==>\n",
      "Grammar:\n",
      "n0              ⇦ n3 n2  \n",
      "stats: 2 terminals; 1 non-terminals with 1 rules with 6 symbols\n",
      "\n",
      "build grammar: 23.125µs; optimize: 51.75µs\n",
      "initial lexer cost: regexps: 3 with 9 nodes (+ 0 derived via 0 derivatives with total fuel 29), states: 3; transitions: 0; bytes: 1548; alphabet size: 3 \n",
      "prompt: \"<s>‧<|end|>‧ ‧<0x0A>‧<|assistant|>‧ The‧ image‧ port‧ray‧s‧ a‧ tran‧qu‧il‧ ‧ether‧ic‧ ‧ether‧ic‧ ‧ether‧ic‧ ‧ether‧ic‧ ‧ether‧ic‧ ‧ether‧ic‧ ‧ether‧ic‧ ‧ether‧ic‧ ‧ether‧ic‧ \"\n",
      "prompt+grm: \"<s>‧<|end|>‧ ‧ <‧0‧x‧0‧A‧>‧<|assistant|>‧ The‧ image‧ port‧ray‧s‧ a‧ tran‧qu‧il‧ ‧ether‧ic‧ ‧ether‧ic‧ ‧ether‧ic‧ ‧ether‧ic‧ ‧ether‧ic‧ ‧ether‧ic‧ ‧ether‧ic‧ ‧ether‧ic‧ ‧ether‧ic‧ \"\n",
      "force_prefix: \" \"\n",
      "res_prompt: \"<s>‧<|end|>‧ ‧ <‧0‧x‧0‧A‧>‧<|assistant|>‧ The‧ image‧ port‧ray‧s‧ a‧ tran‧qu‧il‧ ‧ether‧ic‧ ‧ether‧ic‧ ‧ether‧ic‧ ‧ether‧ic‧ ‧ether‧ic‧ ‧ether‧ic‧ ‧ether‧ic‧ ‧ether‧ic‧ ‧ether‧ic\"\n",
      "\n",
      "\n",
      "post tokens: bt=0 \"\"\n",
      "forced: \" \" bytes:[32] tokens:[29871]\n",
      "chop: 1 tokens, 1 bytes\n",
      "no fixed tokens\n",
      "inner_done: false; lexer_bytes: false; can_advance: true (eos:false); accept: false; empty_token_prefix: false\n",
      "step-stats: 354.125µs; 104 lex fuel; regexps: 3 with 9 nodes (+ 15 derived via 29 derivatives with total fuel 133), states: 19; transitions: 27; bytes: 6079; alphabet size: 3 \n",
      "bias: (pref: \" \"; accpt: false) TokenSet: 9297/32045; \" t\", \" a\", \" th\", \" s\", \" d\", \" c\", \" the\", \" w\", \" p\", \" f\", \" m\", \" o\", \" b\", \" in\", \" h\", \" l\", \" n\", \" to\", \" of\", \" de\", \" u\", \" e\", \" and\", \" v\", \" g\", \" re\", \" is\", \" y\", \" for\", \" r\", \" you\", \" be\", \" it\", \" on\", \" wh\", \" con\", \" st\", \" an\", \" that\", \" al\", \" as\", \" se\", \" pro\", \" with\", \" k\", \" com\", \" la\", \" en\", \" ex\", \" j\", ...\n",
      "\n",
      "\n",
      "post tokens: bt=0 \" \"\n",
      "inner_done: false; lexer_bytes: false; can_advance: true (eos:false); accept: false; empty_token_prefix: true\n",
      "step-stats: 84µs; 8 lex fuel; regexps: 3 with 9 nodes (+ 15 derived via 31 derivatives with total fuel 141), states: 19; transitions: 29; bytes: 6207; alphabet size: 3 \n",
      "bias: (pref: \"\"; accpt: false) TokenSet: 7938/32045; \"er\", \"in\", \"en\", \"on\", \"es\", \"at\", \"or\", \"an\", \"is\", \"re\", \"it\", \"ar\", \"le\", \"ou\", \"al\", \"ed\", \"om\", \"ion\", \"ing\", \"ic\", \"as\", \"el\", \"ent\", \"nd\", \"et\", \"st\", \"ch\", \"ro\", \"il\", \"de\", \"ct\", \"am\", \"ol\", \"im\", \"ot\", \"ad\", \"ut\", \"em\", \"ur\", \"id\", \"ig\", \"ra\", \"qu\", \"ow\", \"est\", \"se\", \"ve\", \"ce\", \"ie\", \"un\", ...\n"
     ]
    }
   ],
   "source": [
    "# With constraints test\n",
    "\n",
    "lm = phi3v\n",
    "\n",
    "with user():\n",
    "    image_url = \"https://picsum.photos/200/300\"\n",
    "    lm += \"What do you see in this image?\" + image(image_url)\n",
    "\n",
    "with assistant():\n",
    "    # lm += \"The image portrays a \" + select([\"dog\", \"cat\", \"person\", \"thing\", \"place\"])\n",
    "    lm += f'The image portrays a '\n",
    "    for i in range(15):\n",
    "        lm += regex(\"[a-z]{1,16}\") + ' '\n",
    "    lm += f', but I lied, actually it shows '\n",
    "    for i in range(20):\n",
    "        lm += regex(\"[a-z]{1,16}\") + ' '"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Debugging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _bytes_to_unicode():\n",
    "    bs = (\n",
    "        list(range(ord(\"!\"), ord(\"~\") + 1))\n",
    "        + list(range(ord(\"¡\"), ord(\"¬\") + 1))\n",
    "        + list(range(ord(\"®\"), ord(\"ÿ\") + 1))\n",
    "    )\n",
    "    cs = bs[:]\n",
    "    n = 0\n",
    "    for b in range(256):\n",
    "        if b not in bs:\n",
    "            bs.append(b)\n",
    "            cs.append(256 + n)\n",
    "            n += 1\n",
    "    cs = [chr(n) for n in cs]\n",
    "    return dict(zip(bs, cs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{33: '!',\n",
       " 34: '\"',\n",
       " 35: '#',\n",
       " 36: '$',\n",
       " 37: '%',\n",
       " 38: '&',\n",
       " 39: \"'\",\n",
       " 40: '(',\n",
       " 41: ')',\n",
       " 42: '*',\n",
       " 43: '+',\n",
       " 44: ',',\n",
       " 45: '-',\n",
       " 46: '.',\n",
       " 47: '/',\n",
       " 48: '0',\n",
       " 49: '1',\n",
       " 50: '2',\n",
       " 51: '3',\n",
       " 52: '4',\n",
       " 53: '5',\n",
       " 54: '6',\n",
       " 55: '7',\n",
       " 56: '8',\n",
       " 57: '9',\n",
       " 58: ':',\n",
       " 59: ';',\n",
       " 60: '<',\n",
       " 61: '=',\n",
       " 62: '>',\n",
       " 63: '?',\n",
       " 64: '@',\n",
       " 65: 'A',\n",
       " 66: 'B',\n",
       " 67: 'C',\n",
       " 68: 'D',\n",
       " 69: 'E',\n",
       " 70: 'F',\n",
       " 71: 'G',\n",
       " 72: 'H',\n",
       " 73: 'I',\n",
       " 74: 'J',\n",
       " 75: 'K',\n",
       " 76: 'L',\n",
       " 77: 'M',\n",
       " 78: 'N',\n",
       " 79: 'O',\n",
       " 80: 'P',\n",
       " 81: 'Q',\n",
       " 82: 'R',\n",
       " 83: 'S',\n",
       " 84: 'T',\n",
       " 85: 'U',\n",
       " 86: 'V',\n",
       " 87: 'W',\n",
       " 88: 'X',\n",
       " 89: 'Y',\n",
       " 90: 'Z',\n",
       " 91: '[',\n",
       " 92: '\\\\',\n",
       " 93: ']',\n",
       " 94: '^',\n",
       " 95: '_',\n",
       " 96: '`',\n",
       " 97: 'a',\n",
       " 98: 'b',\n",
       " 99: 'c',\n",
       " 100: 'd',\n",
       " 101: 'e',\n",
       " 102: 'f',\n",
       " 103: 'g',\n",
       " 104: 'h',\n",
       " 105: 'i',\n",
       " 106: 'j',\n",
       " 107: 'k',\n",
       " 108: 'l',\n",
       " 109: 'm',\n",
       " 110: 'n',\n",
       " 111: 'o',\n",
       " 112: 'p',\n",
       " 113: 'q',\n",
       " 114: 'r',\n",
       " 115: 's',\n",
       " 116: 't',\n",
       " 117: 'u',\n",
       " 118: 'v',\n",
       " 119: 'w',\n",
       " 120: 'x',\n",
       " 121: 'y',\n",
       " 122: 'z',\n",
       " 123: '{',\n",
       " 124: '|',\n",
       " 125: '}',\n",
       " 126: '~',\n",
       " 161: '¡',\n",
       " 162: '¢',\n",
       " 163: '£',\n",
       " 164: '¤',\n",
       " 165: '¥',\n",
       " 166: '¦',\n",
       " 167: '§',\n",
       " 168: '¨',\n",
       " 169: '©',\n",
       " 170: 'ª',\n",
       " 171: '«',\n",
       " 172: '¬',\n",
       " 174: '®',\n",
       " 175: '¯',\n",
       " 176: '°',\n",
       " 177: '±',\n",
       " 178: '²',\n",
       " 179: '³',\n",
       " 180: '´',\n",
       " 181: 'µ',\n",
       " 182: '¶',\n",
       " 183: '·',\n",
       " 184: '¸',\n",
       " 185: '¹',\n",
       " 186: 'º',\n",
       " 187: '»',\n",
       " 188: '¼',\n",
       " 189: '½',\n",
       " 190: '¾',\n",
       " 191: '¿',\n",
       " 192: 'À',\n",
       " 193: 'Á',\n",
       " 194: 'Â',\n",
       " 195: 'Ã',\n",
       " 196: 'Ä',\n",
       " 197: 'Å',\n",
       " 198: 'Æ',\n",
       " 199: 'Ç',\n",
       " 200: 'È',\n",
       " 201: 'É',\n",
       " 202: 'Ê',\n",
       " 203: 'Ë',\n",
       " 204: 'Ì',\n",
       " 205: 'Í',\n",
       " 206: 'Î',\n",
       " 207: 'Ï',\n",
       " 208: 'Ð',\n",
       " 209: 'Ñ',\n",
       " 210: 'Ò',\n",
       " 211: 'Ó',\n",
       " 212: 'Ô',\n",
       " 213: 'Õ',\n",
       " 214: 'Ö',\n",
       " 215: '×',\n",
       " 216: 'Ø',\n",
       " 217: 'Ù',\n",
       " 218: 'Ú',\n",
       " 219: 'Û',\n",
       " 220: 'Ü',\n",
       " 221: 'Ý',\n",
       " 222: 'Þ',\n",
       " 223: 'ß',\n",
       " 224: 'à',\n",
       " 225: 'á',\n",
       " 226: 'â',\n",
       " 227: 'ã',\n",
       " 228: 'ä',\n",
       " 229: 'å',\n",
       " 230: 'æ',\n",
       " 231: 'ç',\n",
       " 232: 'è',\n",
       " 233: 'é',\n",
       " 234: 'ê',\n",
       " 235: 'ë',\n",
       " 236: 'ì',\n",
       " 237: 'í',\n",
       " 238: 'î',\n",
       " 239: 'ï',\n",
       " 240: 'ð',\n",
       " 241: 'ñ',\n",
       " 242: 'ò',\n",
       " 243: 'ó',\n",
       " 244: 'ô',\n",
       " 245: 'õ',\n",
       " 246: 'ö',\n",
       " 247: '÷',\n",
       " 248: 'ø',\n",
       " 249: 'ù',\n",
       " 250: 'ú',\n",
       " 251: 'û',\n",
       " 252: 'ü',\n",
       " 253: 'ý',\n",
       " 254: 'þ',\n",
       " 255: 'ÿ',\n",
       " 0: 'Ā',\n",
       " 1: 'ā',\n",
       " 2: 'Ă',\n",
       " 3: 'ă',\n",
       " 4: 'Ą',\n",
       " 5: 'ą',\n",
       " 6: 'Ć',\n",
       " 7: 'ć',\n",
       " 8: 'Ĉ',\n",
       " 9: 'ĉ',\n",
       " 10: 'Ċ',\n",
       " 11: 'ċ',\n",
       " 12: 'Č',\n",
       " 13: 'č',\n",
       " 14: 'Ď',\n",
       " 15: 'ď',\n",
       " 16: 'Đ',\n",
       " 17: 'đ',\n",
       " 18: 'Ē',\n",
       " 19: 'ē',\n",
       " 20: 'Ĕ',\n",
       " 21: 'ĕ',\n",
       " 22: 'Ė',\n",
       " 23: 'ė',\n",
       " 24: 'Ę',\n",
       " 25: 'ę',\n",
       " 26: 'Ě',\n",
       " 27: 'ě',\n",
       " 28: 'Ĝ',\n",
       " 29: 'ĝ',\n",
       " 30: 'Ğ',\n",
       " 31: 'ğ',\n",
       " 32: 'Ġ',\n",
       " 127: 'ġ',\n",
       " 128: 'Ģ',\n",
       " 129: 'ģ',\n",
       " 130: 'Ĥ',\n",
       " 131: 'ĥ',\n",
       " 132: 'Ħ',\n",
       " 133: 'ħ',\n",
       " 134: 'Ĩ',\n",
       " 135: 'ĩ',\n",
       " 136: 'Ī',\n",
       " 137: 'ī',\n",
       " 138: 'Ĭ',\n",
       " 139: 'ĭ',\n",
       " 140: 'Į',\n",
       " 141: 'į',\n",
       " 142: 'İ',\n",
       " 143: 'ı',\n",
       " 144: 'Ĳ',\n",
       " 145: 'ĳ',\n",
       " 146: 'Ĵ',\n",
       " 147: 'ĵ',\n",
       " 148: 'Ķ',\n",
       " 149: 'ķ',\n",
       " 150: 'ĸ',\n",
       " 151: 'Ĺ',\n",
       " 152: 'ĺ',\n",
       " 153: 'Ļ',\n",
       " 154: 'ļ',\n",
       " 155: 'Ľ',\n",
       " 156: 'ľ',\n",
       " 157: 'Ŀ',\n",
       " 158: 'ŀ',\n",
       " 159: 'Ł',\n",
       " 160: 'ł',\n",
       " 173: 'Ń'}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_bytes_to_unicode()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test different models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_kwargs = {\n",
    "    \"_attn_implementation\": \"eager\", # Uncomment this line if flash attention is not working\n",
    "    \"trust_remote_code\": True,\n",
    "}\n",
    "PHI_3_MINI_MODEL = \"microsoft/Phi-3-mini-4k-instruct\"\n",
    "PHI_3_SMALL_MODEL = \"microsoft/Phi-3-small-8k-instruct\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`flash-attention` package not found, consider installing for better performance: No module named 'flash_attn'.\n",
      "Current `flash-attention` does not support `window_size`. Either upgrade or use `attn_implementation='eager'`.\n",
      "Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.30s/it]\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "# Phi 3 mini\n",
    "model = models.Transformers(\n",
    "    model=PHI_3_MINI_MODEL, **model_kwargs\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "Flash Attention is not available, but is needed for dense attention",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 7\u001b[0m\n\u001b[1;32m      2\u001b[0m model_kwargs \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m      3\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_attn_implementation\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124meager\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;66;03m# Uncomment this line if flash attention is not working\u001b[39;00m\n\u001b[1;32m      4\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrust_remote_code\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m      5\u001b[0m }\n\u001b[1;32m      6\u001b[0m PHI_3_SMALL_MODEL \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmicrosoft/Phi-3-small-8k-instruct\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m----> 7\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mmodels\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTransformers\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmicrosoft/Phi-3-small-8k-instruct\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmodel_kwargs\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/code/ms/guidance/guidance/models/transformers/_transformers.py:431\u001b[0m, in \u001b[0;36mTransformers.__init__\u001b[0;34m(self, model, tokenizer, echo, compute_log_probs, chat_template, **kwargs)\u001b[0m\n\u001b[1;32m    420\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\n\u001b[1;32m    421\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    422\u001b[0m     model\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    427\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m    428\u001b[0m ):\n\u001b[1;32m    429\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Build a new Transformers model object that represents a model in a given state.\"\"\"\u001b[39;00m\n\u001b[1;32m    430\u001b[0m     \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(\n\u001b[0;32m--> 431\u001b[0m         \u001b[43mTransformersEngine\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    432\u001b[0m \u001b[43m            \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    433\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtokenizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    434\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcompute_log_probs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    435\u001b[0m \u001b[43m            \u001b[49m\u001b[43mchat_template\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchat_template\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    436\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    437\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m,\n\u001b[1;32m    438\u001b[0m         echo\u001b[38;5;241m=\u001b[39mecho,\n\u001b[1;32m    439\u001b[0m     )\n",
      "File \u001b[0;32m~/code/ms/guidance/guidance/models/transformers/_transformers.py:285\u001b[0m, in \u001b[0;36mTransformersEngine.__init__\u001b[0;34m(self, model, tokenizer, compute_log_probs, chat_template, **kwargs)\u001b[0m\n\u001b[1;32m    282\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[1;32m    283\u001b[0m         \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[0;32m--> 285\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel_obj \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    287\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(model, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m    288\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\n",
      "File \u001b[0;32m~/code/ms/guidance/guidance/models/transformers/_transformers.py:327\u001b[0m, in \u001b[0;36mTransformersEngine._model\u001b[0;34m(self, model, **kwargs)\u001b[0m\n\u001b[1;32m    323\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m has_transformers:\n\u001b[1;32m    324\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m(\n\u001b[1;32m    325\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPlease install transformers with `pip install transformers` in order to use guidance.models.Transformers!\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    326\u001b[0m         )\n\u001b[0;32m--> 327\u001b[0m     model \u001b[38;5;241m=\u001b[39m \u001b[43mtransformers_package\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mAutoModelForCausalLM\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    328\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m model\n",
      "File \u001b[0;32m~/code/ms/guidance/env/lib/python3.10/site-packages/transformers/models/auto/auto_factory.py:558\u001b[0m, in \u001b[0;36m_BaseAutoModelClass.from_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, *model_args, **kwargs)\u001b[0m\n\u001b[1;32m    556\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    557\u001b[0m         \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39mregister(config\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m, model_class, exist_ok\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m--> 558\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmodel_class\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    559\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpretrained_model_name_or_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmodel_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mhub_kwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    560\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    561\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(config) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_model_mapping\u001b[38;5;241m.\u001b[39mkeys():\n\u001b[1;32m    562\u001b[0m     model_class \u001b[38;5;241m=\u001b[39m _get_model_class(config, \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_model_mapping)\n",
      "File \u001b[0;32m~/code/ms/guidance/env/lib/python3.10/site-packages/transformers/modeling_utils.py:3626\u001b[0m, in \u001b[0;36mPreTrainedModel.from_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, config, cache_dir, ignore_mismatched_sizes, force_download, local_files_only, token, revision, use_safetensors, *model_args, **kwargs)\u001b[0m\n\u001b[1;32m   3620\u001b[0m config \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_autoset_attn_implementation(\n\u001b[1;32m   3621\u001b[0m     config, use_flash_attention_2\u001b[38;5;241m=\u001b[39muse_flash_attention_2, torch_dtype\u001b[38;5;241m=\u001b[39mtorch_dtype, device_map\u001b[38;5;241m=\u001b[39mdevice_map\n\u001b[1;32m   3622\u001b[0m )\n\u001b[1;32m   3624\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m ContextManagers(init_contexts):\n\u001b[1;32m   3625\u001b[0m     \u001b[38;5;66;03m# Let's make sure we don't run the init function of buffer modules\u001b[39;00m\n\u001b[0;32m-> 3626\u001b[0m     model \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmodel_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmodel_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3628\u001b[0m \u001b[38;5;66;03m# make sure we use the model's config since the __init__ call might have copied it\u001b[39;00m\n\u001b[1;32m   3629\u001b[0m config \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mconfig\n",
      "File \u001b[0;32m~/.cache/huggingface/modules/transformers_modules/microsoft/Phi-3-small-8k-instruct/69caae1f2acea34b26f535fecb1f2abb9a304695/modeling_phi3_small.py:903\u001b[0m, in \u001b[0;36mPhi3SmallForCausalLM.__init__\u001b[0;34m(self, config)\u001b[0m\n\u001b[1;32m    901\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, config):\n\u001b[1;32m    902\u001b[0m     \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(config)\n\u001b[0;32m--> 903\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel \u001b[38;5;241m=\u001b[39m \u001b[43mPhi3SmallModel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    904\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvocab_size \u001b[38;5;241m=\u001b[39m config\u001b[38;5;241m.\u001b[39mvocab_size\n\u001b[1;32m    905\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlm_head \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mLinear(config\u001b[38;5;241m.\u001b[39mhidden_size, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvocab_size, bias\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "File \u001b[0;32m~/.cache/huggingface/modules/transformers_modules/microsoft/Phi-3-small-8k-instruct/69caae1f2acea34b26f535fecb1f2abb9a304695/modeling_phi3_small.py:745\u001b[0m, in \u001b[0;36mPhi3SmallModel.__init__\u001b[0;34m(self, config)\u001b[0m\n\u001b[1;32m    742\u001b[0m \u001b[38;5;66;03m# MuP Embedding scaling\u001b[39;00m\n\u001b[1;32m    743\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmup_embedding_multiplier \u001b[38;5;241m=\u001b[39m config\u001b[38;5;241m.\u001b[39mmup_embedding_multiplier\n\u001b[0;32m--> 745\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayers \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mModuleList([Phi3SmallDecoderLayer(config, layer_idx) \u001b[38;5;28;01mfor\u001b[39;00m layer_idx \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(config\u001b[38;5;241m.\u001b[39mnum_hidden_layers)])\n\u001b[1;32m    747\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfinal_layernorm \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mLayerNorm(config\u001b[38;5;241m.\u001b[39mhidden_size, eps\u001b[38;5;241m=\u001b[39mconfig\u001b[38;5;241m.\u001b[39mlayer_norm_epsilon)\n\u001b[1;32m    749\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgradient_checkpointing \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "File \u001b[0;32m~/.cache/huggingface/modules/transformers_modules/microsoft/Phi-3-small-8k-instruct/69caae1f2acea34b26f535fecb1f2abb9a304695/modeling_phi3_small.py:745\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    742\u001b[0m \u001b[38;5;66;03m# MuP Embedding scaling\u001b[39;00m\n\u001b[1;32m    743\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmup_embedding_multiplier \u001b[38;5;241m=\u001b[39m config\u001b[38;5;241m.\u001b[39mmup_embedding_multiplier\n\u001b[0;32m--> 745\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayers \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mModuleList([\u001b[43mPhi3SmallDecoderLayer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlayer_idx\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m layer_idx \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(config\u001b[38;5;241m.\u001b[39mnum_hidden_layers)])\n\u001b[1;32m    747\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfinal_layernorm \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mLayerNorm(config\u001b[38;5;241m.\u001b[39mhidden_size, eps\u001b[38;5;241m=\u001b[39mconfig\u001b[38;5;241m.\u001b[39mlayer_norm_epsilon)\n\u001b[1;32m    749\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgradient_checkpointing \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "File \u001b[0;32m~/.cache/huggingface/modules/transformers_modules/microsoft/Phi-3-small-8k-instruct/69caae1f2acea34b26f535fecb1f2abb9a304695/modeling_phi3_small.py:651\u001b[0m, in \u001b[0;36mPhi3SmallDecoderLayer.__init__\u001b[0;34m(self, config, layer_idx)\u001b[0m\n\u001b[1;32m    649\u001b[0m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m()\n\u001b[1;32m    650\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhidden_size \u001b[38;5;241m=\u001b[39m config\u001b[38;5;241m.\u001b[39mhidden_size\n\u001b[0;32m--> 651\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mself_attn \u001b[38;5;241m=\u001b[39m \u001b[43mPhi3SmallSelfAttention\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlayer_idx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    652\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmlp \u001b[38;5;241m=\u001b[39m Phi3SmallMLP(config)\n\u001b[1;32m    654\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minput_layernorm \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mLayerNorm(config\u001b[38;5;241m.\u001b[39mhidden_size, eps\u001b[38;5;241m=\u001b[39mconfig\u001b[38;5;241m.\u001b[39mlayer_norm_epsilon)\n",
      "File \u001b[0;32m~/.cache/huggingface/modules/transformers_modules/microsoft/Phi-3-small-8k-instruct/69caae1f2acea34b26f535fecb1f2abb9a304695/modeling_phi3_small.py:218\u001b[0m, in \u001b[0;36mPhi3SmallSelfAttention.__init__\u001b[0;34m(self, config, layer_idx)\u001b[0m\n\u001b[1;32m    213\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mdense_attention_every_n_layers \u001b[38;5;129;01mand\u001b[39;00m ((\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayer_idx \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m%\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mdense_attention_every_n_layers \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m):\n\u001b[1;32m    214\u001b[0m     logger\u001b[38;5;241m.\u001b[39minfo(\n\u001b[1;32m    215\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLayer \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlayer_idx\u001b[38;5;250m \u001b[39m\u001b[38;5;241m+\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m is using dense attention since it is divisible by \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    216\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mdense_attention_every_n_layers\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    217\u001b[0m     )\n\u001b[0;32m--> 218\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m is_flash_attention_available, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFlash Attention is not available, but is needed for dense attention\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    219\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    220\u001b[0m     \u001b[38;5;66;03m# BlockSparse related Parameters\u001b[39;00m\n\u001b[1;32m    221\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mblocksparse_params \u001b[38;5;241m=\u001b[39m BlockSparseParams\u001b[38;5;241m.\u001b[39mfrom_config(config)\n",
      "\u001b[0;31mAssertionError\u001b[0m: Flash Attention is not available, but is needed for dense attention"
     ]
    }
   ],
   "source": [
    "model = models.Transformers(\n",
    "    model=PHI_3_SMALL_MODEL, **model_kwargs\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import transformers as transformers_package\n",
    "\n",
    "def _tokenizer(model, **kwargs):\n",
    "    # intantiate the tokenizer\n",
    "    if isinstance(model, str):\n",
    "        # make sure transformers is installed\n",
    "        try:\n",
    "            tokenizer = transformers_package.AutoTokenizer.from_pretrained(\n",
    "                model, use_fast=False, **kwargs\n",
    "            )\n",
    "            # This is here because some tokenizers are bad and don't have all the bytes (I'm looking at you, microsoft/phi2)\n",
    "            if hasattr(tokenizer, \"byte_decoder\"):\n",
    "                all_bytes = set()\n",
    "                for x in tokenizer.get_vocab().keys():\n",
    "                    for y in x:\n",
    "                        all_bytes.add(y)\n",
    "                assert set(tokenizer.byte_decoder.keys()).intersection(all_bytes) == all_bytes\n",
    "        except:\n",
    "            tokenizer = transformers_package.AutoTokenizer.from_pretrained(\n",
    "                model, use_fast=True, **kwargs\n",
    "            )  # fall back to the fast tokenizer\n",
    "\n",
    "    assert (\n",
    "        tokenizer is not None\n",
    "    ), \"You must give a model name when you provide a tokenizer object!\"\n",
    "\n",
    "    return tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "phi3mini_tok = _tokenizer(PHI_3_MINI_MODEL, **model_kwargs)\n",
    "phi3small_tok = _tokenizer(PHI_3_SMALL_MODEL, **model_kwargs)\n",
    "phi3vision_tok = _tokenizer(PHI_3_VISION_MODEL, **model_kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LlamaTokenizer(name_or_path='microsoft/Phi-3-mini-4k-instruct', vocab_size=32000, model_max_length=4096, is_fast=False, padding_side='left', truncation_side='right', special_tokens={'bos_token': '<s>', 'eos_token': '<|endoftext|>', 'unk_token': '<unk>', 'pad_token': '<|endoftext|>'}, clean_up_tokenization_spaces=False),  added_tokens_decoder={\n",
       "\t0: AddedToken(\"<unk>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t1: AddedToken(\"<s>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t2: AddedToken(\"</s>\", rstrip=True, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t32000: AddedToken(\"<|endoftext|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t32001: AddedToken(\"<|assistant|>\", rstrip=True, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t32002: AddedToken(\"<|placeholder1|>\", rstrip=True, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t32003: AddedToken(\"<|placeholder2|>\", rstrip=True, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t32004: AddedToken(\"<|placeholder3|>\", rstrip=True, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t32005: AddedToken(\"<|placeholder4|>\", rstrip=True, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t32006: AddedToken(\"<|system|>\", rstrip=True, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t32007: AddedToken(\"<|end|>\", rstrip=True, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t32008: AddedToken(\"<|placeholder5|>\", rstrip=True, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t32009: AddedToken(\"<|placeholder6|>\", rstrip=True, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t32010: AddedToken(\"<|user|>\", rstrip=True, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "phi3mini_tok"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Phi3SmallTokenizer(name_or_path='', vocab_size=100352, model_max_length=8192, is_fast=False, padding_side='left', truncation_side='right', special_tokens={'bos_token': '<|endoftext|>', 'eos_token': '<|endoftext|>', 'pad_token': '<|endoftext|>'}, clean_up_tokenization_spaces=True),  added_tokens_decoder={\n",
       "\t\n",
       "}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "phi3small_tok"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LlamaTokenizerFast(name_or_path='microsoft/Phi-3-vision-128k-instruct', vocab_size=32000, model_max_length=131072, is_fast=True, padding_side='right', truncation_side='right', special_tokens={'bos_token': '<s>', 'eos_token': '<|endoftext|>', 'unk_token': '<unk>', 'pad_token': '<|endoftext|>', 'additional_special_tokens': ['<|system|>', '<|end|>', '<|user|>', '<|end|>']}, clean_up_tokenization_spaces=False),  added_tokens_decoder={\n",
       "\t0: AddedToken(\"<unk>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t1: AddedToken(\"<s>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t2: AddedToken(\"</s>\", rstrip=True, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t32000: AddedToken(\"<|endoftext|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t32001: AddedToken(\"<|assistant|>\", rstrip=True, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t32002: AddedToken(\"<|placeholder1|>\", rstrip=True, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t32003: AddedToken(\"<|placeholder2|>\", rstrip=True, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t32004: AddedToken(\"<|placeholder3|>\", rstrip=True, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t32005: AddedToken(\"<|placeholder4|>\", rstrip=True, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t32006: AddedToken(\"<|system|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t32007: AddedToken(\"<|end|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t32008: AddedToken(\"<|placeholder5|>\", rstrip=True, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t32009: AddedToken(\"<|placeholder6|>\", rstrip=True, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t32010: AddedToken(\"<|user|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t32011: AddedToken(\"<|placeholder7|>\", rstrip=True, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t32012: AddedToken(\"<|placeholder8|>\", rstrip=True, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t32013: AddedToken(\"<|placeholder9|>\", rstrip=True, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t32014: AddedToken(\"<|placeholder10|>\", rstrip=True, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t32015: AddedToken(\"<|placeholder11|>\", rstrip=True, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t32016: AddedToken(\"<|placeholder12|>\", rstrip=True, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t32017: AddedToken(\"<|placeholder13|>\", rstrip=True, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t32018: AddedToken(\"<|placeholder14|>\", rstrip=True, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t32019: AddedToken(\"<|placeholder15|>\", rstrip=True, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t32020: AddedToken(\"<|placeholder16|>\", rstrip=True, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t32021: AddedToken(\"<|placeholder17|>\", rstrip=True, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t32022: AddedToken(\"<|placeholder18|>\", rstrip=True, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t32023: AddedToken(\"<|placeholder19|>\", rstrip=True, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t32024: AddedToken(\"<|placeholder20|>\", rstrip=True, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t32025: AddedToken(\"<|placeholder21|>\", rstrip=True, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t32026: AddedToken(\"<|placeholder22|>\", rstrip=True, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t32027: AddedToken(\"<|placeholder23|>\", rstrip=True, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t32028: AddedToken(\"<|placeholder24|>\", rstrip=True, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t32029: AddedToken(\"<|placeholder25|>\", rstrip=True, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t32030: AddedToken(\"<|placeholder26|>\", rstrip=True, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t32031: AddedToken(\"<|placeholder27|>\", rstrip=True, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t32032: AddedToken(\"<|placeholder28|>\", rstrip=True, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t32033: AddedToken(\"<|placeholder29|>\", rstrip=True, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t32034: AddedToken(\"<|placeholder30|>\", rstrip=True, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t32035: AddedToken(\"<|placeholder31|>\", rstrip=True, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t32036: AddedToken(\"<|placeholder32|>\", rstrip=True, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t32037: AddedToken(\"<|placeholder33|>\", rstrip=True, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t32038: AddedToken(\"<|placeholder34|>\", rstrip=True, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t32039: AddedToken(\"<|placeholder35|>\", rstrip=True, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t32040: AddedToken(\"<|placeholder36|>\", rstrip=True, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t32041: AddedToken(\"<|placeholder37|>\", rstrip=True, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t32042: AddedToken(\"<|placeholder38|>\", rstrip=True, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t32043: AddedToken(\"<|placeholder39|>\", rstrip=True, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t32044: AddedToken(\"<|image|>\", rstrip=True, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "phi3vision_tok"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "mini_vocab = phi3mini_tok.get_vocab()\n",
    "small_vocab = phi3small_tok.get_vocab()\n",
    "vision_vocab = phi3vision_tok.get_vocab()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'<unk>': 0,\n",
       " '<s>': 1,\n",
       " '</s>': 2,\n",
       " '<0x00>': 3,\n",
       " '<0x01>': 4,\n",
       " '<0x02>': 5,\n",
       " '<0x03>': 6,\n",
       " '<0x04>': 7,\n",
       " '<0x05>': 8,\n",
       " '<0x06>': 9,\n",
       " '<0x07>': 10,\n",
       " '<0x08>': 11,\n",
       " '<0x09>': 12,\n",
       " '<0x0A>': 13,\n",
       " '<0x0B>': 14,\n",
       " '<0x0C>': 15,\n",
       " '<0x0D>': 16,\n",
       " '<0x0E>': 17,\n",
       " '<0x0F>': 18,\n",
       " '<0x10>': 19,\n",
       " '<0x11>': 20,\n",
       " '<0x12>': 21,\n",
       " '<0x13>': 22,\n",
       " '<0x14>': 23,\n",
       " '<0x15>': 24,\n",
       " '<0x16>': 25,\n",
       " '<0x17>': 26,\n",
       " '<0x18>': 27,\n",
       " '<0x19>': 28,\n",
       " '<0x1A>': 29,\n",
       " '<0x1B>': 30,\n",
       " '<0x1C>': 31,\n",
       " '<0x1D>': 32,\n",
       " '<0x1E>': 33,\n",
       " '<0x1F>': 34,\n",
       " '<0x20>': 35,\n",
       " '<0x21>': 36,\n",
       " '<0x22>': 37,\n",
       " '<0x23>': 38,\n",
       " '<0x24>': 39,\n",
       " '<0x25>': 40,\n",
       " '<0x26>': 41,\n",
       " '<0x27>': 42,\n",
       " '<0x28>': 43,\n",
       " '<0x29>': 44,\n",
       " '<0x2A>': 45,\n",
       " '<0x2B>': 46,\n",
       " '<0x2C>': 47,\n",
       " '<0x2D>': 48,\n",
       " '<0x2E>': 49,\n",
       " '<0x2F>': 50,\n",
       " '<0x30>': 51,\n",
       " '<0x31>': 52,\n",
       " '<0x32>': 53,\n",
       " '<0x33>': 54,\n",
       " '<0x34>': 55,\n",
       " '<0x35>': 56,\n",
       " '<0x36>': 57,\n",
       " '<0x37>': 58,\n",
       " '<0x38>': 59,\n",
       " '<0x39>': 60,\n",
       " '<0x3A>': 61,\n",
       " '<0x3B>': 62,\n",
       " '<0x3C>': 63,\n",
       " '<0x3D>': 64,\n",
       " '<0x3E>': 65,\n",
       " '<0x3F>': 66,\n",
       " '<0x40>': 67,\n",
       " '<0x41>': 68,\n",
       " '<0x42>': 69,\n",
       " '<0x43>': 70,\n",
       " '<0x44>': 71,\n",
       " '<0x45>': 72,\n",
       " '<0x46>': 73,\n",
       " '<0x47>': 74,\n",
       " '<0x48>': 75,\n",
       " '<0x49>': 76,\n",
       " '<0x4A>': 77,\n",
       " '<0x4B>': 78,\n",
       " '<0x4C>': 79,\n",
       " '<0x4D>': 80,\n",
       " '<0x4E>': 81,\n",
       " '<0x4F>': 82,\n",
       " '<0x50>': 83,\n",
       " '<0x51>': 84,\n",
       " '<0x52>': 85,\n",
       " '<0x53>': 86,\n",
       " '<0x54>': 87,\n",
       " '<0x55>': 88,\n",
       " '<0x56>': 89,\n",
       " '<0x57>': 90,\n",
       " '<0x58>': 91,\n",
       " '<0x59>': 92,\n",
       " '<0x5A>': 93,\n",
       " '<0x5B>': 94,\n",
       " '<0x5C>': 95,\n",
       " '<0x5D>': 96,\n",
       " '<0x5E>': 97,\n",
       " '<0x5F>': 98,\n",
       " '<0x60>': 99,\n",
       " '<0x61>': 100,\n",
       " '<0x62>': 101,\n",
       " '<0x63>': 102,\n",
       " '<0x64>': 103,\n",
       " '<0x65>': 104,\n",
       " '<0x66>': 105,\n",
       " '<0x67>': 106,\n",
       " '<0x68>': 107,\n",
       " '<0x69>': 108,\n",
       " '<0x6A>': 109,\n",
       " '<0x6B>': 110,\n",
       " '<0x6C>': 111,\n",
       " '<0x6D>': 112,\n",
       " '<0x6E>': 113,\n",
       " '<0x6F>': 114,\n",
       " '<0x70>': 115,\n",
       " '<0x71>': 116,\n",
       " '<0x72>': 117,\n",
       " '<0x73>': 118,\n",
       " '<0x74>': 119,\n",
       " '<0x75>': 120,\n",
       " '<0x76>': 121,\n",
       " '<0x77>': 122,\n",
       " '<0x78>': 123,\n",
       " '<0x79>': 124,\n",
       " '<0x7A>': 125,\n",
       " '<0x7B>': 126,\n",
       " '<0x7C>': 127,\n",
       " '<0x7D>': 128,\n",
       " '<0x7E>': 129,\n",
       " '<0x7F>': 130,\n",
       " '<0x80>': 131,\n",
       " '<0x81>': 132,\n",
       " '<0x82>': 133,\n",
       " '<0x83>': 134,\n",
       " '<0x84>': 135,\n",
       " '<0x85>': 136,\n",
       " '<0x86>': 137,\n",
       " '<0x87>': 138,\n",
       " '<0x88>': 139,\n",
       " '<0x89>': 140,\n",
       " '<0x8A>': 141,\n",
       " '<0x8B>': 142,\n",
       " '<0x8C>': 143,\n",
       " '<0x8D>': 144,\n",
       " '<0x8E>': 145,\n",
       " '<0x8F>': 146,\n",
       " '<0x90>': 147,\n",
       " '<0x91>': 148,\n",
       " '<0x92>': 149,\n",
       " '<0x93>': 150,\n",
       " '<0x94>': 151,\n",
       " '<0x95>': 152,\n",
       " '<0x96>': 153,\n",
       " '<0x97>': 154,\n",
       " '<0x98>': 155,\n",
       " '<0x99>': 156,\n",
       " '<0x9A>': 157,\n",
       " '<0x9B>': 158,\n",
       " '<0x9C>': 159,\n",
       " '<0x9D>': 160,\n",
       " '<0x9E>': 161,\n",
       " '<0x9F>': 162,\n",
       " '<0xA0>': 163,\n",
       " '<0xA1>': 164,\n",
       " '<0xA2>': 165,\n",
       " '<0xA3>': 166,\n",
       " '<0xA4>': 167,\n",
       " '<0xA5>': 168,\n",
       " '<0xA6>': 169,\n",
       " '<0xA7>': 170,\n",
       " '<0xA8>': 171,\n",
       " '<0xA9>': 172,\n",
       " '<0xAA>': 173,\n",
       " '<0xAB>': 174,\n",
       " '<0xAC>': 175,\n",
       " '<0xAD>': 176,\n",
       " '<0xAE>': 177,\n",
       " '<0xAF>': 178,\n",
       " '<0xB0>': 179,\n",
       " '<0xB1>': 180,\n",
       " '<0xB2>': 181,\n",
       " '<0xB3>': 182,\n",
       " '<0xB4>': 183,\n",
       " '<0xB5>': 184,\n",
       " '<0xB6>': 185,\n",
       " '<0xB7>': 186,\n",
       " '<0xB8>': 187,\n",
       " '<0xB9>': 188,\n",
       " '<0xBA>': 189,\n",
       " '<0xBB>': 190,\n",
       " '<0xBC>': 191,\n",
       " '<0xBD>': 192,\n",
       " '<0xBE>': 193,\n",
       " '<0xBF>': 194,\n",
       " '<0xC0>': 195,\n",
       " '<0xC1>': 196,\n",
       " '<0xC2>': 197,\n",
       " '<0xC3>': 198,\n",
       " '<0xC4>': 199,\n",
       " '<0xC5>': 200,\n",
       " '<0xC6>': 201,\n",
       " '<0xC7>': 202,\n",
       " '<0xC8>': 203,\n",
       " '<0xC9>': 204,\n",
       " '<0xCA>': 205,\n",
       " '<0xCB>': 206,\n",
       " '<0xCC>': 207,\n",
       " '<0xCD>': 208,\n",
       " '<0xCE>': 209,\n",
       " '<0xCF>': 210,\n",
       " '<0xD0>': 211,\n",
       " '<0xD1>': 212,\n",
       " '<0xD2>': 213,\n",
       " '<0xD3>': 214,\n",
       " '<0xD4>': 215,\n",
       " '<0xD5>': 216,\n",
       " '<0xD6>': 217,\n",
       " '<0xD7>': 218,\n",
       " '<0xD8>': 219,\n",
       " '<0xD9>': 220,\n",
       " '<0xDA>': 221,\n",
       " '<0xDB>': 222,\n",
       " '<0xDC>': 223,\n",
       " '<0xDD>': 224,\n",
       " '<0xDE>': 225,\n",
       " '<0xDF>': 226,\n",
       " '<0xE0>': 227,\n",
       " '<0xE1>': 228,\n",
       " '<0xE2>': 229,\n",
       " '<0xE3>': 230,\n",
       " '<0xE4>': 231,\n",
       " '<0xE5>': 232,\n",
       " '<0xE6>': 233,\n",
       " '<0xE7>': 234,\n",
       " '<0xE8>': 235,\n",
       " '<0xE9>': 236,\n",
       " '<0xEA>': 237,\n",
       " '<0xEB>': 238,\n",
       " '<0xEC>': 239,\n",
       " '<0xED>': 240,\n",
       " '<0xEE>': 241,\n",
       " '<0xEF>': 242,\n",
       " '<0xF0>': 243,\n",
       " '<0xF1>': 244,\n",
       " '<0xF2>': 245,\n",
       " '<0xF3>': 246,\n",
       " '<0xF4>': 247,\n",
       " '<0xF5>': 248,\n",
       " '<0xF6>': 249,\n",
       " '<0xF7>': 250,\n",
       " '<0xF8>': 251,\n",
       " '<0xF9>': 252,\n",
       " '<0xFA>': 253,\n",
       " '<0xFB>': 254,\n",
       " '<0xFC>': 255,\n",
       " '<0xFD>': 256,\n",
       " '<0xFE>': 257,\n",
       " '<0xFF>': 258,\n",
       " '▁▁': 259,\n",
       " '▁t': 260,\n",
       " 'er': 261,\n",
       " 'in': 262,\n",
       " '▁a': 263,\n",
       " 'en': 264,\n",
       " 'on': 265,\n",
       " '▁th': 266,\n",
       " 'es': 267,\n",
       " '▁▁▁▁': 268,\n",
       " '▁s': 269,\n",
       " '▁d': 270,\n",
       " 'at': 271,\n",
       " 'or': 272,\n",
       " 'an': 273,\n",
       " '▁c': 274,\n",
       " 'is': 275,\n",
       " 're': 276,\n",
       " 'it': 277,\n",
       " '▁the': 278,\n",
       " 'ar': 279,\n",
       " 'le': 280,\n",
       " '▁w': 281,\n",
       " '▁p': 282,\n",
       " 'ou': 283,\n",
       " 'al': 284,\n",
       " '▁f': 285,\n",
       " '▁m': 286,\n",
       " 'ed': 287,\n",
       " '▁o': 288,\n",
       " '▁b': 289,\n",
       " 'om': 290,\n",
       " 'ion': 291,\n",
       " 'ing': 292,\n",
       " 'ic': 293,\n",
       " 'as': 294,\n",
       " 'el': 295,\n",
       " 'ent': 296,\n",
       " '▁in': 297,\n",
       " '▁h': 298,\n",
       " 'nd': 299,\n",
       " 'et': 300,\n",
       " '▁l': 301,\n",
       " '▁n': 302,\n",
       " 'st': 303,\n",
       " '▁to': 304,\n",
       " 'ch': 305,\n",
       " '▁I': 306,\n",
       " 'ro': 307,\n",
       " '▁▁▁▁▁▁▁▁': 308,\n",
       " 'il': 309,\n",
       " '▁of': 310,\n",
       " 'de': 311,\n",
       " 'ct': 312,\n",
       " '▁(': 313,\n",
       " 'am': 314,\n",
       " '▁C': 315,\n",
       " '▁de': 316,\n",
       " '▁S': 317,\n",
       " '▁u': 318,\n",
       " '▁A': 319,\n",
       " '▁\\\\': 320,\n",
       " '▁e': 321,\n",
       " '▁and': 322,\n",
       " '▁T': 323,\n",
       " 'ol': 324,\n",
       " '▁v': 325,\n",
       " 'im': 326,\n",
       " 'ot': 327,\n",
       " 'ad': 328,\n",
       " 'ut': 329,\n",
       " '▁g': 330,\n",
       " 'em': 331,\n",
       " 'ur': 332,\n",
       " 'id': 333,\n",
       " '▁*': 334,\n",
       " 'ig': 335,\n",
       " 'ra': 336,\n",
       " '▁re': 337,\n",
       " '▁is': 338,\n",
       " 'qu': 339,\n",
       " 'ow': 340,\n",
       " '▁M': 341,\n",
       " 'est': 342,\n",
       " '▁y': 343,\n",
       " 'se': 344,\n",
       " 've': 345,\n",
       " 'ce': 346,\n",
       " 'ie': 347,\n",
       " 'un': 348,\n",
       " '▁P': 349,\n",
       " '▁B': 350,\n",
       " 'ag': 351,\n",
       " 'ul': 352,\n",
       " '▁=': 353,\n",
       " 'he': 354,\n",
       " 'end': 355,\n",
       " 'ode': 356,\n",
       " 'ter': 357,\n",
       " 'ment': 358,\n",
       " 'os': 359,\n",
       " '▁D': 360,\n",
       " 'if': 361,\n",
       " 'ation': 362,\n",
       " '▁for': 363,\n",
       " '▁r': 364,\n",
       " '▁L': 365,\n",
       " '▁you': 366,\n",
       " '▁be': 367,\n",
       " 'ly': 368,\n",
       " 'ver': 369,\n",
       " 'ab': 370,\n",
       " 'te': 371,\n",
       " '▁it': 372,\n",
       " '▁on': 373,\n",
       " 'ri': 374,\n",
       " 'us': 375,\n",
       " '▁\"': 376,\n",
       " '▁wh': 377,\n",
       " '▁con': 378,\n",
       " '▁H': 379,\n",
       " '▁st': 380,\n",
       " 'ir': 381,\n",
       " '▁E': 382,\n",
       " '▁F': 383,\n",
       " 'ck': 384,\n",
       " '▁an': 385,\n",
       " 'th': 386,\n",
       " 'eg': 387,\n",
       " 'ay': 388,\n",
       " 'ith': 389,\n",
       " '▁R': 390,\n",
       " 'ist': 391,\n",
       " 'and': 392,\n",
       " '▁that': 393,\n",
       " '▁al': 394,\n",
       " '▁$': 395,\n",
       " '▁#': 396,\n",
       " 'od': 397,\n",
       " 'um': 398,\n",
       " '▁W': 399,\n",
       " 'ht': 400,\n",
       " 'code': 401,\n",
       " '▁G': 402,\n",
       " 'ate': 403,\n",
       " 'ess': 404,\n",
       " '▁N': 405,\n",
       " 'ere': 406,\n",
       " 'pp': 407,\n",
       " '▁as': 408,\n",
       " '▁se': 409,\n",
       " '▁pro': 410,\n",
       " '▁with': 411,\n",
       " 'pe': 412,\n",
       " '▁k': 413,\n",
       " 'ers': 414,\n",
       " 'pt': 415,\n",
       " ');': 416,\n",
       " 'lo': 417,\n",
       " '▁▁▁▁▁': 418,\n",
       " '▁com': 419,\n",
       " 'ame': 420,\n",
       " '▁`': 421,\n",
       " '▁Com': 422,\n",
       " 'ia': 423,\n",
       " 'ant': 424,\n",
       " '▁la': 425,\n",
       " '▁{': 426,\n",
       " '▁en': 427,\n",
       " 'ction': 428,\n",
       " '▁ex': 429,\n",
       " 'ld': 430,\n",
       " 'ub': 431,\n",
       " '▁j': 432,\n",
       " 'la': 433,\n",
       " 'ue': 434,\n",
       " '▁J': 435,\n",
       " 'ich': 436,\n",
       " '▁do': 437,\n",
       " '▁O': 438,\n",
       " '▁qu': 439,\n",
       " 'iv': 440,\n",
       " 'ort': 441,\n",
       " 'art': 442,\n",
       " '▁un': 443,\n",
       " '▁##': 444,\n",
       " '▁this': 445,\n",
       " 'ke': 446,\n",
       " '▁ha': 447,\n",
       " '▁-': 448,\n",
       " 'out': 449,\n",
       " '▁The': 450,\n",
       " '▁not': 451,\n",
       " '▁ne': 452,\n",
       " 'ill': 453,\n",
       " '▁le': 454,\n",
       " 'ci': 455,\n",
       " 'rom': 456,\n",
       " 'ine': 457,\n",
       " '//': 458,\n",
       " 'op': 459,\n",
       " 'egin': 460,\n",
       " '▁Comment': 461,\n",
       " '▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁': 462,\n",
       " 'begin': 463,\n",
       " 'ст': 464,\n",
       " 'ass': 465,\n",
       " 'iz': 466,\n",
       " ').': 467,\n",
       " 'og': 468,\n",
       " '▁п': 469,\n",
       " '▁or': 470,\n",
       " '▁was': 471,\n",
       " '▁at': 472,\n",
       " 'our': 473,\n",
       " '▁i': 474,\n",
       " 'ain': 475,\n",
       " '▁K': 476,\n",
       " 'на': 477,\n",
       " '▁V': 478,\n",
       " 'ge': 479,\n",
       " '▁su': 480,\n",
       " 'ap': 481,\n",
       " 'age': 482,\n",
       " 'ould': 483,\n",
       " 'ne': 484,\n",
       " 'av': 485,\n",
       " 'xt': 486,\n",
       " 'ore': 487,\n",
       " 'ile': 488,\n",
       " '--': 489,\n",
       " '▁в': 490,\n",
       " '▁by': 491,\n",
       " 'li': 492,\n",
       " 'ath': 493,\n",
       " 'ра': 494,\n",
       " 'ber': 495,\n",
       " 'ach': 496,\n",
       " 'all': 497,\n",
       " '▁Th': 498,\n",
       " 'ult': 499,\n",
       " '▁}': 500,\n",
       " '▁U': 501,\n",
       " '▁us': 502,\n",
       " '▁z': 503,\n",
       " 'ust': 504,\n",
       " '▁have': 505,\n",
       " 'lic': 506,\n",
       " 'ни': 507,\n",
       " '▁can': 508,\n",
       " 'tr': 509,\n",
       " 'com': 510,\n",
       " '),': 511,\n",
       " '▁In': 512,\n",
       " 'ind': 513,\n",
       " 'ell': 514,\n",
       " '▁from': 515,\n",
       " 'ов': 516,\n",
       " 'to': 517,\n",
       " '▁[': 518,\n",
       " 'able': 519,\n",
       " 'ost': 520,\n",
       " '▁ch': 521,\n",
       " 'ect': 522,\n",
       " 'ight': 523,\n",
       " 'int': 524,\n",
       " \"▁'\": 525,\n",
       " '▁are': 526,\n",
       " '▁im': 527,\n",
       " '▁sh': 528,\n",
       " '▁<': 529,\n",
       " '▁An': 530,\n",
       " '▁с': 531,\n",
       " 'ata': 532,\n",
       " 'ire': 533,\n",
       " '▁tr': 534,\n",
       " 'con': 535,\n",
       " 'ord': 536,\n",
       " 'ity': 537,\n",
       " 'ard': 538,\n",
       " '▁▁▁▁▁▁': 539,\n",
       " '▁he': 540,\n",
       " '▁but': 541,\n",
       " 'oc': 542,\n",
       " '=\"': 543,\n",
       " '▁pr': 544,\n",
       " 'ure': 545,\n",
       " 'per': 546,\n",
       " 'ack': 547,\n",
       " 'ork': 548,\n",
       " 'ong': 549,\n",
       " 'ans': 550,\n",
       " 'ко': 551,\n",
       " 'ple': 552,\n",
       " '▁des': 553,\n",
       " 'ok': 554,\n",
       " 'orm': 555,\n",
       " 'wer': 556,\n",
       " 'ak': 557,\n",
       " 'pr': 558,\n",
       " 'ase': 559,\n",
       " '▁el': 560,\n",
       " 'ph': 561,\n",
       " 'ac': 562,\n",
       " '▁und': 563,\n",
       " '▁ar': 564,\n",
       " '▁if': 565,\n",
       " 'ud': 566,\n",
       " 'ps': 567,\n",
       " 'ite': 568,\n",
       " 'ble': 569,\n",
       " 'но': 570,\n",
       " 'fer': 571,\n",
       " 'pl': 572,\n",
       " 'ive': 573,\n",
       " 'ang': 574,\n",
       " 'ens': 575,\n",
       " 'ро': 576,\n",
       " '▁so': 577,\n",
       " 'so': 578,\n",
       " 'ast': 579,\n",
       " '()': 580,\n",
       " 'swer': 581,\n",
       " 'ru': 582,\n",
       " 'ies': 583,\n",
       " '▁:': 584,\n",
       " 'au': 585,\n",
       " 'ov': 586,\n",
       " 'ре': 587,\n",
       " 'го': 588,\n",
       " '▁der': 589,\n",
       " '▁my': 590,\n",
       " '▁we': 591,\n",
       " '▁me': 592,\n",
       " 'nt': 593,\n",
       " '▁ad': 594,\n",
       " 'urn': 595,\n",
       " '▁your': 596,\n",
       " '://': 597,\n",
       " 'are': 598,\n",
       " '▁all': 599,\n",
       " 'ff': 600,\n",
       " 'io': 601,\n",
       " 'estion': 602,\n",
       " 'ime': 603,\n",
       " '▁er': 604,\n",
       " 'lass': 605,\n",
       " '▁и': 606,\n",
       " '▁which': 607,\n",
       " 'ome': 608,\n",
       " 'ont': 609,\n",
       " '▁par': 610,\n",
       " '▁ma': 611,\n",
       " '▁Y': 612,\n",
       " '\",': 613,\n",
       " '▁о': 614,\n",
       " 'ft': 615,\n",
       " 'ial': 616,\n",
       " 'cc': 617,\n",
       " 'ound': 618,\n",
       " '▁li': 619,\n",
       " '▁res': 620,\n",
       " 'eth': 621,\n",
       " 'ject': 622,\n",
       " '▁app': 623,\n",
       " '▁St': 624,\n",
       " 'ice': 625,\n",
       " '▁am': 626,\n",
       " 'act': 627,\n",
       " '▁del': 628,\n",
       " 'gr': 629,\n",
       " 'ated': 630,\n",
       " 'ier': 631,\n",
       " '▁▁▁▁▁▁▁▁▁▁▁▁': 632,\n",
       " '▁ab': 633,\n",
       " '▁et': 634,\n",
       " 'ally': 635,\n",
       " '..': 636,\n",
       " 'port': 637,\n",
       " 'ik': 638,\n",
       " '▁per': 639,\n",
       " '▁cont': 640,\n",
       " 'ри': 641,\n",
       " 'ка': 642,\n",
       " 'ser': 643,\n",
       " 'ли': 644,\n",
       " 'll': 645,\n",
       " 'iew': 646,\n",
       " 'ign': 647,\n",
       " '_{': 648,\n",
       " 'put': 649,\n",
       " 'one': 650,\n",
       " 'unction': 651,\n",
       " '▁di': 652,\n",
       " 'ary': 653,\n",
       " 'ition': 654,\n",
       " 'ma': 655,\n",
       " 'ен': 656,\n",
       " 'get': 657,\n",
       " '▁lo': 658,\n",
       " '▁val': 659,\n",
       " '▁Q': 660,\n",
       " 'ran': 661,\n",
       " '▁д': 662,\n",
       " 'ence': 663,\n",
       " '▁work': 664,\n",
       " '▁на': 665,\n",
       " 'ip': 666,\n",
       " 'item': 667,\n",
       " 'ype': 668,\n",
       " '▁&': 669,\n",
       " '▁his': 670,\n",
       " '▁use': 671,\n",
       " 'der': 672,\n",
       " '▁Answer': 673,\n",
       " '▁will': 674,\n",
       " 'ize': 675,\n",
       " 'та': 676,\n",
       " 'low': 677,\n",
       " '▁Ch': 678,\n",
       " '▁get': 679,\n",
       " 'ide': 680,\n",
       " 'ous': 681,\n",
       " 'ink': 682,\n",
       " 'ption': 683,\n",
       " 'ла': 684,\n",
       " 'turn': 685,\n",
       " 'ung': 686,\n",
       " 'ec': 687,\n",
       " 'ug': 688,\n",
       " 'form': 689,\n",
       " 'res': 690,\n",
       " 'htt': 691,\n",
       " 'oug': 692,\n",
       " 'ль': 693,\n",
       " '▁no': 694,\n",
       " 'cl': 695,\n",
       " '▁ro': 696,\n",
       " '▁one': 697,\n",
       " 'tt': 698,\n",
       " 'cri': 699,\n",
       " 'du': 700,\n",
       " '▁up': 701,\n",
       " 'то': 702,\n",
       " '(\"': 703,\n",
       " '▁ob': 704,\n",
       " 'we': 705,\n",
       " 'ory': 706,\n",
       " '▁est': 707,\n",
       " 'ery': 708,\n",
       " 'iel': 709,\n",
       " 'str': 710,\n",
       " 'ob': 711,\n",
       " '▁que': 712,\n",
       " 'ian': 713,\n",
       " '▁out': 714,\n",
       " '▁pl': 715,\n",
       " '▁new': 716,\n",
       " 'ки': 717,\n",
       " '▁+': 718,\n",
       " 'ry': 719,\n",
       " 'oth': 720,\n",
       " 'ther': 721,\n",
       " '▁var': 722,\n",
       " '▁would': 723,\n",
       " '▁ser': 724,\n",
       " 'tern': 725,\n",
       " 'text': 726,\n",
       " '▁there': 727,\n",
       " 'ish': 728,\n",
       " 'ror': 729,\n",
       " 'те': 730,\n",
       " '▁set': 731,\n",
       " '▁@': 732,\n",
       " '▁по': 733,\n",
       " '▁te': 734,\n",
       " 'ex': 735,\n",
       " '▁return': 736,\n",
       " 'ail': 737,\n",
       " '▁any': 738,\n",
       " '▁It': 739,\n",
       " '▁function': 740,\n",
       " '{\\\\': 741,\n",
       " \"',\": 742,\n",
       " 'és': 743,\n",
       " 'ale': 744,\n",
       " 'ан': 745,\n",
       " '▁when': 746,\n",
       " 'ib': 747,\n",
       " '▁go': 748,\n",
       " 'ance': 749,\n",
       " '▁had': 750,\n",
       " '▁Qu': 751,\n",
       " '▁comp': 752,\n",
       " 'ле': 753,\n",
       " '▁з': 754,\n",
       " 'math': 755,\n",
       " '▁has': 756,\n",
       " '▁м': 757,\n",
       " '▁pre': 758,\n",
       " 'ener': 759,\n",
       " '▁part': 760,\n",
       " 'elf': 761,\n",
       " '▁die': 762,\n",
       " '▁like': 763,\n",
       " 'ray': 764,\n",
       " 'irst': 765,\n",
       " '▁dis': 766,\n",
       " '▁man': 767,\n",
       " 'rit': 768,\n",
       " '▁then': 769,\n",
       " '▁class': 770,\n",
       " 'pro': 771,\n",
       " '▁po': 772,\n",
       " '▁using': 773,\n",
       " 'eb': 774,\n",
       " '▁code': 775,\n",
       " 'own': 776,\n",
       " '▁some': 777,\n",
       " 'ces': 778,\n",
       " '▁$\\\\': 779,\n",
       " 'ер': 780,\n",
       " 'lect': 781,\n",
       " '▁au': 782,\n",
       " 'isch': 783,\n",
       " '▁col': 784,\n",
       " '▁–': 785,\n",
       " 'up': 786,\n",
       " 'ons': 787,\n",
       " '▁add': 788,\n",
       " 'ild': 789,\n",
       " 'iss': 790,\n",
       " 'val': 791,\n",
       " 'ount': 792,\n",
       " 'les': 793,\n",
       " 'vent': 794,\n",
       " '▁▁▁▁▁▁▁▁▁▁▁▁▁': 795,\n",
       " '▁Z': 796,\n",
       " 'In': 797,\n",
       " 'row': 798,\n",
       " 'ear': 799,\n",
       " 'ations': 800,\n",
       " 'ah': 801,\n",
       " 'que': 802,\n",
       " 'ublic': 803,\n",
       " 'ank': 804,\n",
       " '▁sp': 805,\n",
       " '▁Wh': 806,\n",
       " '----': 807,\n",
       " 'sk': 808,\n",
       " 'ew': 809,\n",
       " 'ags': 810,\n",
       " 'ти': 811,\n",
       " 'ann': 812,\n",
       " '▁—': 813,\n",
       " 'ert': 814,\n",
       " 'ace': 815,\n",
       " 'sch': 816,\n",
       " '▁need': 817,\n",
       " '▁à': 818,\n",
       " 'ien': 819,\n",
       " 'ough': 820,\n",
       " 'не': 821,\n",
       " '▁def': 822,\n",
       " 'ij': 823,\n",
       " 'ern': 824,\n",
       " '▁what': 825,\n",
       " '▁Ar': 826,\n",
       " 'wo': 827,\n",
       " 'ml': 828,\n",
       " '</': 829,\n",
       " '▁Re': 830,\n",
       " '▁es': 831,\n",
       " '▁inst': 832,\n",
       " 'bo': 833,\n",
       " 'az': 834,\n",
       " '▁###': 835,\n",
       " '▁б': 836,\n",
       " 'erm': 837,\n",
       " '▁Al': 838,\n",
       " 'led': 839,\n",
       " 'да': 840,\n",
       " 'ten': 841,\n",
       " 'set': 842,\n",
       " 'ло': 843,\n",
       " '▁comm': 844,\n",
       " 'sh': 845,\n",
       " 'ва': 846,\n",
       " '▁/': 847,\n",
       " '▁data': 848,\n",
       " '▁//': 849,\n",
       " '](': 850,\n",
       " '▁str': 851,\n",
       " 'ose': 852,\n",
       " '▁Un': 853,\n",
       " 'ven': 854,\n",
       " 'St': 855,\n",
       " '...': 856,\n",
       " '▁С': 857,\n",
       " 'yst': 858,\n",
       " '▁«': 859,\n",
       " 'ick': 860,\n",
       " 'ix': 861,\n",
       " 'par': 862,\n",
       " '▁у': 863,\n",
       " '▁want': 864,\n",
       " 'ng': 865,\n",
       " 'ote': 866,\n",
       " '▁gr': 867,\n",
       " '▁du': 868,\n",
       " '▁.': 869,\n",
       " 'und': 870,\n",
       " '▁only': 871,\n",
       " '▁sa': 872,\n",
       " 'ely': 873,\n",
       " 'vers': 874,\n",
       " '▁ent': 875,\n",
       " '))': 876,\n",
       " \"('\": 877,\n",
       " '▁mod': 878,\n",
       " 'ava': 879,\n",
       " 'ton': 880,\n",
       " '▁should': 881,\n",
       " 'ement': 882,\n",
       " '▁form': 883,\n",
       " '▁also': 884,\n",
       " '▁sc': 885,\n",
       " 'ings': 886,\n",
       " '▁You': 887,\n",
       " 'ón': 888,\n",
       " '▁kn': 889,\n",
       " '();': 890,\n",
       " '▁|': 891,\n",
       " '▁were': 892,\n",
       " 'ss': 893,\n",
       " '▁Question': 894,\n",
       " 'ise': 895,\n",
       " '▁they': 896,\n",
       " '▁De': 897,\n",
       " 'ond': 898,\n",
       " '▁sol': 899,\n",
       " '▁fol': 900,\n",
       " '▁more': 901,\n",
       " '▁her': 902,\n",
       " '▁_': 903,\n",
       " '▁é': 904,\n",
       " 'atch': 905,\n",
       " 'fter': 906,\n",
       " '▁cre': 907,\n",
       " 'lock': 908,\n",
       " 'tring': 909,\n",
       " '▁This': 910,\n",
       " 'ze': 911,\n",
       " 'ado': 912,\n",
       " 'ull': 913,\n",
       " 'ger': 914,\n",
       " 'be': 915,\n",
       " '▁other': 916,\n",
       " '▁Tags': 917,\n",
       " 'ution': 918,\n",
       " 'ict': 919,\n",
       " '▁how': 920,\n",
       " '▁x': 921,\n",
       " '▁Se': 922,\n",
       " '▁che': 923,\n",
       " 'cript': 924,\n",
       " '▁just': 925,\n",
       " '▁pos': 926,\n",
       " 'ange': 927,\n",
       " 'ific': 928,\n",
       " 'ree': 929,\n",
       " '}}': 930,\n",
       " '▁time': 931,\n",
       " 'app': 932,\n",
       " 'ны': 933,\n",
       " '▁file': 934,\n",
       " 'ark': 935,\n",
       " 'ical': 936,\n",
       " '▁first': 937,\n",
       " '▁int': 938,\n",
       " '▁В': 939,\n",
       " '▁He': 940,\n",
       " 'ta': 941,\n",
       " 'ument': 942,\n",
       " 'ors': 943,\n",
       " 'lement': 944,\n",
       " 'rac': 945,\n",
       " '▁ag': 946,\n",
       " '▁does': 947,\n",
       " 'yn': 948,\n",
       " 'read': 949,\n",
       " 'ual': 950,\n",
       " '▁Le': 951,\n",
       " 'ys': 952,\n",
       " '▁em': 953,\n",
       " '▁num': 954,\n",
       " 'vel': 955,\n",
       " 'ди': 956,\n",
       " 'over': 957,\n",
       " '▁dif': 958,\n",
       " 'ethod': 959,\n",
       " '▁If': 960,\n",
       " '▁spe': 961,\n",
       " 'ym': 962,\n",
       " '▁them': 963,\n",
       " '▁into': 964,\n",
       " '▁▁▁▁▁▁▁▁▁▁': 965,\n",
       " '▁les': 966,\n",
       " '▁its': 967,\n",
       " 'ese': 968,\n",
       " 'ield': 969,\n",
       " '▁public': 970,\n",
       " '▁П': 971,\n",
       " '▁den': 972,\n",
       " 'ystem': 973,\n",
       " 'of': 974,\n",
       " '▁over': 975,\n",
       " '->': 976,\n",
       " '▁fil': 977,\n",
       " 'name': 978,\n",
       " 'inal': 979,\n",
       " '▁il': 980,\n",
       " 'ample': 981,\n",
       " '▁way': 982,\n",
       " 'ica': 983,\n",
       " 'во': 984,\n",
       " 'cess': 985,\n",
       " 'itt': 986,\n",
       " 'uch': 987,\n",
       " '▁where': 988,\n",
       " 'ми': 989,\n",
       " 'org': 990,\n",
       " 'https': 991,\n",
       " '▁vo': 992,\n",
       " 'ient': 993,\n",
       " 'ove': 994,\n",
       " '▁value': 995,\n",
       " 'eng': 996,\n",
       " '▁La': 997,\n",
       " '^{': 998,\n",
       " 'ref': 999,\n",
       " ...}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mini_vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{b'!': 0,\n",
       " b'\"': 1,\n",
       " b'#': 2,\n",
       " b'$': 3,\n",
       " b'%': 4,\n",
       " b'&': 5,\n",
       " b\"'\": 6,\n",
       " b'(': 7,\n",
       " b')': 8,\n",
       " b'*': 9,\n",
       " b'+': 10,\n",
       " b',': 11,\n",
       " b'-': 12,\n",
       " b'.': 13,\n",
       " b'/': 14,\n",
       " b'0': 15,\n",
       " b'1': 16,\n",
       " b'2': 17,\n",
       " b'3': 18,\n",
       " b'4': 19,\n",
       " b'5': 20,\n",
       " b'6': 21,\n",
       " b'7': 22,\n",
       " b'8': 23,\n",
       " b'9': 24,\n",
       " b':': 25,\n",
       " b';': 26,\n",
       " b'<': 27,\n",
       " b'=': 28,\n",
       " b'>': 29,\n",
       " b'?': 30,\n",
       " b'@': 31,\n",
       " b'A': 32,\n",
       " b'B': 33,\n",
       " b'C': 34,\n",
       " b'D': 35,\n",
       " b'E': 36,\n",
       " b'F': 37,\n",
       " b'G': 38,\n",
       " b'H': 39,\n",
       " b'I': 40,\n",
       " b'J': 41,\n",
       " b'K': 42,\n",
       " b'L': 43,\n",
       " b'M': 44,\n",
       " b'N': 45,\n",
       " b'O': 46,\n",
       " b'P': 47,\n",
       " b'Q': 48,\n",
       " b'R': 49,\n",
       " b'S': 50,\n",
       " b'T': 51,\n",
       " b'U': 52,\n",
       " b'V': 53,\n",
       " b'W': 54,\n",
       " b'X': 55,\n",
       " b'Y': 56,\n",
       " b'Z': 57,\n",
       " b'[': 58,\n",
       " b'\\\\': 59,\n",
       " b']': 60,\n",
       " b'^': 61,\n",
       " b'_': 62,\n",
       " b'`': 63,\n",
       " b'a': 64,\n",
       " b'b': 65,\n",
       " b'c': 66,\n",
       " b'd': 67,\n",
       " b'e': 68,\n",
       " b'f': 69,\n",
       " b'g': 70,\n",
       " b'h': 71,\n",
       " b'i': 72,\n",
       " b'j': 73,\n",
       " b'k': 74,\n",
       " b'l': 75,\n",
       " b'm': 76,\n",
       " b'n': 77,\n",
       " b'o': 78,\n",
       " b'p': 79,\n",
       " b'q': 80,\n",
       " b'r': 81,\n",
       " b's': 82,\n",
       " b't': 83,\n",
       " b'u': 84,\n",
       " b'v': 85,\n",
       " b'w': 86,\n",
       " b'x': 87,\n",
       " b'y': 88,\n",
       " b'z': 89,\n",
       " b'{': 90,\n",
       " b'|': 91,\n",
       " b'}': 92,\n",
       " b'~': 93,\n",
       " b'\\xa1': 94,\n",
       " b'\\xa2': 95,\n",
       " b'\\xa3': 96,\n",
       " b'\\xa4': 97,\n",
       " b'\\xa5': 98,\n",
       " b'\\xa6': 99,\n",
       " b'\\xa7': 100,\n",
       " b'\\xa8': 101,\n",
       " b'\\xa9': 102,\n",
       " b'\\xaa': 103,\n",
       " b'\\xab': 104,\n",
       " b'\\xac': 105,\n",
       " b'\\xae': 106,\n",
       " b'\\xaf': 107,\n",
       " b'\\xb0': 108,\n",
       " b'\\xb1': 109,\n",
       " b'\\xb2': 110,\n",
       " b'\\xb3': 111,\n",
       " b'\\xb4': 112,\n",
       " b'\\xb5': 113,\n",
       " b'\\xb6': 114,\n",
       " b'\\xb7': 115,\n",
       " b'\\xb8': 116,\n",
       " b'\\xb9': 117,\n",
       " b'\\xba': 118,\n",
       " b'\\xbb': 119,\n",
       " b'\\xbc': 120,\n",
       " b'\\xbd': 121,\n",
       " b'\\xbe': 122,\n",
       " b'\\xbf': 123,\n",
       " b'\\xc0': 124,\n",
       " b'\\xc1': 125,\n",
       " b'\\xc2': 126,\n",
       " b'\\xc3': 127,\n",
       " b'\\xc4': 128,\n",
       " b'\\xc5': 129,\n",
       " b'\\xc6': 130,\n",
       " b'\\xc7': 131,\n",
       " b'\\xc8': 132,\n",
       " b'\\xc9': 133,\n",
       " b'\\xca': 134,\n",
       " b'\\xcb': 135,\n",
       " b'\\xcc': 136,\n",
       " b'\\xcd': 137,\n",
       " b'\\xce': 138,\n",
       " b'\\xcf': 139,\n",
       " b'\\xd0': 140,\n",
       " b'\\xd1': 141,\n",
       " b'\\xd2': 142,\n",
       " b'\\xd3': 143,\n",
       " b'\\xd4': 144,\n",
       " b'\\xd5': 145,\n",
       " b'\\xd6': 146,\n",
       " b'\\xd7': 147,\n",
       " b'\\xd8': 148,\n",
       " b'\\xd9': 149,\n",
       " b'\\xda': 150,\n",
       " b'\\xdb': 151,\n",
       " b'\\xdc': 152,\n",
       " b'\\xdd': 153,\n",
       " b'\\xde': 154,\n",
       " b'\\xdf': 155,\n",
       " b'\\xe0': 156,\n",
       " b'\\xe1': 157,\n",
       " b'\\xe2': 158,\n",
       " b'\\xe3': 159,\n",
       " b'\\xe4': 160,\n",
       " b'\\xe5': 161,\n",
       " b'\\xe6': 162,\n",
       " b'\\xe7': 163,\n",
       " b'\\xe8': 164,\n",
       " b'\\xe9': 165,\n",
       " b'\\xea': 166,\n",
       " b'\\xeb': 167,\n",
       " b'\\xec': 168,\n",
       " b'\\xed': 169,\n",
       " b'\\xee': 170,\n",
       " b'\\xef': 171,\n",
       " b'\\xf0': 172,\n",
       " b'\\xf1': 173,\n",
       " b'\\xf2': 174,\n",
       " b'\\xf3': 175,\n",
       " b'\\xf4': 176,\n",
       " b'\\xf5': 177,\n",
       " b'\\xf6': 178,\n",
       " b'\\xf7': 179,\n",
       " b'\\xf8': 180,\n",
       " b'\\xf9': 181,\n",
       " b'\\xfa': 182,\n",
       " b'\\xfb': 183,\n",
       " b'\\xfc': 184,\n",
       " b'\\xfd': 185,\n",
       " b'\\xfe': 186,\n",
       " b'\\xff': 187,\n",
       " b'\\x00': 188,\n",
       " b'\\x01': 189,\n",
       " b'\\x02': 190,\n",
       " b'\\x03': 191,\n",
       " b'\\x04': 192,\n",
       " b'\\x05': 193,\n",
       " b'\\x06': 194,\n",
       " b'\\x07': 195,\n",
       " b'\\x08': 196,\n",
       " b'\\t': 197,\n",
       " b'\\n': 198,\n",
       " b'\\x0b': 199,\n",
       " b'\\x0c': 200,\n",
       " b'\\r': 201,\n",
       " b'\\x0e': 202,\n",
       " b'\\x0f': 203,\n",
       " b'\\x10': 204,\n",
       " b'\\x11': 205,\n",
       " b'\\x12': 206,\n",
       " b'\\x13': 207,\n",
       " b'\\x14': 208,\n",
       " b'\\x15': 209,\n",
       " b'\\x16': 210,\n",
       " b'\\x17': 211,\n",
       " b'\\x18': 212,\n",
       " b'\\x19': 213,\n",
       " b'\\x1a': 214,\n",
       " b'\\x1b': 215,\n",
       " b'\\x1c': 216,\n",
       " b'\\x1d': 217,\n",
       " b'\\x1e': 218,\n",
       " b'\\x1f': 219,\n",
       " b' ': 220,\n",
       " b'\\x7f': 221,\n",
       " b'\\x80': 222,\n",
       " b'\\x81': 223,\n",
       " b'\\x82': 224,\n",
       " b'\\x83': 225,\n",
       " b'\\x84': 226,\n",
       " b'\\x85': 227,\n",
       " b'\\x86': 228,\n",
       " b'\\x87': 229,\n",
       " b'\\x88': 230,\n",
       " b'\\x89': 231,\n",
       " b'\\x8a': 232,\n",
       " b'\\x8b': 233,\n",
       " b'\\x8c': 234,\n",
       " b'\\x8d': 235,\n",
       " b'\\x8e': 236,\n",
       " b'\\x8f': 237,\n",
       " b'\\x90': 238,\n",
       " b'\\x91': 239,\n",
       " b'\\x92': 240,\n",
       " b'\\x93': 241,\n",
       " b'\\x94': 242,\n",
       " b'\\x95': 243,\n",
       " b'\\x96': 244,\n",
       " b'\\x97': 245,\n",
       " b'\\x98': 246,\n",
       " b'\\x99': 247,\n",
       " b'\\x9a': 248,\n",
       " b'\\x9b': 249,\n",
       " b'\\x9c': 250,\n",
       " b'\\x9d': 251,\n",
       " b'\\x9e': 252,\n",
       " b'\\x9f': 253,\n",
       " b'\\xa0': 254,\n",
       " b'\\xad': 255,\n",
       " b'  ': 256,\n",
       " b'    ': 257,\n",
       " b'in': 258,\n",
       " b' t': 259,\n",
       " b'        ': 260,\n",
       " b'er': 261,\n",
       " b'   ': 262,\n",
       " b'on': 263,\n",
       " b' a': 264,\n",
       " b're': 265,\n",
       " b'at': 266,\n",
       " b'st': 267,\n",
       " b'en': 268,\n",
       " b'or': 269,\n",
       " b' th': 270,\n",
       " b'\\n\\n': 271,\n",
       " b' c': 272,\n",
       " b'le': 273,\n",
       " b' s': 274,\n",
       " b'it': 275,\n",
       " b'an': 276,\n",
       " b'ar': 277,\n",
       " b'al': 278,\n",
       " b' the': 279,\n",
       " b';\\n': 280,\n",
       " b' p': 281,\n",
       " b' f': 282,\n",
       " b'ou': 283,\n",
       " b' =': 284,\n",
       " b'is': 285,\n",
       " b'       ': 286,\n",
       " b'ing': 287,\n",
       " b'es': 288,\n",
       " b' w': 289,\n",
       " b'ion': 290,\n",
       " b'ed': 291,\n",
       " b'ic': 292,\n",
       " b' b': 293,\n",
       " b' d': 294,\n",
       " b'et': 295,\n",
       " b' m': 296,\n",
       " b' o': 297,\n",
       " b'\\t\\t': 298,\n",
       " b'ro': 299,\n",
       " b'as': 300,\n",
       " b'el': 301,\n",
       " b'ct': 302,\n",
       " b'nd': 303,\n",
       " b' in': 304,\n",
       " b' h': 305,\n",
       " b'ent': 306,\n",
       " b'id': 307,\n",
       " b' n': 308,\n",
       " b'am': 309,\n",
       " b'           ': 310,\n",
       " b' to': 311,\n",
       " b' re': 312,\n",
       " b'--': 313,\n",
       " b' {': 314,\n",
       " b' of': 315,\n",
       " b'om': 316,\n",
       " b');\\n': 317,\n",
       " b'im': 318,\n",
       " b'\\r\\n': 319,\n",
       " b' (': 320,\n",
       " b'il': 321,\n",
       " b'//': 322,\n",
       " b' and': 323,\n",
       " b'ur': 324,\n",
       " b'se': 325,\n",
       " b' l': 326,\n",
       " b'ex': 327,\n",
       " b' S': 328,\n",
       " b'ad': 329,\n",
       " b' \"': 330,\n",
       " b'ch': 331,\n",
       " b'ut': 332,\n",
       " b'if': 333,\n",
       " b'**': 334,\n",
       " b' }': 335,\n",
       " b'em': 336,\n",
       " b'ol': 337,\n",
       " b'                ': 338,\n",
       " b'th': 339,\n",
       " b')\\n': 340,\n",
       " b' {\\n': 341,\n",
       " b' g': 342,\n",
       " b'ig': 343,\n",
       " b'iv': 344,\n",
       " b',\\n': 345,\n",
       " b'ce': 346,\n",
       " b'od': 347,\n",
       " b' v': 348,\n",
       " b'ate': 349,\n",
       " b' T': 350,\n",
       " b'ag': 351,\n",
       " b'ay': 352,\n",
       " b' *': 353,\n",
       " b'ot': 354,\n",
       " b'us': 355,\n",
       " b' C': 356,\n",
       " b' st': 357,\n",
       " b' I': 358,\n",
       " b'un': 359,\n",
       " b'ul': 360,\n",
       " b'ue': 361,\n",
       " b' A': 362,\n",
       " b'ow': 363,\n",
       " b\" '\": 364,\n",
       " b'ew': 365,\n",
       " b' <': 366,\n",
       " b'ation': 367,\n",
       " b'()': 368,\n",
       " b' for': 369,\n",
       " b'ab': 370,\n",
       " b'ort': 371,\n",
       " b'um': 372,\n",
       " b'ame': 373,\n",
       " b' is': 374,\n",
       " b'pe': 375,\n",
       " b'tr': 376,\n",
       " b'ck': 377,\n",
       " b'\\xe2\\x80': 378,\n",
       " b' y': 379,\n",
       " b'ist': 380,\n",
       " b'----': 381,\n",
       " b'.\\n\\n': 382,\n",
       " b'he': 383,\n",
       " b' e': 384,\n",
       " b'lo': 385,\n",
       " b' M': 386,\n",
       " b' be': 387,\n",
       " b'ers': 388,\n",
       " b' on': 389,\n",
       " b' con': 390,\n",
       " b'ap': 391,\n",
       " b'ub': 392,\n",
       " b' P': 393,\n",
       " b'               ': 394,\n",
       " b'ass': 395,\n",
       " b'int': 396,\n",
       " b'>\\n': 397,\n",
       " b'ly': 398,\n",
       " b'urn': 399,\n",
       " b' $': 400,\n",
       " b';\\n\\n': 401,\n",
       " b'av': 402,\n",
       " b'port': 403,\n",
       " b'ir': 404,\n",
       " b'->': 405,\n",
       " b'nt': 406,\n",
       " b'ction': 407,\n",
       " b'end': 408,\n",
       " b' de': 409,\n",
       " b'00': 410,\n",
       " b'ith': 411,\n",
       " b'out': 412,\n",
       " b'turn': 413,\n",
       " b'our': 414,\n",
       " b'     ': 415,\n",
       " b'lic': 416,\n",
       " b'res': 417,\n",
       " b'pt': 418,\n",
       " b'==': 419,\n",
       " b' this': 420,\n",
       " b' wh': 421,\n",
       " b' if': 422,\n",
       " b' D': 423,\n",
       " b'ver': 424,\n",
       " b'age': 425,\n",
       " b' B': 426,\n",
       " b'ht': 427,\n",
       " b'ext': 428,\n",
       " b'=\"': 429,\n",
       " b' that': 430,\n",
       " b'****': 431,\n",
       " b' R': 432,\n",
       " b' it': 433,\n",
       " b'ess': 434,\n",
       " b' F': 435,\n",
       " b' r': 436,\n",
       " b'os': 437,\n",
       " b'and': 438,\n",
       " b' as': 439,\n",
       " b'ect': 440,\n",
       " b'ke': 441,\n",
       " b'rom': 442,\n",
       " b' //': 443,\n",
       " b'con': 444,\n",
       " b' L': 445,\n",
       " b'(\"': 446,\n",
       " b'qu': 447,\n",
       " b'lass': 448,\n",
       " b' with': 449,\n",
       " b'iz': 450,\n",
       " b'de': 451,\n",
       " b' N': 452,\n",
       " b' al': 453,\n",
       " b'op': 454,\n",
       " b'up': 455,\n",
       " b'get': 456,\n",
       " b' }\\n': 457,\n",
       " b'ile': 458,\n",
       " b' an': 459,\n",
       " b'ata': 460,\n",
       " b'ore': 461,\n",
       " b'ri': 462,\n",
       " b' pro': 463,\n",
       " b';\\r\\n': 464,\n",
       " b'\\t\\t\\t\\t': 465,\n",
       " b'ter': 466,\n",
       " b'ain': 467,\n",
       " b' W': 468,\n",
       " b' E': 469,\n",
       " b' com': 470,\n",
       " b' return': 471,\n",
       " b'art': 472,\n",
       " b' H': 473,\n",
       " b'ack': 474,\n",
       " b'import': 475,\n",
       " b'ublic': 476,\n",
       " b' or': 477,\n",
       " b'est': 478,\n",
       " b'ment': 479,\n",
       " b' G': 480,\n",
       " b'able': 481,\n",
       " b' -': 482,\n",
       " b'ine': 483,\n",
       " b'ill': 484,\n",
       " b'ind': 485,\n",
       " b'ere': 486,\n",
       " b'::': 487,\n",
       " b'ity': 488,\n",
       " b' +': 489,\n",
       " b' tr': 490,\n",
       " b'elf': 491,\n",
       " b'ight': 492,\n",
       " b\"('\": 493,\n",
       " b'orm': 494,\n",
       " b'ult': 495,\n",
       " b'str': 496,\n",
       " b'..': 497,\n",
       " b'\",': 498,\n",
       " b' you': 499,\n",
       " b'ype': 500,\n",
       " b'pl': 501,\n",
       " b' new': 502,\n",
       " b' j': 503,\n",
       " b'                   ': 504,\n",
       " b' from': 505,\n",
       " b' ex': 506,\n",
       " b' O': 507,\n",
       " b'20': 508,\n",
       " b'ld': 509,\n",
       " b' [': 510,\n",
       " b'oc': 511,\n",
       " b':\\n': 512,\n",
       " b' se': 513,\n",
       " b' le': 514,\n",
       " b'--------': 515,\n",
       " b'.s': 516,\n",
       " b'{\\n': 517,\n",
       " b\"',\": 518,\n",
       " b'ant': 519,\n",
       " b' at': 520,\n",
       " b'ase': 521,\n",
       " b'.c': 522,\n",
       " b' ch': 523,\n",
       " b'</': 524,\n",
       " b'ave': 525,\n",
       " b'ang': 526,\n",
       " b' are': 527,\n",
       " b' int': 528,\n",
       " b'\\xe2\\x80\\x99': 529,\n",
       " b'_t': 530,\n",
       " b'ert': 531,\n",
       " b'ial': 532,\n",
       " b'act': 533,\n",
       " b'}\\n': 534,\n",
       " b'ive': 535,\n",
       " b'ode': 536,\n",
       " b'ost': 537,\n",
       " b' class': 538,\n",
       " b' not': 539,\n",
       " b'og': 540,\n",
       " b'ord': 541,\n",
       " b'alue': 542,\n",
       " b'all': 543,\n",
       " b'ff': 544,\n",
       " b'();\\n': 545,\n",
       " b'ont': 546,\n",
       " b'ime': 547,\n",
       " b'are': 548,\n",
       " b' U': 549,\n",
       " b' pr': 550,\n",
       " b' :': 551,\n",
       " b'ies': 552,\n",
       " b'ize': 553,\n",
       " b'ure': 554,\n",
       " b' by': 555,\n",
       " b'ire': 556,\n",
       " b' }\\n\\n': 557,\n",
       " b'.p': 558,\n",
       " b' sh': 559,\n",
       " b'ice': 560,\n",
       " b'ast': 561,\n",
       " b'ption': 562,\n",
       " b'tring': 563,\n",
       " b'ok': 564,\n",
       " b'__': 565,\n",
       " b'cl': 566,\n",
       " b'##': 567,\n",
       " b' he': 568,\n",
       " b'ard': 569,\n",
       " b').': 570,\n",
       " b' @': 571,\n",
       " b'iew': 572,\n",
       " b'\\t\\t\\t': 573,\n",
       " b' was': 574,\n",
       " b'ip': 575,\n",
       " b'this': 576,\n",
       " b' u': 577,\n",
       " b' The': 578,\n",
       " b'ide': 579,\n",
       " b'ace': 580,\n",
       " b'ib': 581,\n",
       " b'ac': 582,\n",
       " b'rou': 583,\n",
       " b' we': 584,\n",
       " b'ject': 585,\n",
       " b' public': 586,\n",
       " b'ak': 587,\n",
       " b've': 588,\n",
       " b'ath': 589,\n",
       " b'oid': 590,\n",
       " b' =>': 591,\n",
       " b'ust': 592,\n",
       " b'que': 593,\n",
       " b' res': 594,\n",
       " b'))': 595,\n",
       " b\"'s\": 596,\n",
       " b' k': 597,\n",
       " b'ans': 598,\n",
       " b'yst': 599,\n",
       " b'unction': 600,\n",
       " b'********': 601,\n",
       " b' i': 602,\n",
       " b' us': 603,\n",
       " b'pp': 604,\n",
       " b'10': 605,\n",
       " b'one': 606,\n",
       " b'ail': 607,\n",
       " b'====': 608,\n",
       " b'name': 609,\n",
       " b' str': 610,\n",
       " b' /': 611,\n",
       " b' &': 612,\n",
       " b'ach': 613,\n",
       " b'div': 614,\n",
       " b'ystem': 615,\n",
       " b'ell': 616,\n",
       " b' have': 617,\n",
       " b'err': 618,\n",
       " b'ould': 619,\n",
       " b'ull': 620,\n",
       " b'pon': 621,\n",
       " b' J': 622,\n",
       " b'_p': 623,\n",
       " b' ==': 624,\n",
       " b'ign': 625,\n",
       " b'St': 626,\n",
       " b'.\\n': 627,\n",
       " b' pl': 628,\n",
       " b');\\n\\n': 629,\n",
       " b'form': 630,\n",
       " b'put': 631,\n",
       " b'ount': 632,\n",
       " b'}\\n\\n': 633,\n",
       " b'dd': 634,\n",
       " b'ite': 635,\n",
       " b' get': 636,\n",
       " b'rr': 637,\n",
       " b'ome': 638,\n",
       " b' \\xe2\\x80': 639,\n",
       " b'aram': 640,\n",
       " b'cc': 641,\n",
       " b' */': 642,\n",
       " b'ER': 643,\n",
       " b'In': 644,\n",
       " b'les': 645,\n",
       " b'_s': 646,\n",
       " b'ong': 647,\n",
       " b'ie': 648,\n",
       " b' can': 649,\n",
       " b' V': 650,\n",
       " b'erv': 651,\n",
       " b'pr': 652,\n",
       " b' un': 653,\n",
       " b'row': 654,\n",
       " b'ber': 655,\n",
       " b' do': 656,\n",
       " b'll': 657,\n",
       " b' el': 658,\n",
       " b' self': 659,\n",
       " b'ated': 660,\n",
       " b'ary': 661,\n",
       " b' .': 662,\n",
       " b\"']\": 663,\n",
       " b'ud': 664,\n",
       " b' en': 665,\n",
       " b' Th': 666,\n",
       " b'                       ': 667,\n",
       " b'te': 668,\n",
       " b'_c': 669,\n",
       " b'uct': 670,\n",
       " b' ab': 671,\n",
       " b'ork': 672,\n",
       " b'.get': 673,\n",
       " b' #': 674,\n",
       " b'aw': 675,\n",
       " b'ress': 676,\n",
       " b'ob': 677,\n",
       " b'Name': 678,\n",
       " b'201': 679,\n",
       " b'app': 680,\n",
       " b\"['\": 681,\n",
       " b' all': 682,\n",
       " b'ory': 683,\n",
       " b'ition': 684,\n",
       " b'ance': 685,\n",
       " b'ear': 686,\n",
       " b' cont': 687,\n",
       " b'vent': 688,\n",
       " b'ia': 689,\n",
       " b' will': 690,\n",
       " b'IN': 691,\n",
       " b'         ': 692,\n",
       " b'return': 693,\n",
       " b' </': 694,\n",
       " b'data': 695,\n",
       " b')\\n\\n': 696,\n",
       " b'Re': 697,\n",
       " b'ple': 698,\n",
       " b'ild': 699,\n",
       " b'ther': 700,\n",
       " b' your': 701,\n",
       " b'\"\\n': 702,\n",
       " b'($': 703,\n",
       " b' out': 704,\n",
       " b'),': 705,\n",
       " b' has': 706,\n",
       " b'String': 707,\n",
       " b'so': 708,\n",
       " b' up': 709,\n",
       " b'ax': 710,\n",
       " b' def': 711,\n",
       " b' bo': 712,\n",
       " b'ge': 713,\n",
       " b'alse': 714,\n",
       " b'ON': 715,\n",
       " b'per': 716,\n",
       " b'12': 717,\n",
       " b'ich': 718,\n",
       " b' but': 719,\n",
       " b' \\n': 720,\n",
       " b' _': 721,\n",
       " b'_m': 722,\n",
       " b'add': 723,\n",
       " b'quest': 724,\n",
       " b'odel': 725,\n",
       " b'self': 726,\n",
       " b'ery': 727,\n",
       " b'ft': 728,\n",
       " b'ens': 729,\n",
       " b'////': 730,\n",
       " b'ake': 731,\n",
       " b'.C': 732,\n",
       " b' go': 733,\n",
       " b' function': 734,\n",
       " b' K': 735,\n",
       " b'ivate': 736,\n",
       " b' im': 737,\n",
       " b' const': 738,\n",
       " b'.t': 739,\n",
       " b' */\\n': 740,\n",
       " b');\\r\\n': 741,\n",
       " b' void': 742,\n",
       " b' set': 743,\n",
       " b' System': 744,\n",
       " b'cri': 745,\n",
       " b'()\\n': 746,\n",
       " b'li': 747,\n",
       " b'\\tif': 748,\n",
       " b'.m': 749,\n",
       " b'ally': 750,\n",
       " b'set': 751,\n",
       " b'ep': 752,\n",
       " b'\\xe2\\x80\\x99s': 753,\n",
       " b'bo': 754,\n",
       " b'def': 755,\n",
       " b\"',\\n\": 756,\n",
       " b' me': 757,\n",
       " b' !': 758,\n",
       " b'atch': 759,\n",
       " b'\">': 760,\n",
       " b'\",\\n': 761,\n",
       " b'ec': 762,\n",
       " b' In': 763,\n",
       " b'ph': 764,\n",
       " b' |': 765,\n",
       " b'_f': 766,\n",
       " b' var': 767,\n",
       " b'ence': 768,\n",
       " b'Id': 769,\n",
       " b'ree': 770,\n",
       " b'ink': 771,\n",
       " b'lect': 772,\n",
       " b'ug': 773,\n",
       " b'eth': 774,\n",
       " b' else': 775,\n",
       " b'----------------': 776,\n",
       " b'19': 777,\n",
       " b'cont': 778,\n",
       " b' so': 779,\n",
       " b'atic': 780,\n",
       " b' lo': 781,\n",
       " b'pro': 782,\n",
       " b'ton': 783,\n",
       " b'ss': 784,\n",
       " b'own': 785,\n",
       " b'abel': 786,\n",
       " b'oint': 787,\n",
       " b'ous': 788,\n",
       " b'eld': 789,\n",
       " b'ST': 790,\n",
       " b'The': 791,\n",
       " b'                                ': 792,\n",
       " b'RE': 793,\n",
       " b'\":': 794,\n",
       " b'olor': 795,\n",
       " b'tp': 796,\n",
       " b'eg': 797,\n",
       " b'key': 798,\n",
       " b'ude': 799,\n",
       " b' St': 800,\n",
       " b'ound': 801,\n",
       " b' ar': 802,\n",
       " b'\");\\n': 803,\n",
       " b'ener': 804,\n",
       " b'ser': 805,\n",
       " b'11': 806,\n",
       " b'bject': 807,\n",
       " b'essage': 808,\n",
       " b'fer': 809,\n",
       " b' more': 810,\n",
       " b'ations': 811,\n",
       " b'ents': 812,\n",
       " b' his': 813,\n",
       " b' they': 814,\n",
       " b'.S': 815,\n",
       " b' Y': 816,\n",
       " b'use': 817,\n",
       " b'ne': 818,\n",
       " b'ish': 819,\n",
       " b'old': 820,\n",
       " b'_d': 821,\n",
       " b'io': 822,\n",
       " b'ield': 823,\n",
       " b' per': 824,\n",
       " b'Cont': 825,\n",
       " b'ings': 826,\n",
       " b'####': 827,\n",
       " b' data': 828,\n",
       " b' sa': 829,\n",
       " b'ef': 830,\n",
       " b'fo': 831,\n",
       " b' one': 832,\n",
       " b'eng': 833,\n",
       " b' dis': 834,\n",
       " b'AT': 835,\n",
       " b' name': 836,\n",
       " b' true': 837,\n",
       " b'val': 838,\n",
       " b'led': 839,\n",
       " b'.f': 840,\n",
       " b' ne': 841,\n",
       " b' end': 842,\n",
       " b'32': 843,\n",
       " b'.T': 844,\n",
       " b'16': 845,\n",
       " b'cre': 846,\n",
       " b'ark': 847,\n",
       " b'log': 848,\n",
       " b'Ex': 849,\n",
       " b'error': 850,\n",
       " b'_id': 851,\n",
       " b'urre': 852,\n",
       " b'ange': 853,\n",
       " b' null': 854,\n",
       " b'rray': 855,\n",
       " b' my': 856,\n",
       " b'pan': 857,\n",
       " b'ict': 858,\n",
       " b'ator': 859,\n",
       " b'View': 860,\n",
       " b'List': 861,\n",
       " b'\\treturn': 862,\n",
       " b'\\xe2\\x80\\x9d': 863,\n",
       " b' pre': 864,\n",
       " b' x': 865,\n",
       " b'clude': 866,\n",
       " b'arg': 867,\n",
       " b'15': 868,\n",
       " b'ov': 869,\n",
       " b'.h': 870,\n",
       " b' >': 871,\n",
       " b' their': 872,\n",
       " b\"')\": 873,\n",
       " b'irst': 874,\n",
       " b'ick': 875,\n",
       " b'gh': 876,\n",
       " b'LE': 877,\n",
       " b'OR': 878,\n",
       " b' private': 879,\n",
       " b'tem': 880,\n",
       " b'\\r\\n\\r\\n': 881,\n",
       " b'user': 882,\n",
       " b' )': 883,\n",
       " b'com': 884,\n",
       " b'.A': 885,\n",
       " b'\";\\n': 886,\n",
       " b' id': 887,\n",
       " b'read': 888,\n",
       " b' who': 889,\n",
       " b'_b': 890,\n",
       " b'\">\\n': 891,\n",
       " b' time': 892,\n",
       " b' man': 893,\n",
       " b'ry': 894,\n",
       " b'========': 895,\n",
       " b'roup': 896,\n",
       " b'rop': 897,\n",
       " b'public': 898,\n",
       " b'vel': 899,\n",
       " b'umber': 900,\n",
       " b'ble': 901,\n",
       " b' which': 902,\n",
       " b'****************': 903,\n",
       " b' any': 904,\n",
       " b' false': 905,\n",
       " b'we': 906,\n",
       " b' value': 907,\n",
       " b' li': 908,\n",
       " b'\")': 909,\n",
       " b'nder': 910,\n",
       " b'gr': 911,\n",
       " b' no': 912,\n",
       " b'param': 913,\n",
       " b'25': 914,\n",
       " b'fig': 915,\n",
       " b'.com': 916,\n",
       " b' app': 917,\n",
       " b'_l': 918,\n",
       " b'ions': 919,\n",
       " b'.D': 920,\n",
       " b' Ch': 921,\n",
       " b' about': 922,\n",
       " b' add': 923,\n",
       " b' su': 924,\n",
       " b' string': 925,\n",
       " b'ID': 926,\n",
       " b' over': 927,\n",
       " b'string': 928,\n",
       " b'.l': 929,\n",
       " b'ource': 930,\n",
       " b'000': 931,\n",
       " b'_C': 932,\n",
       " b']\\n': 933,\n",
       " b' qu': 934,\n",
       " b' String': 935,\n",
       " b'ca': 936,\n",
       " b'SE': 937,\n",
       " b' ro': 938,\n",
       " b'sh': 939,\n",
       " b'ual': 940,\n",
       " b'Type': 941,\n",
       " b'son': 942,\n",
       " b'new': 943,\n",
       " b'ern': 944,\n",
       " b' ag': 945,\n",
       " b'AR': 946,\n",
       " b'];\\n': 947,\n",
       " b'].': 948,\n",
       " b' ?': 949,\n",
       " b'ical': 950,\n",
       " b' des': 951,\n",
       " b'uth': 952,\n",
       " b'ix': 953,\n",
       " b'ays': 954,\n",
       " b' type': 955,\n",
       " b\"'t\": 956,\n",
       " b'ault': 957,\n",
       " b' inter': 958,\n",
       " b'var': 959,\n",
       " b'.b': 960,\n",
       " b' part': 961,\n",
       " b'.d': 962,\n",
       " b'urrent': 963,\n",
       " b'IT': 964,\n",
       " b'EN': 965,\n",
       " b'30': 966,\n",
       " b'enc': 967,\n",
       " b'(f': 968,\n",
       " b'ra': 969,\n",
       " b'value': 970,\n",
       " b'cho': 971,\n",
       " b'18': 972,\n",
       " b'utton': 973,\n",
       " b'ose': 974,\n",
       " b'14': 975,\n",
       " b' !=': 976,\n",
       " b'ater': 977,\n",
       " b'\\xc3\\xa9': 978,\n",
       " b'reate': 979,\n",
       " b'oll': 980,\n",
       " b'pos': 981,\n",
       " b'yle': 982,\n",
       " b'ng': 983,\n",
       " b'AL': 984,\n",
       " b'using': 985,\n",
       " b'ames': 986,\n",
       " b' {\\r\\n': 987,\n",
       " b'ates': 988,\n",
       " b'ely': 989,\n",
       " b' work': 990,\n",
       " b' em': 991,\n",
       " b'inal': 992,\n",
       " b' sp': 993,\n",
       " b' when': 994,\n",
       " b'.set': 995,\n",
       " b'      ': 996,\n",
       " b'):\\n': 997,\n",
       " b'to': 998,\n",
       " b'quire': 999,\n",
       " ...}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "small_vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'▁angular': 6401,\n",
       " 'querySelector': 18825,\n",
       " 'unde': 9140,\n",
       " '▁sqlite': 21120,\n",
       " 'unnel': 16163,\n",
       " 'рит': 28717,\n",
       " 'eor': 22241,\n",
       " 'mm': 4317,\n",
       " '▁tf': 15886,\n",
       " '▁zar': 21370,\n",
       " '▁generic': 10035,\n",
       " '▁periods': 23704,\n",
       " '▁added': 2715,\n",
       " 'Microsoft': 11277,\n",
       " '▁decla': 5237,\n",
       " 'ística': 17427,\n",
       " 'ват': 12993,\n",
       " '▁Arizona': 23716,\n",
       " '▁ihnen': 25181,\n",
       " 'raft': 4154,\n",
       " '▁mathematical': 19475,\n",
       " 'ც': 31828,\n",
       " '▁иде': 28866,\n",
       " '▁donc': 12866,\n",
       " 'яз': 27763,\n",
       " '▁duration': 14385,\n",
       " 'UMN': 29127,\n",
       " 'Sch': 4504,\n",
       " 'ión': 3175,\n",
       " '▁Costa': 17513,\n",
       " '▁включа': 20352,\n",
       " '▁javax': 11317,\n",
       " 'ík': 23576,\n",
       " '▁figlio': 24881,\n",
       " '▁lambda': 14013,\n",
       " '▁Social': 10307,\n",
       " 'ést': 21611,\n",
       " '▁IP': 5641,\n",
       " 'osas': 28903,\n",
       " '▁sint': 25507,\n",
       " '▁kir': 18990,\n",
       " '▁Scanner': 23412,\n",
       " 'END': 11794,\n",
       " 'педи': 8947,\n",
       " 'ogeneous': 23724,\n",
       " \"');\": 2157,\n",
       " 'њи': 20171,\n",
       " 'emu': 24425,\n",
       " 'ethe': 23043,\n",
       " 'MAX': 12648,\n",
       " 'icole': 23249,\n",
       " '▁brow': 3347,\n",
       " '▁titled': 25278,\n",
       " '▁trial': 14260,\n",
       " '▁huvud': 13078,\n",
       " 'Sl': 16973,\n",
       " '▁--': 1192,\n",
       " 'Repos': 10913,\n",
       " 'illé': 23589,\n",
       " 'confirm': 26897,\n",
       " '▁Inn': 25408,\n",
       " 'あ': 30641,\n",
       " '▁Кар': 10777,\n",
       " '▁Mars': 16852,\n",
       " '▁представ': 11876,\n",
       " '▁renamed': 19533,\n",
       " 'chi': 4161,\n",
       " '▁Che': 6561,\n",
       " '自': 30688,\n",
       " '▁bekannt': 13633,\n",
       " 'თ': 30838,\n",
       " 'öt': 9618,\n",
       " '限': 31175,\n",
       " '▁nearly': 8886,\n",
       " 'тери': 8747,\n",
       " '▁receiver': 19870,\n",
       " \"(['\": 18959,\n",
       " 'mitt': 18344,\n",
       " '▁grund': 19816,\n",
       " '▁k': 413,\n",
       " '▁Tar': 11740,\n",
       " '▁indicating': 23941,\n",
       " 'esota': 19622,\n",
       " 'ἡ': 31598,\n",
       " 'anning': 9450,\n",
       " 'fficial': 7880,\n",
       " '▁constraints': 11938,\n",
       " '▁Это': 20782,\n",
       " '▁Mary': 6182,\n",
       " '▁hier': 6128,\n",
       " '▁Neder': 10584,\n",
       " 'dll': 12396,\n",
       " '▁Pse': 17646,\n",
       " 'tomcat': 24468,\n",
       " 'shared': 12366,\n",
       " '------+': 25809,\n",
       " '▁Archiv': 5522,\n",
       " 'elijke': 6945,\n",
       " '时': 30594,\n",
       " '▁Нов': 27527,\n",
       " 'হ': 31717,\n",
       " '▁Auß': 17257,\n",
       " 'il': 309,\n",
       " 'widet': 10588,\n",
       " '/$': 13346,\n",
       " '▁chapter': 16385,\n",
       " '▁internacional': 19285,\n",
       " '▁computing': 20602,\n",
       " 'istischen': 23426,\n",
       " '▁Braun': 23514,\n",
       " '▁responsibility': 23134,\n",
       " 'ню': 11128,\n",
       " 'нг': 10232,\n",
       " 'irche': 26846,\n",
       " 'title': 3257,\n",
       " 'ToString': 8246,\n",
       " '▁Jim': 8507,\n",
       " 'encer': 22687,\n",
       " '▁fuel': 26413,\n",
       " '<|placeholder17|>': 32021,\n",
       " '▁sleep': 8709,\n",
       " 'မ': 31233,\n",
       " '▁Unter': 5266,\n",
       " 'рёх': 22726,\n",
       " 'aka': 8245,\n",
       " '▁hijo': 23737,\n",
       " '▁stup': 15885,\n",
       " 'ências': 9339,\n",
       " '▁posto': 17614,\n",
       " 'esty': 14596,\n",
       " 'haft': 22023,\n",
       " '▁losses': 28495,\n",
       " '、': 30330,\n",
       " '<0x12>': 21,\n",
       " '▁wordt': 9925,\n",
       " 'orted': 18054,\n",
       " 'шен': 10084,\n",
       " 'xs': 10351,\n",
       " '▁angularjs': 20740,\n",
       " 'ivel': 13255,\n",
       " 'ח': 30428,\n",
       " '▁GET': 12354,\n",
       " 'Number': 4557,\n",
       " '▁representation': 8954,\n",
       " '▁': 29871,\n",
       " '▁dram': 8541,\n",
       " 'ো': 31864,\n",
       " '▁Ки': 6746,\n",
       " '▁dels': 7195,\n",
       " '▁Dez': 7383,\n",
       " 'ень': 8358,\n",
       " '▁tard': 11364,\n",
       " 'grid': 7720,\n",
       " 'Attribute': 6708,\n",
       " '▁pressure': 12959,\n",
       " '动': 30846,\n",
       " '▁liber': 7866,\n",
       " 'TextView': 10607,\n",
       " '▁inspir': 23459,\n",
       " '▁producer': 14297,\n",
       " 'sterdam': 15372,\n",
       " '▁Louisiana': 28838,\n",
       " '▁convers': 9678,\n",
       " '-,': 15767,\n",
       " 'around': 11316,\n",
       " '▁List': 2391,\n",
       " 'ién': 5170,\n",
       " 'fatt': 27502,\n",
       " 'kn': 3959,\n",
       " 'ships': 9981,\n",
       " 'alia': 19627,\n",
       " '▁algebraic': 21531,\n",
       " '▁nécessaire': 23309,\n",
       " 'ragma': 23929,\n",
       " '岩': 31753,\n",
       " '▁inv': 2437,\n",
       " 'ˠ': 31794,\n",
       " '▁bout': 25927,\n",
       " 'нар': 19619,\n",
       " '▁архи': 16480,\n",
       " '의': 30708,\n",
       " '▁Twe': 27637,\n",
       " '▁quest': 21126,\n",
       " '<0x19>': 28,\n",
       " 'Good': 18420,\n",
       " '▁Rule': 27308,\n",
       " 'െ': 30840,\n",
       " '▁golf': 29416,\n",
       " 'login': 7507,\n",
       " '発': 31657,\n",
       " '▁Dezember': 7860,\n",
       " '▁hvor': 29768,\n",
       " '▁AND': 5300,\n",
       " '▁escape': 10169,\n",
       " 'жил': 23639,\n",
       " '▁desenvol': 20599,\n",
       " '▁raison': 18836,\n",
       " '▁одной': 25816,\n",
       " '▁Од': 29770,\n",
       " '▁зв': 27643,\n",
       " '▁становника': 11229,\n",
       " '▁FF': 21379,\n",
       " '<0xB3>': 182,\n",
       " '▁Пре': 7127,\n",
       " '▁certainly': 8959,\n",
       " '▁programs': 11104,\n",
       " 'ura': 2002,\n",
       " '▁tous': 9411,\n",
       " '▁История': 15034,\n",
       " 'to': 517,\n",
       " 'Ű': 31311,\n",
       " \"▁{'\": 11117,\n",
       " 'чик': 28407,\n",
       " 'den': 1145,\n",
       " 'oks': 12117,\n",
       " '▁abb': 22195,\n",
       " '▁atomic': 23489,\n",
       " '▁équipe': 25740,\n",
       " 'шее': 29656,\n",
       " 'Chain': 14688,\n",
       " 'dorf': 16360,\n",
       " '▁awesome': 29663,\n",
       " 'rite': 1377,\n",
       " '▁Giov': 11429,\n",
       " '▁Тур': 23411,\n",
       " '▁abs': 6425,\n",
       " 'udes': 8192,\n",
       " '▁Бар': 20730,\n",
       " '▁Australian': 9870,\n",
       " '▁lon': 23123,\n",
       " 'mel': 12873,\n",
       " 'Assert': 14697,\n",
       " '▁zum': 3356,\n",
       " '▁forming': 25391,\n",
       " 'ifolia': 28963,\n",
       " 'gef': 21831,\n",
       " 'Period': 29853,\n",
       " '▁lev': 14453,\n",
       " 'ὑ': 31544,\n",
       " 'ὲ': 31265,\n",
       " '▁doubt': 7404,\n",
       " 'слав': 12669,\n",
       " '▁Admin': 10229,\n",
       " 'WD': 24668,\n",
       " '▁Gó': 25055,\n",
       " 'շ': 31720,\n",
       " '▁gru': 4500,\n",
       " '▁gods': 27379,\n",
       " '▁miembros': 29406,\n",
       " '▁Warner': 26699,\n",
       " 'equiv': 9402,\n",
       " '▁Mat': 5345,\n",
       " '▁Parse': 20969,\n",
       " '▁único': 27794,\n",
       " 'гато': 23984,\n",
       " '▁выше': 27252,\n",
       " 'rad': 3665,\n",
       " '▁Binding': 25799,\n",
       " 'ו': 30205,\n",
       " '▁Пере': 16204,\n",
       " '▁naturally': 18180,\n",
       " 'Camera': 20717,\n",
       " '▁Ana': 20367,\n",
       " '▁actu': 20331,\n",
       " '▁leur': 6267,\n",
       " '▁Бо': 6281,\n",
       " 'ief': 2575,\n",
       " '▁Jerusalem': 23204,\n",
       " ';&': 25359,\n",
       " '▁получи': 12052,\n",
       " 'ю': 30005,\n",
       " '▁forme': 13618,\n",
       " '<0x43>': 70,\n",
       " '▁journ': 21824,\n",
       " '▁Results': 17212,\n",
       " '乡': 30574,\n",
       " '以': 30651,\n",
       " '▁ло': 13860,\n",
       " '▁Ż': 14589,\n",
       " 'ване': 16091,\n",
       " 'ieved': 6402,\n",
       " 'Hy': 26322,\n",
       " ')),': 8243,\n",
       " '▁Federal': 14879,\n",
       " '<|placeholder33|>': 32037,\n",
       " '▁Was': 12547,\n",
       " '▁nouveau': 13164,\n",
       " 'porter': 18505,\n",
       " 'Gu': 9485,\n",
       " 'Send': 12600,\n",
       " '▁режи': 16223,\n",
       " '▁Muham': 27100,\n",
       " 'velope': 21367,\n",
       " '塔': 31831,\n",
       " '▁Blo': 11447,\n",
       " '}=': 5369,\n",
       " '▁К': 1069,\n",
       " 'ention': 2509,\n",
       " '▁ім': 19240,\n",
       " 'http': 1124,\n",
       " 'bia': 15959,\n",
       " '▁Jap': 4407,\n",
       " '▁axis': 9685,\n",
       " 'ritz': 18238,\n",
       " '▁bom': 18523,\n",
       " 'chus': 26806,\n",
       " 'VI': 18118,\n",
       " '▁Vector': 16510,\n",
       " 'ometric': 14066,\n",
       " 'Die': 16334,\n",
       " 'oem': 21942,\n",
       " '▁Gill': 28047,\n",
       " '▁seule': 25642,\n",
       " 'urrency': 10880,\n",
       " 'url': 2271,\n",
       " '▁ot': 4932,\n",
       " '▁$_': 7471,\n",
       " '▁rum': 16558,\n",
       " '▁Три': 28928,\n",
       " 'стр': 25819,\n",
       " 'сите': 9440,\n",
       " '▁március': 24605,\n",
       " 'ору': 18968,\n",
       " '▁DJ': 23366,\n",
       " '▁боль': 9935,\n",
       " '▁Education': 13151,\n",
       " 'ishop': 9835,\n",
       " '▁committed': 19355,\n",
       " 'Ord': 23302,\n",
       " 'selenium': 27373,\n",
       " 'bert': 2151,\n",
       " 'туа': 29412,\n",
       " '▁partir': 8019,\n",
       " '▁Grund': 10197,\n",
       " 'trim': 15450,\n",
       " '▁Jó': 18433,\n",
       " '▁front': 4565,\n",
       " '▁pron': 11504,\n",
       " '▁gradually': 22020,\n",
       " '▁visible': 7962,\n",
       " '▁Colomb': 15253,\n",
       " '▁Rail': 9620,\n",
       " 'bey': 22072,\n",
       " '▁Estado': 16763,\n",
       " 'lex': 2506,\n",
       " '▁Park': 4815,\n",
       " '▁configure': 10822,\n",
       " 'ees': 12712,\n",
       " 'bullet': 18850,\n",
       " '▁direct': 1513,\n",
       " 'ist': 391,\n",
       " '▁проис': 23061,\n",
       " 'nehmer': 23450,\n",
       " 'chter': 8255,\n",
       " '▁Florence': 23998,\n",
       " '▁ricon': 26365,\n",
       " 'Al': 2499,\n",
       " 'ALSE': 12195,\n",
       " '₉': 30301,\n",
       " '▁фі': 18396,\n",
       " 'loading': 13234,\n",
       " '▁Yan': 23094,\n",
       " 'wirtschaft': 20402,\n",
       " '▁Kh': 12217,\n",
       " '▁struggling': 20042,\n",
       " 'slice': 18337,\n",
       " 'add': 1202,\n",
       " 'TB': 24895,\n",
       " 'perform': 19826,\n",
       " 'icut': 24408,\n",
       " 'enne': 4584,\n",
       " '▁neighborhood': 18403,\n",
       " 'dfrac': 10779,\n",
       " 'cv': 11023,\n",
       " '▁momento': 14341,\n",
       " 'mun': 24579,\n",
       " '▁све': 19939,\n",
       " '▁gan': 9581,\n",
       " 'гро': 25938,\n",
       " '▁tongue': 26820,\n",
       " '▁кан': 20247,\n",
       " '▁metres': 17963,\n",
       " 'isen': 7674,\n",
       " '▁famil': 1832,\n",
       " '▁TRUE': 15676,\n",
       " 'лово': 19071,\n",
       " '▁portion': 11910,\n",
       " '▁ihr': 5351,\n",
       " 'Items': 6913,\n",
       " 'TextBox': 15102,\n",
       " '▁silver': 13283,\n",
       " \"'];\": 8219,\n",
       " '▁several': 3196,\n",
       " '▁archiválva': 27914,\n",
       " '▁општини': 23406,\n",
       " 'Boot': 20967,\n",
       " '▁є': 9582,\n",
       " '².': 11298,\n",
       " '▁Über': 12093,\n",
       " '<0x0C>': 15,\n",
       " 'Override': 4640,\n",
       " 'ем': 3098,\n",
       " '▁obec': 26055,\n",
       " 'opher': 13434,\n",
       " 'mal': 5156,\n",
       " 'они': 18582,\n",
       " '▁appointment': 28573,\n",
       " '▁Mo': 4546,\n",
       " 'anch': 14588,\n",
       " '▁disappoint': 23451,\n",
       " '✅': 31681,\n",
       " '区': 30467,\n",
       " '▁kleinen': 28566,\n",
       " 'fahr': 18693,\n",
       " 'usk': 17400,\n",
       " 'ide': 680,\n",
       " '▁kind': 2924,\n",
       " 'sterd': 14807,\n",
       " 'ScrollView': 28556,\n",
       " '▁onto': 11480,\n",
       " '▁Schwe': 10445,\n",
       " '▁Garc': 19734,\n",
       " '▁ihre': 9856,\n",
       " '▁Schul': 12988,\n",
       " '유': 31533,\n",
       " '▁cours': 9587,\n",
       " '₀': 30220,\n",
       " '▁Tas': 23793,\n",
       " 'atio': 20819,\n",
       " '▁mant': 13694,\n",
       " '▁MS': 10888,\n",
       " 'рина': 24436,\n",
       " 'cted': 2954,\n",
       " '▁Championship': 8972,\n",
       " 'cluster': 19594,\n",
       " 'Done': 25632,\n",
       " '▁vessels': 24479,\n",
       " 'ginx': 16237,\n",
       " '▁ride': 22203,\n",
       " '▁Mort': 15533,\n",
       " 'Java': 8404,\n",
       " 'ivity': 2068,\n",
       " '▁monuments': 22586,\n",
       " '▁abit': 19709,\n",
       " 'ческих': 17349,\n",
       " 'Plus': 29575,\n",
       " 'fish': 15161,\n",
       " 'cius': 16102,\n",
       " 'ղ': 31443,\n",
       " 'parameter': 15501,\n",
       " 'enburg': 22284,\n",
       " '▁*': 334,\n",
       " '▁Carol': 8562,\n",
       " '▁aller': 16454,\n",
       " '▁Zu': 13893,\n",
       " '▁pau': 24571,\n",
       " '▁config': 2295,\n",
       " '▁Universal': 21536,\n",
       " '▁werk': 23085,\n",
       " '▁largely': 18425,\n",
       " '▁destru': 26468,\n",
       " '到': 30780,\n",
       " 'ব': 30962,\n",
       " 'pkg': 15865,\n",
       " '▁proven': 16413,\n",
       " 'raction': 13857,\n",
       " '<0x92>': 149,\n",
       " 'ależ': 19272,\n",
       " 'Ignore': 23805,\n",
       " 'аль': 4393,\n",
       " 'Len': 21515,\n",
       " '▁Or': 1394,\n",
       " '▁cards': 15889,\n",
       " '▁hid': 20552,\n",
       " 'нова': 8240,\n",
       " '▁adopt': 9332,\n",
       " 'rera': 13941,\n",
       " '▁Whe': 26286,\n",
       " 'ป': 31010,\n",
       " 'blem': 1031,\n",
       " '\"])': 20068,\n",
       " 'ioned': 28487,\n",
       " '▁ils': 11797,\n",
       " '▁Oliver': 19731,\n",
       " '▁Toy': 29411,\n",
       " '▁solem': 25070,\n",
       " 'attend': 27601,\n",
       " '▁lines': 3454,\n",
       " 'сер': 14315,\n",
       " '▁believe': 4658,\n",
       " '▁tip': 6872,\n",
       " '▁AD': 11033,\n",
       " '<0x79>': 124,\n",
       " '▁ори': 19974,\n",
       " '▁White': 8037,\n",
       " '<0x9C>': 159,\n",
       " '▁impossible': 9301,\n",
       " 'onds': 13788,\n",
       " 'Ne': 8139,\n",
       " 'ąc': 29280,\n",
       " 'ots': 1862,\n",
       " '▁equ': 1592,\n",
       " '▁bor': 9820,\n",
       " '▁Hollywood': 19180,\n",
       " '”,': 9363,\n",
       " '▁актив': 15696,\n",
       " 'фек': 18201,\n",
       " 'ON': 1164,\n",
       " 'LES': 17101,\n",
       " 'skiej': 8779,\n",
       " 'ead': 1479,\n",
       " '▁favour': 15381,\n",
       " 'etch': 3486,\n",
       " '▁analy': 16455,\n",
       " '▁simplified': 20875,\n",
       " '▁canvas': 10508,\n",
       " 'Theta': 17458,\n",
       " 'reduce': 17469,\n",
       " '<0xBC>': 191,\n",
       " '▁тя': 23512,\n",
       " '▁britann': 14629,\n",
       " '▁causes': 9946,\n",
       " 'ɯ': 31983,\n",
       " '▁spos': 24253,\n",
       " '▁Woman': 22712,\n",
       " 'кими': 21456,\n",
       " 'jin': 28789,\n",
       " '▁updated': 4784,\n",
       " '▁~': 3695,\n",
       " '▁look': 1106,\n",
       " 'ур': 5179,\n",
       " '▁Under': 7634,\n",
       " 'lij': 7267,\n",
       " '▁phil': 8578,\n",
       " 'ifik': 14759,\n",
       " '▁Charlie': 20283,\n",
       " 'Par': 2177,\n",
       " 'Ze': 24625,\n",
       " 'ア': 30310,\n",
       " '▁characteristic': 17443,\n",
       " '▁notable': 18697,\n",
       " '▁совет': 11999,\n",
       " '▁Jin': 29779,\n",
       " '▁mely': 22202,\n",
       " 'on': 265,\n",
       " '▁inicial': 24879,\n",
       " 'logo': 14569,\n",
       " '▁Lomb': 24869,\n",
       " '▁Lage': 24531,\n",
       " '▁dinner': 17803,\n",
       " 'ა': 30272,\n",
       " '▁contain': 1712,\n",
       " 'alette': 26456,\n",
       " 'äd': 8827,\n",
       " 'nab': 7183,\n",
       " 'liqu': 28378,\n",
       " 'play': 1456,\n",
       " '▁citt': 10439,\n",
       " 'tain': 2408,\n",
       " 'Allow': 15930,\n",
       " '▁складі': 21887,\n",
       " 'jpeg': 26568,\n",
       " '▁ку': 6226,\n",
       " '▁remembered': 21832,\n",
       " 'út': 14384,\n",
       " 'activ': 11236,\n",
       " 'BER': 13635,\n",
       " '▁example': 1342,\n",
       " 'ptions': 1980,\n",
       " '▁terror': 15115,\n",
       " 'elde': 16024,\n",
       " '▁kindly': 25036,\n",
       " '▁Linked': 28547,\n",
       " '▁exempl': 29455,\n",
       " 'Ă': 31468,\n",
       " '▁verschied': 14261,\n",
       " '▁indep': 5111,\n",
       " '▁Britann': 15822,\n",
       " 'lek': 28508,\n",
       " '\\x9d': 31555,\n",
       " '▁seat': 12949,\n",
       " '▁encontr': 14567,\n",
       " '▁Externa': 13263,\n",
       " 'iez': 26477,\n",
       " '▁Cub': 28618,\n",
       " 'тели': 12373,\n",
       " '▁kin': 19015,\n",
       " '▁Ernest': 23993,\n",
       " '万': 31535,\n",
       " '▁map': 2910,\n",
       " 'choice': 16957,\n",
       " '▁Ј': 15181,\n",
       " '▁lun': 25081,\n",
       " 'kh': 15339,\n",
       " '▁gives': 4076,\n",
       " 'ation': 362,\n",
       " 'ší': 7767,\n",
       " 'COUNT': 18736,\n",
       " '▁Rad': 4957,\n",
       " 'bin': 2109,\n",
       " 'tom': 15135,\n",
       " '▁де': 2263,\n",
       " 'iety': 21549,\n",
       " '▁primer': 7130,\n",
       " 'któber': 23441,\n",
       " 'Fact': 20738,\n",
       " 'сторія': 23548,\n",
       " 'parison': 20941,\n",
       " '▁segundo': 14729,\n",
       " '▁back': 1250,\n",
       " '▁Pennsylvania': 16636,\n",
       " 'Q': 29984,\n",
       " '▁Pho': 21884,\n",
       " '▁comple': 1614,\n",
       " 'сков': 22136,\n",
       " 'Height': 7011,\n",
       " '▁М': 1142,\n",
       " '▁technology': 15483,\n",
       " 'atan': 23402,\n",
       " 'month': 10874,\n",
       " '▁Storm': 24444,\n",
       " 'paces': 22459,\n",
       " 'agua': 29296,\n",
       " 'boa': 28954,\n",
       " '▁fils': 14560,\n",
       " '▁мм': 24427,\n",
       " '▁improved': 16710,\n",
       " '▁Abb': 13896,\n",
       " 'xml': 3134,\n",
       " 'uru': 20144,\n",
       " '▁triumph': 24124,\n",
       " '▁Giuseppe': 18824,\n",
       " '𝓝': 31926,\n",
       " 'eder': 2447,\n",
       " '▁uma': 3672,\n",
       " 'XX': 6247,\n",
       " '▁evening': 11005,\n",
       " 'prés': 12974,\n",
       " 'rado': 26881,\n",
       " '▁codes': 11561,\n",
       " '▁Speed': 24839,\n",
       " '▁seinen': 10316,\n",
       " 'гне': 21740,\n",
       " '▁polity': 24694,\n",
       " 'Wikispecies': 24075,\n",
       " '▁elabor': 13771,\n",
       " 'versary': 27547,\n",
       " '▁pav': 23952,\n",
       " 'Equal': 9843,\n",
       " '▁amery': 26447,\n",
       " 'enk': 5842,\n",
       " 'izi': 10077,\n",
       " 'iod': 2660,\n",
       " '▁[:': 20840,\n",
       " '▁qu': 439,\n",
       " '(()': 14885,\n",
       " '收': 31997,\n",
       " 'étique': 19971,\n",
       " '▁września': 25298,\n",
       " 'Л': 30050,\n",
       " '▁Sm': 4116,\n",
       " '▁Hen': 4114,\n",
       " '<0x40>': 67,\n",
       " '▁HT': 3154,\n",
       " 'Component': 5308,\n",
       " '▁Admir': 23946,\n",
       " 'vić': 27532,\n",
       " '▁Hibernate': 27772,\n",
       " 'wp': 11912,\n",
       " 'œur': 16581,\n",
       " '▁Rod': 7733,\n",
       " '⊕': 31200,\n",
       " '片': 31122,\n",
       " '▁station': 5073,\n",
       " '▁Amer': 2163,\n",
       " '秋': 31569,\n",
       " '▁одним': 24753,\n",
       " 'ouver': 8885,\n",
       " 'heid': 9722,\n",
       " 'bar': 1646,\n",
       " 'list': 1761,\n",
       " '▁Human': 12968,\n",
       " '▁одна': 15295,\n",
       " 'кти': 9054,\n",
       " '▁pres': 2225,\n",
       " 'imately': 15084,\n",
       " '▁зали': 23989,\n",
       " 'tuple': 23583,\n",
       " '▁inner': 6426,\n",
       " '▁приня': 17867,\n",
       " '▁T': 323,\n",
       " 'ference': 1659,\n",
       " 'ä': 29986,\n",
       " '▁Mundo': 29790,\n",
       " '▁su': 480,\n",
       " '▁atmosphere': 25005,\n",
       " '▁valley': 19599,\n",
       " 'ket': 7873,\n",
       " 'che': 1173,\n",
       " 'ingsområ': 14723,\n",
       " '▁muss': 23885,\n",
       " '▁arrow': 16578,\n",
       " 'ме': 1488,\n",
       " '▁batter': 10193,\n",
       " '▁anten': 25504,\n",
       " 'shot': 8962,\n",
       " '▁answering': 22862,\n",
       " '▁Jag': 24423,\n",
       " '▁Männer': 29760,\n",
       " '▁cons': 1136,\n",
       " '²': 30088,\n",
       " '▁Att': 6212,\n",
       " '▁fund': 5220,\n",
       " '▁siehe': 27005,\n",
       " 'ому': 22870,\n",
       " 'nelle': 23497,\n",
       " '▁прави': 12318,\n",
       " '▁pił': 23602,\n",
       " '▁Business': 15197,\n",
       " '▁size': 2159,\n",
       " '▁icons': 27673,\n",
       " '▁diesen': 12155,\n",
       " '▁attacks': 16661,\n",
       " '▁Beth': 23408,\n",
       " 'para': 22752,\n",
       " '▁convert': 3588,\n",
       " '------': 22158,\n",
       " '▁gave': 4846,\n",
       " '▁Harr': 12303,\n",
       " '▁functions': 3168,\n",
       " 'ición': 6396,\n",
       " 'Node': 4247,\n",
       " '▁fémin': 26883,\n",
       " 'date': 1256,\n",
       " '▁Access': 11028,\n",
       " '▁Mant': 26873,\n",
       " 'Portail': 2639,\n",
       " '▁bande': 27628,\n",
       " '▁Ign': 18076,\n",
       " '▁памя': 22836,\n",
       " '▁LP': 23671,\n",
       " '▁Metal': 24992,\n",
       " '泉': 31637,\n",
       " 'бле': 18718,\n",
       " 'owan': 24136,\n",
       " '▁equipment': 21083,\n",
       " 'Pe': 15666,\n",
       " 'itate': 10388,\n",
       " '▁Basketball': 21850,\n",
       " 'rypted': 14740,\n",
       " 'arca': 23372,\n",
       " 'close': 5358,\n",
       " '▁decimal': 13677,\n",
       " '▁lod': 21896,\n",
       " 'žen': 19331,\n",
       " 'κ': 30173,\n",
       " '▁relac': 14552,\n",
       " '▁danger': 9703,\n",
       " '▁invoked': 22336,\n",
       " '▁Portugal': 12077,\n",
       " 'zia': 19822,\n",
       " 'mq': 28466,\n",
       " 'ту': 1500,\n",
       " 'ḥ': 30327,\n",
       " 'ス': 30255,\n",
       " 'illo': 9093,\n",
       " '▁role': 6297,\n",
       " '▁dispon': 14458,\n",
       " \"'+\": 18717,\n",
       " 'ynam': 2926,\n",
       " '▁Verb': 26646,\n",
       " 'Ét': 22353,\n",
       " 'ermann': 20648,\n",
       " 'ﬁ': 31017,\n",
       " '▁forcing': 28172,\n",
       " 'bul': 8645,\n",
       " 'ultimo': 26752,\n",
       " '知': 31043,\n",
       " 'type': 1853,\n",
       " '▁origin': 3978,\n",
       " '▁printing': 14010,\n",
       " 'slant': 17139,\n",
       " 'ose': 852,\n",
       " 'friend': 18326,\n",
       " '▁CGFloat': 29239,\n",
       " '▁started': 4687,\n",
       " '▁demonstrated': 28585,\n",
       " 'ama': 3304,\n",
       " 'cular': 16637,\n",
       " '▁MAX': 18134,\n",
       " '▁составля': 13227,\n",
       " 'ache': 1829,\n",
       " '▁label': 3858,\n",
       " '▁кри': 12273,\n",
       " 'Audio': 17111,\n",
       " 'Application': 4873,\n",
       " '▁unto': 20550,\n",
       " '▁xml': 4903,\n",
       " '构': 31901,\n",
       " 'ស': 31708,\n",
       " '▁placeholder': 12983,\n",
       " 'ení': 10639,\n",
       " 'IOS': 25925,\n",
       " '▁était': 6303,\n",
       " 'Word': 14463,\n",
       " '$': 29938,\n",
       " 'ма': 1155,\n",
       " 'ío': 9393,\n",
       " '▁expos': 14060,\n",
       " '▁пока': 25693,\n",
       " '<0x96>': 153,\n",
       " 'reichen': 19261,\n",
       " 'ational': 1288,\n",
       " 'ifferent': 15622,\n",
       " '▁Mobile': 21600,\n",
       " '▁Нор': 28664,\n",
       " 'ׁ': 31194,\n",
       " 'enger': 15109,\n",
       " '▁typically': 12234,\n",
       " '▁був': 11394,\n",
       " '▁wis': 22573,\n",
       " 'ome': 608,\n",
       " 'bě': 27950,\n",
       " 'стве': 9374,\n",
       " '<0x89>': 140,\n",
       " '▁anonymous': 21560,\n",
       " 'ိ': 31498,\n",
       " 'PD': 25014,\n",
       " 'ús': 7381,\n",
       " 'MAIN': 29032,\n",
       " '면': 31747,\n",
       " 'ври': 20219,\n",
       " 'ytu': 20588,\n",
       " '▁gewesen': 29321,\n",
       " '▁étaient': 15777,\n",
       " 'expect': 17854,\n",
       " '▁doctrine': 22542,\n",
       " '▁Corn': 11655,\n",
       " '▁му': 4179,\n",
       " 'lobal': 3157,\n",
       " 'єм': 23802,\n",
       " 'ici': 1654,\n",
       " '▁Premio': 18931,\n",
       " 'έ': 30273,\n",
       " 'ohn': 6547,\n",
       " '▁from': 515,\n",
       " 'ics': 1199,\n",
       " '▁$-': 15727,\n",
       " '▁Atlantic': 19948,\n",
       " '▁та': 1710,\n",
       " 'AR': 1718,\n",
       " 'bour': 6526,\n",
       " '▁issued': 16610,\n",
       " '▁magic': 15709,\n",
       " '▁стре': 21373,\n",
       " 'bled': 27225,\n",
       " '▁proc': 9580,\n",
       " '▁song': 4823,\n",
       " 'checkbox': 12348,\n",
       " 'Why': 11008,\n",
       " '▁дов': 26313,\n",
       " '▁pass': 1209,\n",
       " 'amentos': 26376,\n",
       " 'ă': 30035,\n",
       " '무': 31716,\n",
       " '▁assigned': 9859,\n",
       " '▁obra': 11557,\n",
       " '▁specified': 6790,\n",
       " '▁affected': 15201,\n",
       " 'co': 1111,\n",
       " 'azioni': 8312,\n",
       " 'ty': 1017,\n",
       " '▁deutschen': 13806,\n",
       " '▁####': 3191,\n",
       " 'bers': 2596,\n",
       " '▁Singapore': 25960,\n",
       " 'près': 5435,\n",
       " '▁Type': 5167,\n",
       " '▁Sver': 18144,\n",
       " 'avascript': 2516,\n",
       " 'was': 11102,\n",
       " '▁questo': 11352,\n",
       " '▁Background': 16585,\n",
       " '▁Normdatei': 28331,\n",
       " 'ize': 675,\n",
       " '▁useful': 5407,\n",
       " '▁Nice': 20103,\n",
       " '▁fil': 977,\n",
       " 'aires': 7147,\n",
       " '▁TH': 3446,\n",
       " '▁secured': 26130,\n",
       " 'çu': 24359,\n",
       " 'remove': 5992,\n",
       " 'bool': 11227,\n",
       " '▁expedition': 24431,\n",
       " 'дян': 21127,\n",
       " '▁GNU': 15143,\n",
       " '▁suffering': 23164,\n",
       " '▁Need': 20768,\n",
       " '▁pov': 16545,\n",
       " 'Impl': 6647,\n",
       " 'ши': 1911,\n",
       " 'AUT': 20656,\n",
       " 'ждения': 18479,\n",
       " 'skih': 26896,\n",
       " '▁meant': 6839,\n",
       " 'DidLoad': 20127,\n",
       " '▁eux': 23778,\n",
       " '▁libro': 19366,\n",
       " 'Usage': 27573,\n",
       " '▁По': 2195,\n",
       " 'sets': 7224,\n",
       " '▁Ara': 25953,\n",
       " '▁sin': 4457,\n",
       " '▁Fir': 14152,\n",
       " '▁particul': 16530,\n",
       " '▁tweede': 27460,\n",
       " 'ído': 27806,\n",
       " '▁Kun': 25472,\n",
       " 'sign': 4530,\n",
       " '▁HashMap': 23073,\n",
       " '▁Nevertheless': 25678,\n",
       " 'untime': 5572,\n",
       " 'министра': 14437,\n",
       " '▁Div': 4910,\n",
       " '了': 30743,\n",
       " 'ierten': 12025,\n",
       " '}\\\\,\\\\': 27559,\n",
       " 'g': 29887,\n",
       " 'Only': 11730,\n",
       " '▁Nak': 20962,\n",
       " 'dialog': 15901,\n",
       " '▁Daily': 23331,\n",
       " '▁caval': 16873,\n",
       " '▁asym': 16936,\n",
       " '▁McK': 24053,\n",
       " 'Sidenote': 28030,\n",
       " '▁environ': 12471,\n",
       " '▁deployed': 21168,\n",
       " 'fér': 3666,\n",
       " '▁aged': 26552,\n",
       " 'зе': 4791,\n",
       " '▁оп': 10645,\n",
       " 'vens': 9852,\n",
       " 'awn': 18101,\n",
       " 'ej': 10337,\n",
       " 'Has': 14510,\n",
       " '▁laughed': 19090,\n",
       " '▁histor': 3603,\n",
       " 'Tab': 8863,\n",
       " 'iker': 5603,\n",
       " '▁número': 13831,\n",
       " 'pport': 3016,\n",
       " 'printf': 8124,\n",
       " '▁станов': 9719,\n",
       " 'frastr': 14867,\n",
       " 'voy': 18644,\n",
       " 'ighth': 18919,\n",
       " 'annon': 23453,\n",
       " 'zyma': 27425,\n",
       " 'Observable': 27928,\n",
       " 'launch': 15343,\n",
       " '▁with': 411,\n",
       " '\\x82': 30469,\n",
       " '<|placeholder20|>': 32024,\n",
       " 'ateien': 12472,\n",
       " '▁param': 1828,\n",
       " '▁witness': 16277,\n",
       " '▁facts': 17099,\n",
       " 'кро': 25041,\n",
       " 'ց': 31554,\n",
       " '▁purpose': 6437,\n",
       " '▁Jahres': 19787,\n",
       " '▁remaining': 9886,\n",
       " 'zeuge': 29471,\n",
       " '▁work': 664,\n",
       " '▁carre': 24320,\n",
       " '▁other': 916,\n",
       " 'shadow': 17505,\n",
       " 'limat': 23442,\n",
       " '▁möglich': 25959,\n",
       " '┐': 31082,\n",
       " '▁dialect': 23725,\n",
       " '▁castle': 20610,\n",
       " '▁Fran': 1352,\n",
       " '▁thereby': 27999,\n",
       " 'ссии': 28229,\n",
       " '▁пові': 19664,\n",
       " 'rollo': 20426,\n",
       " '▁Monte': 11240,\n",
       " '▁dép': 17631,\n",
       " '▁disc': 2313,\n",
       " '反': 31908,\n",
       " '▁terminate': 29504,\n",
       " '▁pop': 1835,\n",
       " 'charts': 18366,\n",
       " 'akt': 5867,\n",
       " '▁Follow': 10306,\n",
       " '▁module': 3883,\n",
       " 'aze': 28334,\n",
       " ...}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vision_vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32011"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(mini_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100352"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(small_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32045"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vision_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hasattr(phi3mini_tok, \"sp_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hasattr(phi3small_tok, \"sp_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hasattr(phi3vision_tok, \"sp_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "space_sep = \"▁\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "mini_toks = list(mini_vocab.keys())\n",
    "small_toks = list(small_vocab.keys())\n",
    "vision_toks = list(vision_vocab.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32011\n",
      "100352\n",
      "32045\n"
     ]
    }
   ],
   "source": [
    "print(len(mini_toks))\n",
    "print(len(small_toks))\n",
    "print(len(vision_toks))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'et'"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "phi3mini_tok.sp_model.id_to_piece(300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<sentencepiece.SentencePieceProcessor; proxy of <Swig Object of type 'sentencepiece::SentencePieceProcessor *' at 0x7aea4f390> >"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "phi3mini_tok.sp_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
