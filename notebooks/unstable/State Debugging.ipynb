{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6322ebeedc335fc6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-02T17:16:39.381695Z",
     "start_time": "2024-10-02T17:16:39.334719Z"
    }
   },
   "outputs": [],
   "source": [
    "import stitch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1ec02432-a44d-4fdb-b44c-b153529fc03d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-02T17:11:00.340331Z",
     "start_time": "2024-10-02T17:11:00.337392Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/samueljenkins/dev/guidance-dev/venv/lib/python3.9/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from guidance.models import Transformers\n",
    "from guidance import gen, user, system\n",
    "\n",
    "import logging\n",
    "logging.basicConfig()\n",
    "logging.getLogger().setLevel(logging.DEBUG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "18b70f42-4b6d-41a4-94be-a41360571901",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): huggingface.co:443\n",
      "DEBUG:urllib3.connectionpool:https://huggingface.co:443 \"HEAD /gpt2/resolve/main/config.json HTTP/11\" 200 0\n",
      "DEBUG:urllib3.connectionpool:https://huggingface.co:443 \"HEAD /gpt2/resolve/main/generation_config.json HTTP/11\" 200 0\n",
      "DEBUG:urllib3.connectionpool:https://huggingface.co:443 \"HEAD /gpt2/resolve/main/tokenizer_config.json HTTP/11\" 200 0\n",
      "/Users/samueljenkins/dev/guidance-dev/venv/lib/python3.9/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n",
      "DEBUG:asyncio:Using selector: KqueueSelector\n",
      "DEBUG:guidance.visual._renderer:NEED_RESET:empty\n",
      "DEBUG:guidance.visual._renderer:RECV:init\n",
      "DEBUG:guidance.visual._renderer:NEED_RESET:jupyter:a6b92d43-0fe8-465e-aa33-5b060af58bc4|3\n",
      "DEBUG:guidance.visual._renderer:SEND:init\n",
      "DEBUG:guidance.visual._renderer:NEED_NEW_DISPLAY:new widget\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7ffd73cded79478ca781a6ee2dea57fc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "StitchWidget(initial_height='auto', initial_width='100%', srcdoc='<!doctype html>\\n<html lang=\"en\">\\n<head>\\n …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:guidance.library._gen:start gen(name=\"suffix\")\n",
      "DEBUG:guidance.library._gen:finish gen\n",
      "DEBUG:guidance.models._model:start Model._run_stateless\n",
      "DEBUG:guidance.models._model:finish Model._run_stateless\n",
      "DEBUG:guidance.visual._renderer:SEND:ready\n",
      "DEBUG:guidance.visual._renderer:RECV:raw:{\"class_name\":\"HeartbeatMessage\"}\n",
      "DEBUG:guidance.visual._renderer:RECV:msg:{'class_name': 'HeartbeatMessage'}\n",
      "DEBUG:guidance.visual._renderer:NOTIFY:{'class_name': 'HeartbeatMessage'}\n",
      "DEBUG:guidance.visual._renderer:NOTIFY:[<bound method Engine._msg_recv of <guidance.models.transformers._transformers.TransformersEngine object at 0x12c0c3970>>]\n",
      "DEBUG:guidance.models._model:ENGINE:{'class_name': 'HeartbeatMessage'}\n"
     ]
    }
   ],
   "source": [
    "m0 = Transformers(\"gpt2\")\n",
    "# m1 = m0 + \"Alms for the \" + gen(name=\"suffix\", max_tokens=5, stop='\\n')\n",
    "\n",
    "with system():\n",
    "    m1 = m0 + \"You are responsible for autocompleting a sentence.\"\n",
    "with user():\n",
    "    m2 = m1 + \"Roses are red and \" + gen(name=\"suffix\", regex=r'[\\w\\s]{15,20}', max_tokens=20)\n",
    "m3 = m2 + \">:(\"\n",
    "\n",
    "# with user():\n",
    "#     m3 = m2 + \"\\nWhat can I do?\"\n",
    "\n",
    "# m1 = m0 + f\"Hi there {gen(name='name', max_tokens=10, regex='[A-Za-z]{3,5}')}\"\n",
    "# m2 = m0 + f\"You can't stop \" + gen(name='name', max_tokens=10, regex='[A-Za-z]{3,5}')\n",
    "\n",
    "# with system():\n",
    "#     m3 = m0 + \"You are responsible for autocompleting a sentence.\"\n",
    "\n",
    "# with user():\n",
    "#     m4 = m3 + \"The sun is rising \" + gen(name='sentence_suffix', max_tokens=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5a5d668a11bda28f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-02T17:11:12.293140Z",
     "start_time": "2024-10-02T17:11:12.290965Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:0:None:None\n",
      "└── 1:1:RoleOpenerInput:'RoleOpenerInput':'system':None\n",
      "    └── 2:2:StatefulGuidanceInput({{G|5088695296|G}}):None\n",
      "        └── 3:3:LiteralInput:'LiteralInput':'<|im_start|>system\\n':TextOutput:'TextOutput':'<|im_start|>system\\n'\n",
      "            └── 4:4:LiteralInput:'LiteralInput':'You are responsible for autocompleting a sentence.':TextOutput:'TextOutput':'You are responsible for autocompleting a sentence.'\n",
      "                └── 5:5:RoleCloserInput:'RoleCloserInput':'system':CaptureOutput:'CaptureOutput':'system':'You are responsible for autocompleting a sentence.'\n",
      "                    └── 6:6:StatefulGuidanceInput({{G|5246009408|G}}):None\n",
      "                        └── 7:7:LiteralInput:'LiteralInput':'<|im_end|>\\n':TextOutput:'TextOutput':'<|im_end|>\\n'\n",
      "                            └── 8:8:RoleOpenerInput:'RoleOpenerInput':'user':None\n",
      "                                └── 9:9:StatefulGuidanceInput({{G|5243002288|G}}):None\n",
      "                                    └── 10:10:LiteralInput:'LiteralInput':'<|im_start|>user\\n':TextOutput:'TextOutput':'<|im_start|>user\\n'\n",
      "                                        └── 11:11:LiteralInput:'LiteralInput':'Roses are red and ':TextOutput:'TextOutput':'Roses are red and '\n",
      "                                            └── 12:12:StatelessGuidanceInput({{G|5243713552|G}}):None\n",
      "                                                └── 13:13:None:TextOutput:'TextOutput':'you':True:1\n",
      "                                                    └── 14:14:None:TextOutput:'TextOutput':' are':True:1\n",
      "                                                        └── 15:15:None:TextOutput:'TextOutput':' responsible':True:1\n",
      "                                                            └── 16:16:None:CaptureOutput:'CaptureOutput':'suffix':'you are responsible'\n",
      "                                                                └── 17:17:RoleCloserInput:'RoleCloserInput':'user':CaptureOutput:'CaptureOutput':'user':'Roses are red and you are responsible'\n",
      "                                                                    └── 18:18:StatefulGuidanceInput({{G|5029891824|G}}):None\n",
      "                                                                        └── 19:19:LiteralInput:'LiteralInput':'<|im_end|>\\n':TextOutput:'TextOutput':'<|im_end|>\\n'\n",
      "                                                                            └── 20:20:LiteralInput:'LiteralInput':'>:(':TextOutput:'TextOutput':'>:('\n"
     ]
    }
   ],
   "source": [
    "from guidance.visual import display_trace_tree\n",
    "\n",
    "display_trace_tree(m0._trace_handler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "407d0ea5-f53f-4600-93e8-b83d01aaee16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hi\n",
      "4\n",
      "cell execution finished\n"
     ]
    }
   ],
   "source": [
    "def notify_cell_done():\n",
    "    print('cell execution finished')\n",
    "    get_ipython().events.unregister('post_execute', notify_cell_done)\n",
    "\n",
    "print('hi')\n",
    "x = 2\n",
    "y = 2 + x\n",
    "print(y)\n",
    "\n",
    "get_ipython().events.register('post_execute', notify_cell_done)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da738f07-e136-46b9-8d64-32d16062c332",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
